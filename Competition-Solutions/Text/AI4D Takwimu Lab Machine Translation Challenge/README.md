# Competition Summary

## Description

Ewe and Fongbe are Niger–Congo languages, part of a cluster of related languages commonly called Gbe.

L’éwé et le fon sont des langues du Niger-Congo d’un cluster de langues similaires appelé communément Gbe.


Fongbe is the major Gbe language of Benin (with approximately 4.1 million speakers), while Ewe is spoken in Togo and southeastern Ghana by approximately 4.5 million people as a first language and by a million others as a second language.

Le fon est la langue la plus parlée au Bénin avec approximativement 4.1 millions d’utilisateurs. L’éwé est parlé au Togo et dans le sud-est du Ghana par approximativement 4.5 millions de personnes comme première langue et par un million d’ autres personnes comme deuxième langue.


Although those languages are at the core of the economic and social life of at least 3 major West African capital cities (namely Cotonou, Lome and Accra), they are today mostly spoken and very rarely written.

Bien que ces langues soient au cœur de la vie économique et sociale d’au moins capitales principales ouest africaines (Cotonou, Lomé et Accra), elles sont bien plus parlées qu’écrites au jour d’aujourd’hui.


Due to that fact (among other reasons), there is very little official or formal communication in those languages, leaving non-French/English speakers often unable to access critical facilities like education, banking, and healthcare.

Pour cette raison (entre autres raisons), il y a très peu de communication officielle ou formelle dans ces langues, laissant les non francophones / anglophones souvent incapables d'accéder aux services fondamentaux comme l'éducation, la banque, la santé, etc. 


The objective of this challenge is to create a machine translation system capable of converting text from French into Fongbe or Ewe. 

L'objectif de ce défi est de créer un système de traduction automatique capable de convertir du texte du français en Fongbe ou Ewe. 



## Competition Rules

Participation in this competition could be as an individual or in a team of up to four people.

Prizes are transferred only to the individual players or to the team leader.

Code was not shared privately outside of a team. Any code shared, was made available to all competition participants through the platform. (i.e. on the discussion boards).



## Datasets and packages

Only the datasets provided for this competition was used.

Vous ne pouvez utiliser que les ensembles de données fournis pour la compétition.


A parallel corpus dataset for machine translation from French to Ewe and French to Fongbe, languages from Togo and Benin respectively was provided.

Il s'agit d'un ensemble de données de corpus parallèle pour la traduction automatique du français vers l'éwé et du français vers le fongbe, langues respectivement du Togo et du Bénin.


It contained roughly 23 000 French to Ewe and 53 000 French to Fongbe parallel sentences, collected from blogs, tales, newspapers, daily conversations, webpages and annotated for neural machine translation.

Il contient environ 23 000 phrases parallèles entre le français et l'éwé et 53 000 le français vers le fongbe, annotées pour la traduction automatique neuronale. Les données Français vers Ewe et Français vers Fongbe contiennent des phrases parallèles collectées à partir de blogs, contes, journaux, conversations quotidiennes, pages Web.


Pretrained models were permitted as long as they are openly available to everyone.

Vous pouvez utiliser des modèles pré-entraînés tant qu'ils sont ouverts à tous.



## Submissions and winning

The top 3 solution placed on the final leaderboard were required to submit their winning solution code to us for verification, and thereby agreed to assign all worldwide rights of copyright in and to such winning solution to Zindi.



## Reproducibility

The full documentation was retrieved. This includes:
- All data used

- Output data and where they are stored

- Explanation of features used

- The solution must include the original data provided by Zindi and validated external data (no processed data)

- All editing of data must be done in a notebook (i.e. not manually in Excel)



## Data standards:

- The most recent versions of packages were used.

- Submitted code run on the original train, test, and other datasets provided.



## Evaluation:

The error metric for this competition is Rouge Score, ROUGE-N (N-gram) scoring (Rouge1), reporting the F-measure.

The Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scoring algorithm calculates the similarity between a candidate document and a collection of reference documents.

Use the ROUGE score to evaluate the quality of document translation and summarization models 



## Prizes

1st Place: $1 000 USD

2nd Place: $600 USD

3rd Place: $400 USD



## Benefits

The solutions would be a model that can be improved upon or used by researchers across the world to create APIs that can be integrated into day-to-day tools like ATMs, delivery applications etc., and help bridge the gap between rural West Africa and the modernized services.

La meilleure solution pourrait être améliorée ou utilisée par des chercheurs du monde entier pour créer des API qui peuvent être intégrées dans des outils du quotidien tels que les guichets automatiques, les applications de livraison, etc. et aider à combler le fossé entre l'Afrique de l'Ouest rurale et les services modernisés.


This challenge is part of an initiative that wishes to bring down the barriers between African local language speakers and modern society.

Ainsi, cette compétition s'inscrit dans une initiative qui souhaite faire tomber les barrières entre les locuteurs de langues locales et la société moderne.
