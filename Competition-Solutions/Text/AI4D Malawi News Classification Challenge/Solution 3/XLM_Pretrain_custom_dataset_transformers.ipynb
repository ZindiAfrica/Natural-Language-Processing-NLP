{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgUvpWQrQkw0",
    "outputId": "6706e105-3a39-4887-df0f-45ac77dc6e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 10 16:59:05 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5idMkSE5xiTT",
    "outputId": "135ad6d4-f09e-4f56-a646-032935d90cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8_DhQR1w1ra0"
   },
   "outputs": [],
   "source": [
    "!cp drive/MyDrive/zindi_nlp/MalawiNews/*.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIwZsZv_i9on",
    "outputId": "38dba343-3390-4c1a-9287-2ec375a8570f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-t7pl8olf\n",
      "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-t7pl8olf\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Collecting sacremoses\n",
      "  Using cached https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.10.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2217008 sha256=5bb8c2d056475e1112be6b27827ebae24fa893f0497ee46ac65671062b392929\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1ukytz5s/wheels/33/eb/3b/4bf5dd835e865e472d4fc0754f35ac0edb08fe852e8f21655f\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "#!pip install transformers==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8j8OmgW7lLQ",
    "outputId": "c5aa1aff-0466-4bff-f7d3-501c8c4a9dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/1a/b9f9b3bfef624686ae81c070f0a6bb635047b17cdb3698c7ad01281e6f9a/datasets-1.6.2-py3-none-any.whl (221kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 16.9MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 28.3MB/s \n",
      "\u001b[?25hCollecting xxhash\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 64.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Collecting fsspec\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 69.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: xxhash, fsspec, datasets, sentencepiece\n",
      "Successfully installed datasets-1.6.2 fsspec-2021.4.0 sentencepiece-0.1.95 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IR8bN706iTzU",
    "outputId": "7e037bb7-7aed-42e1-93dd-086a93c4d706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
      "\r",
      "\u001b[K     |██▌                             | 10kB 15.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 20kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 30kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 40kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 51kB 11.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 61kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 71kB 12.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 81kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 92kB 12.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 102kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 112kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 122kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 12.1MB/s \n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm-x4z-PDDTP",
    "outputId": "98c212c4-21d9-4838-a8ec-0b6fc1443af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'transformers': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! rm -r transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZFY_0dy5tZ4",
    "outputId": "a08c24a0-31d3-411c-c059-43c84b4bf2e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 72233, done.\u001b[K\n",
      "remote: Counting objects: 100% (274/274), done.\u001b[K\n",
      "remote: Compressing objects: 100% (202/202), done.\u001b[K\n",
      "remote: Total 72233 (delta 118), reused 153 (delta 53), pack-reused 71959\u001b[K\n",
      "Receiving objects: 100% (72233/72233), 55.04 MiB | 23.42 MiB/s, done.\n",
      "Resolving deltas: 100% (51253/51253), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/huggingface/transformers.git\n",
    "#  && cd transformers && git checkout 4906a29 \n",
    "# && cd transformers && git checkout bae0c79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZLLRsLW5thQ",
    "outputId": "2f0caa69-66fb-4c77-abe9-b886f1791912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056\n",
      "1436 620\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "data = pd.read_csv(\"Train.csv\").Text.tolist() + pd.read_csv(\"Test.csv\").Text.tolist()\n",
    "print(len(data))\n",
    "print(len(pd.read_csv(\"Train.csv\")), len(pd.read_csv(\"Test.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "ca8caed81ed5451bb8ed95bb6c1ba0d6",
      "55a1f8b32a5f4f0fbbccf63b91161aa4",
      "f48b42081937463bacd77f6fdf615290",
      "cf76bb33bbd244fc9cb3d5a05c716c42",
      "b91eba4d7c474eceba732727fa7ac270",
      "8a0c429cc1f24fbe9024eac5303aecab",
      "921be1e8aa744fd3b0e27bc35cadbfe3",
      "e5b0d87ede044059a0d5126436d3fcdc"
     ]
    },
    "id": "cIrIqlR84W9O",
    "outputId": "3e701793-3381-40ff-a71e-8c4e80e3664d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8caed81ed5451bb8ed95bb6c1ba0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2056.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for x in tqdm(data):\n",
    "  texts.extend(x.strip().split(\"\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zDjaZtgltEGr"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IFW61_s35tlI"
   },
   "outputs": [],
   "source": [
    "with open(\"datas.txt\", \"w\") as f:\n",
    "  for line in texts:\n",
    "    f.write(line.strip() + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YMgy_Ymp5tsp"
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iz9sPppK5tng",
    "outputId": "049ed139-305c-4e93-fd80-7771af4db4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-10 16:59:37.548507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "05/10/2021 16:59:39 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "05/10/2021 16:59:39 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=drive/MyDrive/zindi_nlp/MalawiNews/pretrain/xlm-r-large/, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=8, gradient_accumulation_steps=4, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1000.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May10_16-59-39_2d45db7298d1, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=45000, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=drive/MyDrive/zindi_nlp/MalawiNews/pretrain/xlm-r-large/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
      "05/10/2021 16:59:39 - WARNING - datasets.builder -   Using custom data configuration default-f3099c5c91370bd5\n",
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-f3099c5c91370bd5/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
      "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-f3099c5c91370bd5/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
      "[INFO|file_utils.py:1531] 2021-05-10 16:59:40,366 >> https://huggingface.co/xlm-roberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmprbbs7gcw\n",
      "Downloading: 100% 513/513 [00:00<00:00, 471kB/s]\n",
      "[INFO|file_utils.py:1535] 2021-05-10 16:59:40,633 >> storing https://huggingface.co/xlm-roberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
      "[INFO|file_utils.py:1543] 2021-05-10 16:59:40,634 >> creating metadata file for /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
      "[INFO|configuration_utils.py:517] 2021-05-10 16:59:40,635 >> loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
      "[INFO|configuration_utils.py:553] 2021-05-10 16:59:40,635 >> Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:517] 2021-05-10 16:59:40,905 >> loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
      "[INFO|configuration_utils.py:553] 2021-05-10 16:59:40,905 >> Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|file_utils.py:1531] 2021-05-10 16:59:41,174 >> https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmprf65t9wm\n",
      "Downloading: 100% 5.07M/5.07M [00:00<00:00, 7.32MB/s]\n",
      "[INFO|file_utils.py:1535] 2021-05-10 16:59:42,182 >> storing https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "[INFO|file_utils.py:1543] 2021-05-10 16:59:42,182 >> creating metadata file for /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "[INFO|file_utils.py:1531] 2021-05-10 16:59:42,451 >> https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpstvmrw4y\n",
      "Downloading: 100% 9.10M/9.10M [00:00<00:00, 10.6MB/s]\n",
      "[INFO|file_utils.py:1535] 2021-05-10 16:59:43,651 >> storing https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "[INFO|file_utils.py:1543] 2021-05-10 16:59:43,651 >> creating metadata file for /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "[INFO|tokenization_utils_base.py:1717] 2021-05-10 16:59:44,454 >> loading file https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "[INFO|tokenization_utils_base.py:1717] 2021-05-10 16:59:44,454 >> loading file https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "[INFO|tokenization_utils_base.py:1717] 2021-05-10 16:59:44,454 >> loading file https://huggingface.co/xlm-roberta-large/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1717] 2021-05-10 16:59:44,454 >> loading file https://huggingface.co/xlm-roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1717] 2021-05-10 16:59:44,454 >> loading file https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|file_utils.py:1531] 2021-05-10 16:59:45,249 >> https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppx94m98r\n",
      "Downloading: 100% 2.24G/2.24G [00:44<00:00, 50.4MB/s]\n",
      "[INFO|file_utils.py:1535] 2021-05-10 17:00:29,938 >> storing https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
      "[INFO|file_utils.py:1543] 2021-05-10 17:00:29,938 >> creating metadata file for /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
      "[INFO|modeling_utils.py:1149] 2021-05-10 17:00:29,938 >> loading weights file https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
      "[INFO|modeling_utils.py:1331] 2021-05-10 17:00:37,877 >> All model checkpoint weights were used when initializing XLMRobertaForMaskedLM.\n",
      "\n",
      "[INFO|modeling_utils.py:1340] 2021-05-10 17:00:37,877 >> All the weights of XLMRobertaForMaskedLM were initialized from the model checkpoint at xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForMaskedLM for predictions without further training.\n",
      "#0:   0% 0/6 [00:00<?, ?ba/s]\n",
      "#1:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\n",
      "\n",
      "#2:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#0:  17% 1/6 [00:01<00:08,  1.67s/ba]\n",
      "#1:  17% 1/6 [00:01<00:07,  1.59s/ba]\u001b[A\n",
      "\n",
      "\n",
      "#3:  17% 1/6 [00:01<00:07,  1.53s/ba]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  17% 1/6 [00:01<00:07,  1.58s/ba]\u001b[A\u001b[A\n",
      "#0:  33% 2/6 [00:01<00:04,  1.24s/ba]\n",
      "\n",
      "\n",
      "#3:  33% 2/6 [00:01<00:04,  1.15s/ba]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  33% 2/6 [00:01<00:04,  1.18s/ba]\u001b[A\u001b[A\n",
      "#0:  50% 3/6 [00:02<00:02,  1.05ba/s]\n",
      "\n",
      "\n",
      "#3:  50% 3/6 [00:02<00:02,  1.13ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  50% 3/6 [00:02<00:02,  1.09ba/s]\u001b[A\u001b[A\n",
      "#0:  67% 4/6 [00:02<00:01,  1.33ba/s]\n",
      "\n",
      "\n",
      "#3:  67% 4/6 [00:02<00:01,  1.42ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  67% 4/6 [00:02<00:01,  1.39ba/s]\u001b[A\u001b[A\n",
      "#0:  83% 5/6 [00:02<00:00,  1.66ba/s]\n",
      "\n",
      "\n",
      "#3:  83% 5/6 [00:02<00:00,  1.74ba/s]\u001b[A\u001b[A\u001b[A\n",
      "#1: 100% 6/6 [00:02<00:00,  2.18ba/s]\n",
      "\n",
      "\n",
      "#0: 100% 6/6 [00:02<00:00,  2.11ba/s]\n",
      "\n",
      "\n",
      "\n",
      "#3: 100% 6/6 [00:02<00:00,  2.20ba/s]\n",
      "\n",
      "\n",
      "#2: 100% 6/6 [00:02<00:00,  2.14ba/s]\n",
      "#0:   0% 0/6 [00:00<?, ?ba/s]\n",
      "#1:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\n",
      "\n",
      "#2:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#0:  17% 1/6 [00:01<00:07,  1.51s/ba]\n",
      "#1:  17% 1/6 [00:01<00:07,  1.52s/ba]\u001b[A\n",
      "\n",
      "\n",
      "#3:  17% 1/6 [00:01<00:07,  1.52s/ba]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#0:  33% 2/6 [00:01<00:04,  1.14s/ba]\n",
      "#1:  33% 2/6 [00:01<00:04,  1.14s/ba]\u001b[A\n",
      "\n",
      "\n",
      "#3:  33% 2/6 [00:01<00:04,  1.13s/ba]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#0:  50% 3/6 [00:02<00:02,  1.13ba/s]\n",
      "#1:  50% 3/6 [00:02<00:02,  1.15ba/s]\u001b[A\n",
      "\n",
      "\n",
      "#3:  50% 3/6 [00:02<00:02,  1.15ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  50% 3/6 [00:02<00:02,  1.12ba/s]\u001b[A\u001b[A\n",
      "#0:  67% 4/6 [00:02<00:01,  1.43ba/s]\n",
      "\n",
      "\n",
      "#3:  67% 4/6 [00:02<00:01,  1.46ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "#2:  67% 4/6 [00:02<00:01,  1.42ba/s]\u001b[A\u001b[A\n",
      "#0:  83% 5/6 [00:02<00:00,  1.75ba/s]\n",
      "#1: 100% 6/6 [00:02<00:00,  2.30ba/s]\n",
      "\n",
      "\n",
      "\n",
      "#0: 100% 6/6 [00:02<00:00,  2.19ba/s]\n",
      "\n",
      "\n",
      "#2:  83% 5/6 [00:02<00:00,  1.71ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3: 100% 6/6 [00:02<00:00,  2.26ba/s]\n",
      "\n",
      "\n",
      "#2: 100% 6/6 [00:02<00:00,  2.17ba/s]\n",
      "[INFO|trainer.py:414] 2021-05-10 17:00:56,363 >> Using amp fp16 backend\n",
      "[INFO|trainer.py:515] 2021-05-10 17:00:56,554 >> The following columns in the training set  don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
      "[INFO|trainer.py:1144] 2021-05-10 17:00:56,569 >> ***** Running training *****\n",
      "[INFO|trainer.py:1145] 2021-05-10 17:00:56,569 >>   Num examples = 21529\n",
      "[INFO|trainer.py:1146] 2021-05-10 17:00:56,569 >>   Num Epochs = 1000\n",
      "[INFO|trainer.py:1147] 2021-05-10 17:00:56,569 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1148] 2021-05-10 17:00:56,569 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1149] 2021-05-10 17:00:56,569 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1150] 2021-05-10 17:00:56,569 >>   Total optimization steps = 1345000\n",
      "{'loss': 3.9169, 'learning_rate': 9.996319702602232e-06, 'epoch': 0.37}\n",
      "{'loss': 2.9214, 'learning_rate': 9.992602230483273e-06, 'epoch': 0.74}\n",
      "{'loss': 2.5627, 'learning_rate': 9.988884758364313e-06, 'epoch': 1.12}\n",
      "{'loss': 2.3216, 'learning_rate': 9.985174721189592e-06, 'epoch': 1.49}\n",
      "{'loss': 2.1682, 'learning_rate': 9.981457249070633e-06, 'epoch': 1.86}\n",
      "{'loss': 2.071, 'learning_rate': 9.977747211895911e-06, 'epoch': 2.23}\n",
      "{'loss': 1.9759, 'learning_rate': 9.974029739776952e-06, 'epoch': 2.6}\n",
      "  0% 3890/1345000 [45:32<250:33:21,  1.49it/s]"
     ]
    }
   ],
   "source": [
    "!python transformers/examples/pytorch/language-modeling/run_mlm.py --model_name_or_path \"xlm-roberta-large\" --fp16 --max_seq_length 200 --gradient_accumulation 4  \\\n",
    "  --train_file \"datas.txt\" --validation_file \"datas.txt\"  --do_train --per_device_train_batch_size 4 --save_steps 10000 --do_eval --line_by_line --seed 42 \\\n",
    "  --learning_rate 1e-5 --mlm_probability 0.2 --num_train_epochs 1000  --output_dir drive/MyDrive/zindi_nlp/MalawiNews/pretrain/xlm-r-large/ --preprocessing_num_workers=4\\\n",
    "  # --pad_to_max_length True   #  #\"google/electra-small-generator\" \\   transformers/examples/xla_spawn.py --num_cores 8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL6A2AVI4Uhc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjLYd2G62QBO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ro-MiH85dw0g"
   },
   "outputs": [],
   "source": [
    "!python transformers/examples/language-modeling/run_mlm.py -h"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "XLM Pretrain custom dataset transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "55a1f8b32a5f4f0fbbccf63b91161aa4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a0c429cc1f24fbe9024eac5303aecab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "921be1e8aa744fd3b0e27bc35cadbfe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b91eba4d7c474eceba732727fa7ac270": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ca8caed81ed5451bb8ed95bb6c1ba0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f48b42081937463bacd77f6fdf615290",
       "IPY_MODEL_cf76bb33bbd244fc9cb3d5a05c716c42"
      ],
      "layout": "IPY_MODEL_55a1f8b32a5f4f0fbbccf63b91161aa4"
     }
    },
    "cf76bb33bbd244fc9cb3d5a05c716c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5b0d87ede044059a0d5126436d3fcdc",
      "placeholder": "​",
      "style": "IPY_MODEL_921be1e8aa744fd3b0e27bc35cadbfe3",
      "value": " 2056/2056 [00:00&lt;00:00, 63062.09it/s]"
     }
    },
    "e5b0d87ede044059a0d5126436d3fcdc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f48b42081937463bacd77f6fdf615290": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0c429cc1f24fbe9024eac5303aecab",
      "max": 2056,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b91eba4d7c474eceba732727fa7ac270",
      "value": 2056
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
