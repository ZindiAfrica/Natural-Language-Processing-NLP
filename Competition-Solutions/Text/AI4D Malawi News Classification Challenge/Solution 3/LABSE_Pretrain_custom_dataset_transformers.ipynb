{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LABSE_Pretrain_custom_dataset_transformers.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"17e3e1eaf0304ebcbef877dd3cc7037f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_03e2078229c4433d8d027f03b7da0e85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7abbf9ada5a643a596c53d1c96f01a90","IPY_MODEL_6afc63aeaf7542258baf2293453dc2a8"]}},"03e2078229c4433d8d027f03b7da0e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7abbf9ada5a643a596c53d1c96f01a90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_99a44bc3e61b4d698b10d50556229c06","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":2056,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2056,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1681ab84ab7c4d9e89ea08b7efcb621e"}},"6afc63aeaf7542258baf2293453dc2a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e8edef0278c4258af054720452949ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2056/2056 [00:06&lt;00:00, 318.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff7f5bd7674e4797a2424f8cbf4a2601"}},"99a44bc3e61b4d698b10d50556229c06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1681ab84ab7c4d9e89ea08b7efcb621e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e8edef0278c4258af054720452949ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff7f5bd7674e4797a2424f8cbf4a2601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9Okd_tPrY0c","executionInfo":{"status":"ok","timestamp":1622116694510,"user_tz":-180,"elapsed":56352,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"602bb28a-77ae-40af-af5a-81479bb19910"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgUvpWQrQkw0","executionInfo":{"status":"ok","timestamp":1622116705317,"user_tz":-180,"elapsed":417,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"da9a03d5-97a2-41ae-a257-c5eb33f6a7f7"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Thu May 27 11:58:24 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RKE1u7kYyFYH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622116853371,"user_tz":-180,"elapsed":427,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"4213a23e-40b2-4595-c9bb-0bee7e382914"},"source":["import os\n","!rm -r transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'transformers': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6tiMmkkKxLvx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5idMkSE5xiTT","executionInfo":{"status":"ok","timestamp":1622116859012,"user_tz":-180,"elapsed":3125,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"ec43e53a-160e-4008-ec8b-b075ad421210"},"source":["import torch\n","print(torch.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8_DhQR1w1ra0","executionInfo":{"status":"ok","timestamp":1622116878253,"user_tz":-180,"elapsed":2303,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["!cp drive/MyDrive/zindi_nlp/MalawiNews/*.csv ."],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1tIpfxLCVra"},"source":["# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIwZsZv_i9on","executionInfo":{"status":"ok","timestamp":1622116904554,"user_tz":-180,"elapsed":19957,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"10b2dd96-b008-4afc-c9e9-c2ecbad2311a"},"source":["!pip install git+https://github.com/huggingface/transformers.git\n","#transformers==4.5transformers==4.6.0.dev0"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-qzjw4vnh\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-qzjw4vnh\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 17.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2019.12.20)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 51.6MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.7.4.3)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.7.0.dev0-cp37-none-any.whl size=2316570 sha256=6cd318509264487a20887f44ab1cf1984d3d7213a15f2fdf1ddd0d002af71343\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9fbn8ykl/wheels/33/eb/3b/4bf5dd835e865e472d4fc0754f35ac0edb08fe852e8f21655f\n","Successfully built transformers\n","Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0.dev0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8j8OmgW7lLQ","executionInfo":{"status":"ok","timestamp":1622116935491,"user_tz":-180,"elapsed":4847,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"c129b7b2-5834-4ffd-cfd4-3135d6d1f153"},"source":["!pip install datasets sentencepiece "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f8/ff7cd6e3b400b33dcbbfd31c6c1481678a2b2f669f521ad20053009a9aa3/datasets-1.7.0-py3-none-any.whl (234kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 14.6MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 22.5MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 55.0MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 58.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: fsspec, xxhash, datasets, sentencepiece\n","Successfully installed datasets-1.7.0 fsspec-2021.5.0 sentencepiece-0.1.95 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IR8bN706iTzU","executionInfo":{"status":"ok","timestamp":1622116942724,"user_tz":-180,"elapsed":3662,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"e7802e6c-2d0d-4070-fc6f-c1b32be7a74f"},"source":["!pip install emoji"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n","\r\u001b[K     |â–ˆâ–ˆâ–Œ                             | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 30kB 23.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 40kB 19.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 51kB 18.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 61kB 17.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 81kB 13.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 92kB 14.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 102kB 14.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112kB 14.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 122kB 14.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 14.4MB/s \n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZFY_0dy5tZ4","executionInfo":{"status":"ok","timestamp":1622116952348,"user_tz":-180,"elapsed":7547,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"89049a45-6688-4e25-fac3-e812350470f8"},"source":["! git clone https://github.com/huggingface/transformers.git\n","# && cd transformers && git checkout 4906a29 \n","#  bae0c79"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 73558, done.\u001b[K\n","remote: Counting objects: 100% (311/311), done.\u001b[K\n","remote: Compressing objects: 100% (200/200), done.\u001b[K\n","remote: Total 73558 (delta 150), reused 183 (delta 91), pack-reused 73247\u001b[K\n","Receiving objects: 100% (73558/73558), 56.63 MiB | 18.67 MiB/s, done.\n","Resolving deltas: 100% (52251/52251), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZLLRsLW5thQ","executionInfo":{"status":"ok","timestamp":1622116954599,"user_tz":-180,"elapsed":3,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"608f7498-30f9-4304-91c2-f296466cca9f"},"source":["import pandas as pd\n","import numpy as np\n","import warnings\n","from tqdm.auto import tqdm\n","warnings.simplefilter(\"ignore\")\n","\n","data = pd.read_csv(\"Train.csv\").Text.tolist() + pd.read_csv(\"Test.csv\").Text.tolist()\n","print(len(data))\n","print(len(pd.read_csv(\"Train.csv\")), len(pd.read_csv(\"Test.csv\")))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2056\n","1436 620\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["17e3e1eaf0304ebcbef877dd3cc7037f","03e2078229c4433d8d027f03b7da0e85","7abbf9ada5a643a596c53d1c96f01a90","6afc63aeaf7542258baf2293453dc2a8","99a44bc3e61b4d698b10d50556229c06","1681ab84ab7c4d9e89ea08b7efcb621e","2e8edef0278c4258af054720452949ce","ff7f5bd7674e4797a2424f8cbf4a2601"]},"id":"cIrIqlR84W9O","executionInfo":{"status":"ok","timestamp":1622116957432,"user_tz":-180,"elapsed":25,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}},"outputId":"d7a7fcee-74a1-4cb7-8764-6abcf999c8eb"},"source":["texts = []\n","for x in tqdm(data):\n","  texts.extend(x.strip().split(\"\\n\"))\n"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17e3e1eaf0304ebcbef877dd3cc7037f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=2056.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zDjaZtgltEGr","executionInfo":{"status":"ok","timestamp":1622116961733,"user_tz":-180,"elapsed":632,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["#%load_ext tensorboard"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFW61_s35tlI","executionInfo":{"status":"ok","timestamp":1622116964320,"user_tz":-180,"elapsed":1080,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["with open(\"datas.txt\", \"w\") as f:\n","  for line in texts:\n","    f.write(line.strip() + \"\\n\")\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMgy_Ymp5tsp","executionInfo":{"status":"ok","timestamp":1622116965605,"user_tz":-180,"elapsed":4,"user":{"displayName":"Cedric Manouan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnI55k9QnJV4mtok5wRGE36cZcj1DZIjihnSx6=s64","userId":"00242929915047742214"}}},"source":["#%tensorboard --logdir runs"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iz9sPppK5tng","outputId":"e5c6e745-9cd9-4f1e-b17b-c9bec1bc4604"},"source":["!python transformers/examples/pytorch/language-modeling/run_mlm.py --model_name_or_path \"setu4993/LaBSE\" --max_seq_length 200 --gradient_accumulation 8 --fp16 \\\n","  --train_file \"datas.txt\" --validation_file \"datas.txt\"  --do_train --per_device_train_batch_size 4  --save_steps 15000 --do_eval --line_by_line --seed 42 \\\n","  --learning_rate 1e-5 --mlm_probability 0.2 --num_train_epochs 2000  --output_dir drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/ --preprocessing_num_workers=4\\\n","  #--pad_to_max_length True   # transformers/examples/xla_spawn.py --num_cores 8 \n","\n","  # 60k bs 4 4->8 max 200"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-05-27 12:02:48.935402: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","05/27/2021 12:02:51 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n","05/27/2021 12:02:51 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=8, gradient_accumulation_steps=8, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2000.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May27_12-02-51_f1cb4bc3684c, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=15000, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, log_on_each_node=True, _n_gpu=1, mp_parameters=)\n","05/27/2021 12:02:51 - WARNING - datasets.builder -   Using custom data configuration default-eac28c70c4d5136a\n","Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-eac28c70c4d5136a/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-eac28c70c4d5136a/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:52,132 >> https://huggingface.co/setu4993/LaBSE/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpz3rggc3y\n","Downloading: 100% 560/560 [00:00<00:00, 327kB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:02:52,487 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/5e8580c8bc79861e8f05c7107d3576aa1e21098fcc7a3d6767e6b9449f0de551.1a9666a40fd2ff320970aaaf9cd4c3eeae8d58d1bb15577c7f4389739fc25f0a\n","[INFO|file_utils.py:1568] 2021-05-27 12:02:52,487 >> creating metadata file for /root/.cache/huggingface/transformers/5e8580c8bc79861e8f05c7107d3576aa1e21098fcc7a3d6767e6b9449f0de551.1a9666a40fd2ff320970aaaf9cd4c3eeae8d58d1bb15577c7f4389739fc25f0a\n","[INFO|configuration_utils.py:517] 2021-05-27 12:02:52,488 >> loading configuration file https://huggingface.co/setu4993/LaBSE/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5e8580c8bc79861e8f05c7107d3576aa1e21098fcc7a3d6767e6b9449f0de551.1a9666a40fd2ff320970aaaf9cd4c3eeae8d58d1bb15577c7f4389739fc25f0a\n","[INFO|configuration_utils.py:553] 2021-05-27 12:02:52,488 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 501153\n","}\n","\n","[INFO|configuration_utils.py:517] 2021-05-27 12:02:52,834 >> loading configuration file https://huggingface.co/setu4993/LaBSE/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5e8580c8bc79861e8f05c7107d3576aa1e21098fcc7a3d6767e6b9449f0de551.1a9666a40fd2ff320970aaaf9cd4c3eeae8d58d1bb15577c7f4389739fc25f0a\n","[INFO|configuration_utils.py:553] 2021-05-27 12:02:52,834 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 501153\n","}\n","\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:53,235 >> https://huggingface.co/setu4993/LaBSE/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpexuaniou\n","Downloading: 100% 5.22M/5.22M [00:00<00:00, 10.4MB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:02:54,146 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/e8627ea3796059a5af6469cdac41ea99354b04bd2e4f5c8943e8ed1c599ed9f0.8f2ffe7514c779e620b40da312123fd8536e25273a5873d73b975930ff3f3def\n","[INFO|file_utils.py:1568] 2021-05-27 12:02:54,146 >> creating metadata file for /root/.cache/huggingface/transformers/e8627ea3796059a5af6469cdac41ea99354b04bd2e4f5c8943e8ed1c599ed9f0.8f2ffe7514c779e620b40da312123fd8536e25273a5873d73b975930ff3f3def\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:54,582 >> https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_zivam4r\n","Downloading: 100% 9.62M/9.62M [00:00<00:00, 14.5MB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:02:55,694 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/7bb8637d7dd2bf3f1844099cffa3c6dd48ea15d13c123b7e7557f03a556c4580.eb59c97be3df9f113dbd88197e3744bd63efbc76bd68875345453aa01afc2372\n","[INFO|file_utils.py:1568] 2021-05-27 12:02:55,694 >> creating metadata file for /root/.cache/huggingface/transformers/7bb8637d7dd2bf3f1844099cffa3c6dd48ea15d13c123b7e7557f03a556c4580.eb59c97be3df9f113dbd88197e3744bd63efbc76bd68875345453aa01afc2372\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:56,399 >> https://huggingface.co/setu4993/LaBSE/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7xg8zjtk\n","Downloading: 100% 112/112 [00:00<00:00, 93.4kB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:02:56,750 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/f7976973d6e1d492e81cc7e3f495661fffb63be89dd6889a1f1b32911095fbbc.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","[INFO|file_utils.py:1568] 2021-05-27 12:02:56,751 >> creating metadata file for /root/.cache/huggingface/transformers/f7976973d6e1d492e81cc7e3f495661fffb63be89dd6889a1f1b32911095fbbc.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:57,101 >> https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpuwkopb7m\n","Downloading: 100% 239/239 [00:00<00:00, 201kB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:02:57,456 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/01bc61f45f47c0df8718fb3cfd2274394a70b3851d96f7d99181e3b7c189f50a.5c62174d76f59a3da1ffb86077423a9a5ec33177b83777152e1a4d0e1a7b4111\n","[INFO|file_utils.py:1568] 2021-05-27 12:02:57,456 >> creating metadata file for /root/.cache/huggingface/transformers/01bc61f45f47c0df8718fb3cfd2274394a70b3851d96f7d99181e3b7c189f50a.5c62174d76f59a3da1ffb86077423a9a5ec33177b83777152e1a4d0e1a7b4111\n","[INFO|tokenization_utils_base.py:1717] 2021-05-27 12:02:57,457 >> loading file https://huggingface.co/setu4993/LaBSE/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/e8627ea3796059a5af6469cdac41ea99354b04bd2e4f5c8943e8ed1c599ed9f0.8f2ffe7514c779e620b40da312123fd8536e25273a5873d73b975930ff3f3def\n","[INFO|tokenization_utils_base.py:1717] 2021-05-27 12:02:57,457 >> loading file https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/7bb8637d7dd2bf3f1844099cffa3c6dd48ea15d13c123b7e7557f03a556c4580.eb59c97be3df9f113dbd88197e3744bd63efbc76bd68875345453aa01afc2372\n","[INFO|tokenization_utils_base.py:1717] 2021-05-27 12:02:57,457 >> loading file https://huggingface.co/setu4993/LaBSE/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1717] 2021-05-27 12:02:57,457 >> loading file https://huggingface.co/setu4993/LaBSE/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/f7976973d6e1d492e81cc7e3f495661fffb63be89dd6889a1f1b32911095fbbc.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","[INFO|tokenization_utils_base.py:1717] 2021-05-27 12:02:57,457 >> loading file https://huggingface.co/setu4993/LaBSE/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/01bc61f45f47c0df8718fb3cfd2274394a70b3851d96f7d99181e3b7c189f50a.5c62174d76f59a3da1ffb86077423a9a5ec33177b83777152e1a4d0e1a7b4111\n","[INFO|file_utils.py:1556] 2021-05-27 12:02:58,235 >> https://huggingface.co/setu4993/LaBSE/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpshy1fmop\n","Downloading: 100% 1.88G/1.88G [00:32<00:00, 58.2MB/s]\n","[INFO|file_utils.py:1560] 2021-05-27 12:03:30,711 >> storing https://huggingface.co/setu4993/LaBSE/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/1cb7d97d64ce45b4859d55e285a4ec4c0188a88799241005ec5838635a8cc052.70eb4ae447b9e863b25c34aa8765f0a68f995c0338251c824a2b6faadcc99929\n","[INFO|file_utils.py:1568] 2021-05-27 12:03:30,711 >> creating metadata file for /root/.cache/huggingface/transformers/1cb7d97d64ce45b4859d55e285a4ec4c0188a88799241005ec5838635a8cc052.70eb4ae447b9e863b25c34aa8765f0a68f995c0338251c824a2b6faadcc99929\n","[INFO|modeling_utils.py:1155] 2021-05-27 12:03:30,711 >> loading weights file https://huggingface.co/setu4993/LaBSE/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1cb7d97d64ce45b4859d55e285a4ec4c0188a88799241005ec5838635a8cc052.70eb4ae447b9e863b25c34aa8765f0a68f995c0338251c824a2b6faadcc99929\n","tcmalloc: large alloc 1539547136 bytes == 0x55d0140be000 @  0x7f1b03f19b6b 0x7f1b03f39379 0x7f1a8472d25e 0x7f1a8472e9d2 0x7f1ac14118e6 0x7f1ac1873dd9 0x7f1ac1d7e77a 0x7f1ac1d49ef9 0x7f1ac1d00657 0x7f1ac1ba4929 0x7f1ad3570c07 0x7f1ad3572584 0x7f1ad331cd0a 0x55cfff785c65 0x55cfff746462 0x55cfff7b9fd5 0x55cfff7b47ad 0x55cfff747c9f 0x55cfff788d79 0x55cfff785cc4 0x55cfff746559 0x55cfff7ba4f8 0x55cfff7b47ad 0x55cfff747a81 0x55cfff788d79 0x55cfff785cc4 0x55cfff746462 0x55cfff7b9715 0x55cfff7b47ad 0x55cfff747c9f 0x55cfff788d79\n","tcmalloc: large alloc 1539547136 bytes == 0x55d07d738000 @  0x7f1b03f19b6b 0x7f1b03f39379 0x7f1a8472d25e 0x7f1a8472e9d2 0x7f1ac14118e6 0x7f1ac1873dd9 0x7f1ac1d7e77a 0x7f1ac1d49ef9 0x7f1ac1d00657 0x7f1ac1ba4929 0x7f1ad3570c07 0x7f1ad3572584 0x7f1ad331cd0a 0x55cfff785c65 0x55cfff746462 0x55cfff7b9fd5 0x55cfff7b47ad 0x55cfff747c9f 0x55cfff788d79 0x55cfff785cc4 0x55cfff746559 0x55cfff7ba4f8 0x55cfff7b47ad 0x55cfff747a81 0x55cfff788d79 0x55cfff785cc4 0x55cfff746462 0x55cfff7b9715 0x55cfff7b47ad 0x55cfff747a81 0x55cfff788d79\n","tcmalloc: large alloc 1539547136 bytes == 0x55d0d9372000 @  0x7f1b03f19b6b 0x7f1b03f39379 0x7f1a8472d25e 0x7f1a8472e9d2 0x7f1ac1ff68a5 0x7f1ad320c699 0x55cfff785c65 0x55cfff746462 0x55cfff7b9715 0x55cfff7b47ad 0x55cfff747003 0x55cfff746b09 0x55cfff88e28d 0x55cfff7fd1db 0x55cfff745bb1 0x55cfff836fed 0x55cfff7b9988 0x55cfff7b47ad 0x55cfff686e2c 0x55cfff7b6bb5 0x55cfff7b44ae 0x55cfff7473ea 0x55cfff7b632a 0x55cfff7b44ae 0x55cfff747c9f 0x55cfff747ea1 0x55cfff7b6bb5 0x55cfff7b44ae 0x55cfff7473ea 0x55cfff7b632a 0x55cfff7b47ad\n","[INFO|modeling_utils.py:1339] 2021-05-27 12:03:43,876 >> All model checkpoint weights were used when initializing BertForMaskedLM.\n","\n","[WARNING|modeling_utils.py:1342] 2021-05-27 12:03:43,876 >> Some weights of BertForMaskedLM were not initialized from the model checkpoint at setu4993/LaBSE and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," #0:  17% 1/6 [00:00<00:00,  5.28ba/s]\n"," #0:  33% 2/6 [00:00<00:00,  5.40ba/s]\n"," #0:  50% 3/6 [00:00<00:00,  5.48ba/s]\n","\n"," #2:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\n"," #0:  67% 4/6 [00:00<00:00,  5.48ba/s]\n","\n","\n"," #3:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n","\n"," #2:  17% 1/6 [00:00<00:01,  4.61ba/s]\u001b[A\u001b[A\n"," #0:  83% 5/6 [00:00<00:00,  5.43ba/s]\n","\n","\n"," #3:  17% 1/6 [00:00<00:00,  5.04ba/s]\u001b[A\u001b[A\u001b[A\n","\n"," #0: 100% 6/6 [00:00<00:00,  6.07ba/s]\n","\n"," #1:  67% 4/6 [00:00<00:00,  5.59ba/s]\u001b[A\n","\n"," #2:  50% 3/6 [00:00<00:00,  5.09ba/s]\u001b[A\u001b[A\n"," #1:  83% 5/6 [00:00<00:00,  5.58ba/s]\u001b[A\n","\n","\n"," #1: 100% 6/6 [00:00<00:00,  6.29ba/s]\n","\n","\n"," #2:  67% 4/6 [00:00<00:00,  5.78ba/s]\u001b[A\u001b[A\n","\n","\n"," #3:  50% 3/6 [00:00<00:00,  5.17ba/s]\u001b[A\u001b[A\u001b[A\n","\n"," #2: 100% 6/6 [00:00<00:00,  6.90ba/s]\n","\n","\n","\n"," #3:  67% 4/6 [00:00<00:00,  5.74ba/s]\u001b[A\u001b[A\u001b[A\n","\n","\n"," #3: 100% 6/6 [00:00<00:00,  6.91ba/s]\n"," #0:  17% 1/6 [00:00<00:00,  5.28ba/s]\n"," #0:  33% 2/6 [00:00<00:00,  5.28ba/s]\n"," #0:  50% 3/6 [00:00<00:00,  5.35ba/s]\n","\n"," #2:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\n"," #0:  67% 4/6 [00:00<00:00,  5.25ba/s]\n","\n"," #2:  17% 1/6 [00:00<00:01,  4.72ba/s]\u001b[A\u001b[A\n","\n","\n"," #3:   0% 0/6 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n"," #0:  83% 5/6 [00:00<00:00,  5.25ba/s]\n","\n"," #2:  33% 2/6 [00:00<00:00,  4.88ba/s]\u001b[A\u001b[A\n","\n","\n"," #0: 100% 6/6 [00:01<00:00,  5.87ba/s]\n","\n"," #1:  67% 4/6 [00:00<00:00,  5.34ba/s]\u001b[A\n","\n"," #2:  50% 3/6 [00:00<00:00,  5.16ba/s]\u001b[A\u001b[A\n","\n","\n"," #3:  33% 2/6 [00:00<00:00,  5.21ba/s]\u001b[A\u001b[A\u001b[A\n"," #1:  83% 5/6 [00:00<00:00,  5.41ba/s]\u001b[A\n","\n"," #1: 100% 6/6 [00:00<00:00,  6.07ba/s]\n","\n","\n","\n"," #3:  50% 3/6 [00:00<00:00,  5.23ba/s]\u001b[A\u001b[A\u001b[A\n","\n"," #2: 100% 6/6 [00:00<00:00,  6.94ba/s]\n","\n","\n","\n"," #3:  67% 4/6 [00:00<00:00,  5.69ba/s]\u001b[A\u001b[A\u001b[A\n","\n","\n"," #3: 100% 6/6 [00:00<00:00,  6.82ba/s]\n","[INFO|trainer.py:415] 2021-05-27 12:04:01,202 >> Using amp fp16 backend\n","[INFO|trainer.py:516] 2021-05-27 12:04:01,202 >> The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n","[INFO|trainer.py:1148] 2021-05-27 12:04:01,214 >> ***** Running training *****\n","[INFO|trainer.py:1149] 2021-05-27 12:04:01,214 >>   Num examples = 21529\n","[INFO|trainer.py:1150] 2021-05-27 12:04:01,214 >>   Num Epochs = 2000\n","[INFO|trainer.py:1151] 2021-05-27 12:04:01,214 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:1152] 2021-05-27 12:04:01,214 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n","[INFO|trainer.py:1153] 2021-05-27 12:04:01,214 >>   Gradient Accumulation steps = 8\n","[INFO|trainer.py:1154] 2021-05-27 12:04:01,214 >>   Total optimization steps = 1344000\n","{'loss': 8.5357, 'learning_rate': 9.996287202380952e-06, 'epoch': 0.74}\n","{'loss': 6.3761, 'learning_rate': 9.992566964285714e-06, 'epoch': 1.49}\n","{'loss': 5.5448, 'learning_rate': 9.988846726190476e-06, 'epoch': 2.23}\n","{'loss': 5.0527, 'learning_rate': 9.98512648809524e-06, 'epoch': 2.97}\n","{'loss': 4.6672, 'learning_rate': 9.981406250000001e-06, 'epoch': 3.72}\n","{'loss': 4.402, 'learning_rate': 9.977686011904763e-06, 'epoch': 4.46}\n","{'loss': 4.1872, 'learning_rate': 9.973965773809525e-06, 'epoch': 5.21}\n","{'loss': 4.0204, 'learning_rate': 9.970252976190476e-06, 'epoch': 5.95}\n","{'loss': 3.866, 'learning_rate': 9.96653273809524e-06, 'epoch': 6.7}\n","{'loss': 3.7634, 'learning_rate': 9.962812500000001e-06, 'epoch': 7.44}\n","{'loss': 3.6483, 'learning_rate': 9.959092261904763e-06, 'epoch': 8.18}\n","{'loss': 3.5662, 'learning_rate': 9.955372023809525e-06, 'epoch': 8.93}\n","{'loss': 3.4542, 'learning_rate': 9.951651785714287e-06, 'epoch': 9.67}\n","{'loss': 3.4045, 'learning_rate': 9.94793898809524e-06, 'epoch': 10.42}\n","{'loss': 3.3261, 'learning_rate': 9.944226190476192e-06, 'epoch': 11.16}\n","{'loss': 3.2726, 'learning_rate': 9.940505952380953e-06, 'epoch': 11.9}\n","{'loss': 3.2033, 'learning_rate': 9.936785714285715e-06, 'epoch': 12.65}\n","{'loss': 3.137, 'learning_rate': 9.933065476190477e-06, 'epoch': 13.39}\n","{'loss': 3.0991, 'learning_rate': 9.929345238095239e-06, 'epoch': 14.14}\n","{'loss': 3.0602, 'learning_rate': 9.925625e-06, 'epoch': 14.88}\n","{'loss': 3.0032, 'learning_rate': 9.921904761904762e-06, 'epoch': 15.62}\n","{'loss': 2.9399, 'learning_rate': 9.918184523809524e-06, 'epoch': 16.37}\n","{'loss': 2.9288, 'learning_rate': 9.914464285714287e-06, 'epoch': 17.11}\n","{'loss': 2.8776, 'learning_rate': 9.910744047619049e-06, 'epoch': 17.86}\n","{'loss': 2.8607, 'learning_rate': 9.90702380952381e-06, 'epoch': 18.6}\n","{'loss': 2.8085, 'learning_rate': 9.903303571428572e-06, 'epoch': 19.34}\n","{'loss': 2.7908, 'learning_rate': 9.899590773809524e-06, 'epoch': 20.09}\n","{'loss': 2.7357, 'learning_rate': 9.895870535714288e-06, 'epoch': 20.83}\n","{'loss': 2.7223, 'learning_rate': 9.89215773809524e-06, 'epoch': 21.58}\n","{'loss': 2.7037, 'learning_rate': 9.888437500000001e-06, 'epoch': 22.32}\n","  1% 15000/1344000 [3:55:24<331:55:01,  1.11it/s][INFO|trainer.py:1884] 2021-05-27 15:59:25,235 >> Saving model checkpoint to drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/checkpoint-15000\n","[INFO|configuration_utils.py:351] 2021-05-27 15:59:25,240 >> Configuration saved in drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/checkpoint-15000/config.json\n","tcmalloc: large alloc 1539547136 bytes == 0x55d0140be000 @  0x7f1b03f19b6b 0x7f1b03f39379 0x7f1a8472d25e 0x7f1a8472e9d2 0x7f1ac1ff68a5 0x7f1ad320c699 0x55cfff785c65 0x55cfff746462 0x55cfff7b9715 0x55cfff7b44ae 0x55cfff747a81 0x55cfff747ea1 0x55cfff7b6bb5 0x55cfff7b47ad 0x55cfff7473ea 0x55cfff7b560e 0x55cfff74730a 0x55cfff7b560e 0x55cfff7b47ad 0x55cfff7473ea 0x55cfff7b53b5 0x55cfff7b44ae 0x55cfff7473ea 0x55cfff7b53b5 0x55cfff7b47ad 0x55cfff7473ea 0x55cfff7b632a 0x55cfff7b44ae 0x55cfff7473ea 0x55cfff7b560e 0x55cfff7b44ae\n","[INFO|modeling_utils.py:889] 2021-05-27 15:59:34,195 >> Model weights saved in drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/checkpoint-15000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:1924] 2021-05-27 15:59:34,199 >> tokenizer config file saved in drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/checkpoint-15000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:1930] 2021-05-27 15:59:34,202 >> Special tokens file saved in drive/MyDrive/zindi_nlp/MalawiNews/pretrain/LABSE-v100-reproduce/checkpoint-15000/special_tokens_map.json\n","{'loss': 2.6543, 'learning_rate': 9.884717261904763e-06, 'epoch': 23.07}\n","{'loss': 2.6295, 'learning_rate': 9.880997023809524e-06, 'epoch': 23.81}\n","{'loss': 2.6121, 'learning_rate': 9.877276785714288e-06, 'epoch': 24.55}\n","  1% 16798/1344000 [4:24:35<359:45:50,  1.02it/s]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EjLYd2G62QBO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ro-MiH85dw0g"},"source":["!python transformers/examples/language-modeling/run_mlm.py -h"],"execution_count":null,"outputs":[]}]}