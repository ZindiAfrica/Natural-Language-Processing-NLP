{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZM7vmMGd9bS"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChwxQL8Eiy81",
        "outputId": "22e4f821-1496-4db9-a000-09ca741f2609"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeRVM4AOjFDv"
      },
      "source": [
        "!cp '/content/drive/MyDrive/AI4D_Malawi_News_Classification/data/Train.csv' .\n",
        "!cp '/content/drive/MyDrive/AI4D_Malawi_News_Classification/data/Test.csv' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14mvGuYFZBqw"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP9FM3Pks68N"
      },
      "source": [
        "import pandas as pd \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cloudpickle\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZclVUn6IeLhX"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY-ek2RyeL0q"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQnyEDttqtI3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYl2Q-_qqtGi"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Concatenate , Input ,concatenate\n",
        "from keras.models import Sequential, Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DqU_ce8qtEe"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8iyeRAU4qfr"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmGrNJ8q5Gk5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlxSutGEeASx"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUaHH0Aus68P"
      },
      "source": [
        "train = pd.read_csv('Train.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9uhNc9Ls68Q"
      },
      "source": [
        "test = pd.read_csv('Test.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJiq2NCs68Q"
      },
      "source": [
        "LABEL = 'Label'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6euT6sR_SZNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233d9c07-2572-4cf1-8e18-adb3c874c4de"
      },
      "source": [
        "# Dowload pretrained vectorizer\n",
        "file_id = '1F7q38t_KASJKLcs2IBdF4k0pbm1lgk5A'\n",
        "destination = '/content/vectorizer.txt'\n",
        "gdd.download_file_from_google_drive(file_id=file_id,\n",
        "                                    dest_path=destination)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1F7q38t_KASJKLcs2IBdF4k0pbm1lgk5A into /content/vectorizer.txt... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNhOHH7uZF8o"
      },
      "source": [
        "# **Modeling : ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnjVmiDOofdu"
      },
      "source": [
        "def CUSTOM_ResNet(shape1) :\n",
        "  # define two sets of inputs\n",
        "  input_1 = tf.keras.layers.Input(shape = (shape1),name='20_Features')\n",
        "  input_conv = tf.keras.layers.Input(shape = (shape1, 1),name='20_Features_Conv')\n",
        "  \n",
        "  # create Convolution Layer \n",
        "  head_conv = Convolution1D(filters=64, kernel_size=1, input_shape=(shape1, 1),name='Conv_Layer')(input_conv)\n",
        "  head_conv = Activation('relu',name='Conv_Activation')(head_conv)\n",
        "  input_2_conv = Flatten()(head_conv)\n",
        "  \n",
        "  # create a simple 3 layers for input_1\n",
        "  # Layer 1 -- input_1\n",
        "  head_2 = tf.keras.layers.BatchNormalization(name='Conv_Features_BatchNormalization_1')(input_2_conv)\n",
        "  head_2 = tf.keras.layers.Dense(512, activation = \"relu\",name='Conv_Features_Layer_1')(head_2)\n",
        "  head_2 = tf.keras.layers.Dropout(0.2,name='Conv_Features_DropOut_1')(head_2)\n",
        "  # Layer 2 -- input_1\n",
        "  head_2 = tf.keras.layers.BatchNormalization(name='Conv_Features_BatchNormalization_2')(head_2)\n",
        "  input_2 = tf.keras.layers.Dense(128, activation = \"relu\",name='Conv_Features_Output_Layer_2')(head_2)\n",
        "\n",
        "\n",
        "  # create a simple 3 layers for input_1\n",
        "  # Layer 1 -- input_1\n",
        "  head_1 = tf.keras.layers.BatchNormalization(name='20_Features_BatchNormalization_1')(input_1)\n",
        "  head_1 = tf.keras.layers.Dense(256, activation = \"relu\",name='20_Features_Layer_1')(head_1)\n",
        "  head_1 = tf.keras.layers.Dropout(0.15,name='20_Features_DropOut_1')(head_1)\n",
        "  # Layer 2 -- input_1\n",
        "  head_1 = tf.keras.layers.BatchNormalization(name='20_Features_BatchNormalization_2')(head_1)\n",
        "  input_3 = tf.keras.layers.Dense(128, activation = \"relu\",name='20_Features_Output_Layer_2')(head_1)\n",
        "\n",
        "  input_4 = tf.keras.layers.Concatenate(name='Concatenate_Outputs_Features')([input_3,input_2])\n",
        "\n",
        "  # create a simple 3 layers for input_4\n",
        "  # Layer 1 -- input_1\n",
        "  head_4 = tf.keras.layers.BatchNormalization(name='Conv_20_Features_BatchNormalization_1')(input_4)\n",
        "  head_4 = tf.keras.layers.Dense(256, activation = \"relu\",name='Conv_20_Features_Layer_1')(head_4)\n",
        "  input_5 = tf.keras.layers.Dropout(0.2,name='Conv_20_Features_DropOut_1')(head_4)\n",
        "\n",
        "  # combine the output vector of the two branches\n",
        "  input_4_avg = tf.keras.layers.Average()([input_5, input_4]) \n",
        "\n",
        "  head_3 = tf.keras.layers.BatchNormalization(name='Outputs_Features_BatchNormalization')(input_4_avg)\n",
        "  head_3 = tf.keras.layers.Dense(256, \"relu\",name='Outputs_Features_Layer_1')(head_3)\n",
        "  head_3 = tf.keras.layers.Dropout(0.15,name='Outputs_Features_DropOut_1')(head_3)\n",
        "  \n",
        "  head_3 = tf.keras.layers.BatchNormalization(name='Outputs_Features_BatchNormalization_2')(head_3)\n",
        "  head_3 = tf.keras.layers.Dense(160, \"relu\",name='Outputs_Features_Layer_2')(head_3)\n",
        "  \n",
        "  head_3 = tf.keras.layers.Dense(80, \"relu\",name='Outputs_Features_Layer_3')(head_3)\n",
        "  head_3 =  tf.keras.layers.Dropout(0.4,name='Outputs_Features_DropOut_3')(head_3)\n",
        "  \n",
        "  output = tf.keras.layers.Dense(20, activation = \"softmax\",name='Output')(head_3)\n",
        "  \n",
        "  model = tf.keras.models.Model(inputs = [input_1,input_conv], outputs = output)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiVX74B3xzh8"
      },
      "source": [
        "# Function to seed everything\n",
        "import random , os\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNHTfRL-a0sZ",
        "outputId": "fb976e8d-631f-4d7a-ef23-f0562af2e179"
      },
      "source": [
        "n_splits = 5\n",
        "kf = StratifiedKFold(n_splits=n_splits, random_state=10, shuffle=True)\n",
        "\n",
        "# custom vectorizer \n",
        "vectorizer = cloudpickle.load(open('vectorizer.txt', 'rb'))\n",
        "X_train = vectorizer.predict(train['Text'])\n",
        "X_test = vectorizer.predict(test['Text'])\n",
        "\n",
        "\n",
        "# reshape test data\n",
        "X_test_r = np.zeros((len(X_test), 20, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :]\n",
        "\n",
        "\n",
        "y_train = train[LABEL].copy()\n",
        "n_labels = train[LABEL].unique().shape[0]\n",
        "\n",
        "# we need to binarize the labels for the neural net\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "LE = LabelEncoder()\n",
        "ytrain_enc = pd.get_dummies(y_train).values\n",
        "TARGETS = pd.get_dummies(y_train).columns\n",
        "\n",
        "y_oof = np.zeros([X_train.shape[0], n_labels])\n",
        "y_test = np.zeros([X_test.shape[0], n_labels])\n",
        "\n",
        "i = 0\n",
        "metrics = list()\n",
        "apply_aug = False\n",
        "\n",
        "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
        "\n",
        "    X_tr, X_vl = X_train[tr_idx, :], X_train[val_idx, :]\n",
        "    y_tr, y_vl = ytrain_enc[tr_idx], ytrain_enc[val_idx]\n",
        "    y_train_, y_vld_ = y_train[tr_idx], y_train[val_idx]\n",
        "\n",
        "    # reshape train data\n",
        "    X_train_r = np.zeros((len(X_tr), 20, 1))\n",
        "    X_train_r[:, :, 0] = X_tr[:, :]\n",
        "\n",
        "    # reshape validation data\n",
        "    X_valid_r = np.zeros((len(X_vl), 20, 1))\n",
        "    X_valid_r[:, :, 0] = X_vl[:, :]\n",
        "    \n",
        "    # 1 CNN ANN\n",
        "    seed_everything(seed=1)\n",
        "    model_ResNet = CUSTOM_ResNet(shape1=20)\n",
        "    model_ResNet.fit([X_tr,X_train_r], y=y_tr, batch_size=8, epochs=8, verbose=0, validation_data=([X_vl,X_valid_r], y_vl))\n",
        "    y_pred_ResNet = model_ResNet.predict([X_vl,X_valid_r])\n",
        "    test_pred_ResNet = model_ResNet.predict([X_test,X_test_r])\n",
        "    \n",
        "    # 2 - MLP\n",
        "    model1 = MLPClassifier(250, random_state=47) \n",
        "    model1.fit(X_tr, y_train_)\n",
        "    y_pred1    = model1.predict_proba(X_vl)\n",
        "    test_pred1 = model1.predict_proba(X_test)\n",
        "    \n",
        "    y_pred = (y_pred1+y_pred_ResNet ) / 2.0\n",
        "    y_oof[val_idx, :] = y_pred\n",
        "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
        "    metric = accuracy_score(y_vl, TARGETS[np.argmax(y_pred,axis=1)])\n",
        "    print(\"fold #{} val_accuracy: {}\".format(i, metric))\n",
        "    \n",
        "    i += 1\n",
        "    test_pred = (test_pred1 + test_pred_ResNet ) / 2.0\n",
        "    y_test += test_pred / n_splits\n",
        "    metrics.append(metric)\n",
        "    \n",
        "metrics = np.array(metrics).mean()\n",
        "print(f'Full accuracy {metrics}')  # Full accuracy 0.6908222028648858"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold #0 val_accuracy: 0.6979166666666666\n",
            "fold #1 val_accuracy: 0.6968641114982579\n",
            "fold #2 val_accuracy: 0.6968641114982579\n",
            "fold #3 val_accuracy: 0.6898954703832753\n",
            "fold #4 val_accuracy: 0.686411149825784\n",
            "Full accuracy 0.6935903019744483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZUZIVB9rJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "cc6f1d7d-59dc-44d8-8194-087acd252d9d"
      },
      "source": [
        "# Prepare submission\n",
        "y_sub = np.argmax(y_test, 1)\n",
        "y_sub = pd.DataFrame({LABEL: y_sub})\n",
        "class_ = TARGETS\n",
        "y_sub[LABEL] = y_sub[LABEL].apply(lambda x: class_[x])\n",
        "sub = test[['ID']]\n",
        "sub['LABEL'] = y_sub[LABEL]\n",
        "sub.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_ADHEtjTi</td>\n",
              "      <td>SOCIAL ISSUES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_AHfJktdQ</td>\n",
              "      <td>RELIGION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_AUJIHpZr</td>\n",
              "      <td>RELATIONSHIPS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_AUKYBbIM</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_AZnsVPEi</td>\n",
              "      <td>WILDLIFE/ENVIRONMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ID_AcEmtLNf</td>\n",
              "      <td>RELIGION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ID_AeOXSXRV</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ID_AgyQFeQn</td>\n",
              "      <td>ECONOMY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ID_AjOcippL</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ID_AjzKuqko</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ID_AtYxYHTe</td>\n",
              "      <td>SPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ID_AyKlcuII</td>\n",
              "      <td>WILDLIFE/ENVIRONMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ID_BCcZpVbb</td>\n",
              "      <td>SOCIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ID_BDLxsYrM</td>\n",
              "      <td>SOCIAL ISSUES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ID_BFjxDKzn</td>\n",
              "      <td>SOCIAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID                 LABEL\n",
              "0   ID_ADHEtjTi         SOCIAL ISSUES\n",
              "1   ID_AHfJktdQ              RELIGION\n",
              "2   ID_AUJIHpZr         RELATIONSHIPS\n",
              "3   ID_AUKYBbIM              POLITICS\n",
              "4   ID_AZnsVPEi  WILDLIFE/ENVIRONMENT\n",
              "5   ID_AcEmtLNf              RELIGION\n",
              "6   ID_AeOXSXRV              POLITICS\n",
              "7   ID_AgyQFeQn               ECONOMY\n",
              "8   ID_AjOcippL              POLITICS\n",
              "9   ID_AjzKuqko              POLITICS\n",
              "10  ID_AtYxYHTe                SPORTS\n",
              "11  ID_AyKlcuII  WILDLIFE/ENVIRONMENT\n",
              "12  ID_BCcZpVbb                SOCIAL\n",
              "13  ID_BDLxsYrM         SOCIAL ISSUES\n",
              "14  ID_BFjxDKzn                SOCIAL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDz8_t2bs68S"
      },
      "source": [
        "sub.to_csv(f'seed_10_Resnet_MLP_sub_{round(metrics,4)}.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh8H71ZRCTSE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}