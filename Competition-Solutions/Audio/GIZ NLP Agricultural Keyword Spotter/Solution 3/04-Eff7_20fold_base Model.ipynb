{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04-Eff7_20fold_base Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mgIRFfegQApR"},"source":["### Eff7_20fold_base -----> (0 to 19) folds\n","\n","- In this notebook we are using colab pro with high ram and 16gb GPU\n","- this notebook sane as previus notebook 01-Eff5_20fold_base part1\n","- except encoder/model to EfficientNet-07\n","\n","#### Important points \n","- for saving outputs we need to mount drive \n","- for downloading preprocessing data we need to include kaggle.json file for kaggle API\n","- for saving outputs we need to give output path\n","- output path in `Run.py` `args` class `output_dir`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RE0b1lGqPCy7","executionInfo":{"status":"ok","timestamp":1606613838375,"user_tz":-330,"elapsed":1401,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"4713e1df-d7da-4025-ddfa-1fd414a14783"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun Nov 29 01:37:17 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjH07ydpPoyO","executionInfo":{"status":"ok","timestamp":1606613927008,"user_tz":-330,"elapsed":85174,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"36c9f1c2-2d89-4469-ab26-6b181ca0d3cd"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1_JDA_DsPwsX"},"source":["# kaggle api for download preprocessed data\n","! mkdir /root/.kaggle\n","! cp '/content/drive/My Drive/kaggle.json' /root/.kaggle\n","! chmod 400 /root/.kaggle/kaggle.json\n","\n","!pip uninstall -y kaggle >> quit\n","!pip install --upgrade pip >> quit\n","!pip install kaggle==1.5.6 >> quit\n","!kaggle -v >> quit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RD2w3OaNQAqf","executionInfo":{"status":"ok","timestamp":1606613954780,"user_tz":-330,"elapsed":70157,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"e6381315-81fe-4052-9a75-754d9fccdcb6"},"source":["!kaggle datasets download -d gopidurgaprasad/giz-nlp-agricultural-keyword-spotter\n","!unzip giz-nlp-agricultural-keyword-spotter.zip >> quit"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading giz-nlp-agricultural-keyword-spotter.zip to /content\n"," 99% 569M/575M [00:04<00:00, 164MB/s]\n","100% 575M/575M [00:04<00:00, 149MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8yDh-uIQZoP","executionInfo":{"status":"ok","timestamp":1606613991458,"user_tz":-330,"elapsed":104231,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"d1aeacde-a481-4158-da0a-763b1778e9cd"},"source":["##install requred packages\n","!pip -q install timm\n","!pip -q install albumentations\n","!pip -q install soundfile\n","!pip -q install torchlibrosa\n","!pip -q install audiomentations\n","!pip -q install catalyst\n","!pip -q install transformers\n","!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 247 kB 5.9 MB/s \n","\u001b[K     |████████████████████████████████| 631 kB 5.8 MB/s \n","\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 489 kB 6.1 MB/s \n","\u001b[K     |████████████████████████████████| 308 kB 33.1 MB/s \n","\u001b[K     |████████████████████████████████| 159 kB 41.0 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 6.0 MB/s \n","\u001b[K     |████████████████████████████████| 883 kB 33.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 35.6 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 38.5 MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N4BhmjAsQzX9"},"source":["### process data and create k-folds"]},{"cell_type":"code","metadata":{"id":"tkuiGG1RQrc-"},"source":["import glob, os, random\n","import pandas as pd, numpy as np\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Suq6VHGTQ8cp","executionInfo":{"status":"ok","timestamp":1606613992192,"user_tz":-330,"elapsed":99647,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"0ba0f3b9-9b73-45aa-da44-4f2fb84cba38"},"source":["train_wav = glob.glob(\"audio_train/input/audio_train/*/*.wav\")\n","test_wav = glob.glob(\"audio_test/input/audio_test/*.wav\")\n","print(len(train_wav), len(test_wav))\n","\n","train_df = pd.DataFrame({\n","    \"fn\" : train_wav\n","}).sort_values(\"fn\")\n","train_df[\"label\"] = train_df.fn.apply(lambda x: x.split(\"/\")[-2])\n","\n","test_df = pd.DataFrame({\n","    \"fn\" : test_wav\n","}).sort_values(\"fn\")\n","\n","print(train_df.shape, test_df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4709 1017\n","(4709, 2) (1017, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpDtvNaeR-Je","executionInfo":{"status":"ok","timestamp":1606613992705,"user_tz":-330,"elapsed":98996,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"4961ea0c-97f0-4287-bb1b-70d60afa3f1f"},"source":["FOLDS = 20\n","SEED = 24\n","\n","train_df.loc[:, 'kfold'] = -1\n","train_df = train_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","X = train_df['fn'].values\n","y = train_df['label'].values\n","kfold = StratifiedKFold(n_splits=FOLDS)\n","for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n","    train_df.loc[v_idx, \"kfold\"] = fold\n","print(train_df.kfold.value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0     236\n","4     236\n","7     236\n","3     236\n","8     236\n","6     236\n","2     236\n","1     236\n","5     236\n","9     235\n","12    235\n","16    235\n","19    235\n","13    235\n","15    235\n","10    235\n","14    235\n","18    235\n","11    235\n","17    235\n","Name: kfold, dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=20.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PyAIDfpgSqvc"},"source":["train_df.to_csv(\"train_20folds_seed24_df.csv\", index=False)\n","test_df.to_csv(\"test_df.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqorozP9S7vx","executionInfo":{"status":"ok","timestamp":1606614335765,"user_tz":-330,"elapsed":2398,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"c5a3ea90-db5a-41fe-f480-2ad27b42f858"},"source":["%%writefile Codes.py\n","CODE = {\n"," 'Pump': 0,\n"," 'Spinach': 1,\n"," 'abalimi': 2,\n"," 'afukirira': 3,\n"," 'agriculture': 4,\n"," 'akammwanyi': 5,\n"," 'akamonde': 6,\n"," 'akasaanyi': 7,\n"," 'akatunda': 8,\n"," 'akatungulu': 9,\n"," 'akawuka': 10,\n"," 'amakoola': 11,\n"," 'amakungula': 12,\n"," 'amalagala': 13,\n"," 'amappapaali': 14,\n"," 'amatooke': 15,\n"," 'banana': 16,\n"," 'beans': 17,\n"," 'bibala': 18,\n"," 'bulimi': 19,\n"," 'butterfly': 20,\n"," 'cabbages': 21,\n"," 'cassava': 22,\n"," 'caterpillar': 23,\n"," 'caterpillars': 24,\n"," 'coffee': 25,\n"," 'crop': 26,\n"," 'ddagala': 27,\n"," 'dig': 28,\n"," 'disease': 29,\n"," 'doodo': 30,\n"," 'drought': 31,\n"," 'ebbugga': 32,\n"," 'ebibala': 33,\n"," 'ebigimusa': 34,\n"," 'ebijanjaalo': 35,\n"," 'ebijjanjalo': 36,\n"," 'ebikajjo': 37,\n"," 'ebikolo': 38,\n"," 'ebikongoliro': 39,\n"," 'ebikoola': 40,\n"," 'ebimera': 41,\n"," 'ebinyebwa': 42,\n"," 'ebirime': 43,\n"," 'ebisaanyi': 44,\n"," 'ebisooli': 45,\n"," 'ebisoolisooli': 46,\n"," 'ebitooke': 47,\n"," 'ebiwojjolo': 48,\n"," 'ebiwuka': 49,\n"," 'ebyobulimi': 50,\n"," 'eddagala': 51,\n"," 'eggobe': 52,\n"," 'ejjobyo': 53,\n"," 'ekibala': 54,\n"," 'ekigimusa': 55,\n"," 'ekijanjaalo': 56,\n"," 'ekikajjo': 57,\n"," 'ekikolo': 58,\n"," 'ekikoola': 59,\n"," 'ekimera': 60,\n"," 'ekirime': 61,\n"," 'ekirwadde': 62,\n"," 'ekisaanyi': 63,\n"," 'ekitooke': 64,\n"," 'ekiwojjolo': 65,\n"," 'ekyeya': 66,\n"," 'emboga': 67,\n"," 'emicungwa': 68,\n"," 'emisiri': 69,\n"," 'emiyembe': 70,\n"," 'emmwanyi': 71,\n"," 'endagala': 72,\n"," 'endokwa': 73,\n"," 'endwadde': 74,\n"," 'enkota': 75,\n"," 'ennima': 76,\n"," 'ennimiro': 77,\n"," 'ennyaanya': 78,\n"," 'ensigo': 79,\n"," 'ensiringanyi': 80,\n"," 'ensujju': 81,\n"," 'ensuku': 82,\n"," 'ensukusa': 83,\n"," 'enva endiirwa': 84,\n"," 'eppapaali': 85,\n"," 'faamu': 86,\n"," 'farm': 87,\n"," 'farmer': 88,\n"," 'farming instructor': 89,\n"," 'fertilizer': 90,\n"," 'fruit': 91,\n"," 'fruit picking': 92,\n"," 'garden': 93,\n"," 'greens': 94,\n"," 'ground nuts': 95,\n"," 'harvest': 96,\n"," 'harvesting': 97,\n"," 'insect': 98,\n"," 'insects': 99,\n"," 'irish potatoes': 100,\n"," 'irrigate': 101,\n"," 'kaamulali': 102,\n"," 'kasaanyi': 103,\n"," 'kassooli': 104,\n"," 'kikajjo': 105,\n"," 'kikolo': 106,\n"," 'kisaanyi': 107,\n"," 'kukungula': 108,\n"," 'leaf': 109,\n"," 'leaves': 110,\n"," 'lumonde': 111,\n"," 'lusuku': 112,\n"," 'maize': 113,\n"," 'maize stalk borer': 114,\n"," 'maize streak virus': 115,\n"," 'mango': 116,\n"," 'mangoes': 117,\n"," 'matooke': 118,\n"," 'matooke seedlings': 119,\n"," 'medicine': 120,\n"," 'miceere': 121,\n"," 'micungwa': 122,\n"," 'mpeke': 123,\n"," 'muceere': 124,\n"," 'mucungwa': 125,\n"," 'mulimi': 126,\n"," 'munyeera': 127,\n"," 'muwogo': 128,\n"," 'nakavundira': 129,\n"," 'nambaale': 130,\n"," 'namuginga': 131,\n"," 'ndwadde': 132,\n"," 'nfukirira': 133,\n"," 'nnakati': 134,\n"," 'nnasale beedi': 135,\n"," 'nnimiro': 136,\n"," 'nnyaanya': 137,\n"," 'npk': 138,\n"," 'nursery bed': 139,\n"," 'obulimi': 140,\n"," 'obulwadde': 141,\n"," 'obumonde': 142,\n"," 'obusaanyi': 143,\n"," 'obutunda': 144,\n"," 'obutungulu': 145,\n"," 'obuwuka': 146,\n"," 'okufukirira': 147,\n"," 'okufuuyira': 148,\n"," 'okugimusa': 149,\n"," 'okukkoola': 150,\n"," 'okukungula': 151,\n"," 'okulima': 152,\n"," 'okulimibwa': 153,\n"," 'okunnoga': 154,\n"," 'okusaasaana': 155,\n"," 'okusaasaanya': 156,\n"," 'okusiga': 157,\n"," 'okusimba': 158,\n"," 'okuzifuuyira': 159,\n"," 'olusuku': 160,\n"," 'omuceere': 161,\n"," 'omucungwa': 162,\n"," 'omulimi': 163,\n"," 'omulimisa': 164,\n"," 'omusiri': 165,\n"," 'omuyembe': 166,\n"," 'onion': 167,\n"," 'orange': 168,\n"," 'pampu': 169,\n"," 'passion fruit': 170,\n"," 'pawpaw': 171,\n"," 'pepper': 172,\n"," 'plant': 173,\n"," 'plantation': 174,\n"," 'ppaapaali': 175,\n"," 'pumpkin': 176,\n"," 'rice': 177,\n"," 'seed': 178,\n"," 'sikungula': 179,\n"," 'sow': 180,\n"," 'spray': 181,\n"," 'spread': 182,\n"," 'suckers': 183,\n"," 'sugarcane': 184,\n"," 'sukumawiki': 185,\n"," 'super grow': 186,\n"," 'sweet potatoes': 187,\n"," 'tomatoes': 188,\n"," 'vegetables': 189,\n"," 'watermelon': 190,\n"," 'weeding': 191,\n"," 'worm': 192\n","}\n","\n","INV_CODE = {v: k for k, v in CODE.items()}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Codes.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zxgzmrfTE3L","executionInfo":{"status":"ok","timestamp":1606614336534,"user_tz":-330,"elapsed":1305,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"9429f76c-c426-4b91-ac73-9e2b0034bd06"},"source":["%%writefile pytorch_utils.py\n","import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","\n","\n","def move_data_to_device(x, device):\n","    if 'float' in str(x.dtype):\n","        x = torch.Tensor(x)\n","    elif 'int' in str(x.dtype):\n","        x = torch.LongTensor(x)\n","    else:\n","        return x\n","\n","    return x.to(device)\n","\n","\n","def do_mixup(x, mixup_lambda):\n","    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n","    (1, 3, 5, ...).\n","\n","    Args:\n","      x: (batch_size * 2, ...)\n","      mixup_lambda: (batch_size * 2,)\n","\n","    Returns:\n","      out: (batch_size, ...)\n","    \"\"\"\n","    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n","        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n","    return out\n","    \n","\n","def append_to_dict(dict, key, value):\n","    if key in dict.keys():\n","        dict[key].append(value)\n","    else:\n","        dict[key] = [value]\n","\n","\n","def forward(model, generator, return_input=False, \n","    return_target=False):\n","    \"\"\"Forward data to a model.\n","    \n","    Args: \n","      model: object\n","      generator: object\n","      return_input: bool\n","      return_target: bool\n","\n","    Returns:\n","      audio_name: (audios_num,)\n","      clipwise_output: (audios_num, classes_num)\n","      (ifexist) segmentwise_output: (audios_num, segments_num, classes_num)\n","      (ifexist) framewise_output: (audios_num, frames_num, classes_num)\n","      (optional) return_input: (audios_num, segment_samples)\n","      (optional) return_target: (audios_num, classes_num)\n","    \"\"\"\n","    output_dict = {}\n","    device = next(model.parameters()).device\n","    time1 = time.time()\n","\n","    # Forward data to a model in mini-batches\n","    for n, batch_data_dict in enumerate(generator):\n","        print(n)\n","        batch_waveform = move_data_to_device(batch_data_dict['waveform'], device)\n","        \n","        with torch.no_grad():\n","            model.eval()\n","            batch_output = model(batch_waveform)\n","\n","        append_to_dict(output_dict, 'audio_name', batch_data_dict['audio_name'])\n","\n","        append_to_dict(output_dict, 'clipwise_output', \n","            batch_output['clipwise_output'].data.cpu().numpy())\n","\n","        if 'segmentwise_output' in batch_output.keys():\n","            append_to_dict(output_dict, 'segmentwise_output', \n","                batch_output['segmentwise_output'].data.cpu().numpy())\n","\n","        if 'framewise_output' in batch_output.keys():\n","            append_to_dict(output_dict, 'framewise_output', \n","                batch_output['framewise_output'].data.cpu().numpy())\n","            \n","        if return_input:\n","            append_to_dict(output_dict, 'waveform', batch_data_dict['waveform'])\n","            \n","        if return_target:\n","            if 'target' in batch_data_dict.keys():\n","                append_to_dict(output_dict, 'target', batch_data_dict['target'])\n","\n","        if n % 10 == 0:\n","            print(' --- Inference time: {:.3f} s / 10 iterations ---'.format(\n","                time.time() - time1))\n","            time1 = time.time()\n","\n","    for key in output_dict.keys():\n","        output_dict[key] = np.concatenate(output_dict[key], axis=0)\n","\n","    return output_dict\n","\n","\n","def interpolate(x, ratio):\n","    \"\"\"Interpolate data in time domain. This is used to compensate the \n","    resolution reduction in downsampling of a CNN.\n","    \n","    Args:\n","      x: (batch_size, time_steps, classes_num)\n","      ratio: int, ratio to interpolate\n","\n","    Returns:\n","      upsampled: (batch_size, time_steps * ratio, classes_num)\n","    \"\"\"\n","    (batch_size, time_steps, classes_num) = x.shape\n","    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n","    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n","    return upsampled\n","\n","\n","def pad_framewise_output(framewise_output, frames_num):\n","    \"\"\"Pad framewise_output to the same length as input frames. The pad value \n","    is the same as the value of the last frame.\n","\n","    Args:\n","      framewise_output: (batch_size, frames_num, classes_num)\n","      frames_num: int, number of frames to pad\n","\n","    Outputs:\n","      output: (batch_size, frames_num, classes_num)\n","    \"\"\"\n","    pad = framewise_output[:, -1 :, :].repeat(1, frames_num - framewise_output.shape[1], 1)\n","    \"\"\"tensor for padding\"\"\"\n","\n","    output = torch.cat((framewise_output, pad), dim=1)\n","    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n","\n","    return output\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def count_flops(model, audio_length):\n","    \"\"\"Count flops. Code modified from others' implementation.\n","    \"\"\"\n","    multiply_adds = True\n","    list_conv2d=[]\n","    def conv2d_hook(self, input, output):\n","        batch_size, input_channels, input_height, input_width = input[0].size()\n","        output_channels, output_height, output_width = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n","        bias_ops = 1 if self.bias is not None else 0\n"," \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_height * output_width\n"," \n","        list_conv2d.append(flops)\n","\n","    list_conv1d=[]\n","    def conv1d_hook(self, input, output):\n","        batch_size, input_channels, input_length = input[0].size()\n","        output_channels, output_length = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n","        bias_ops = 1 if self.bias is not None else 0\n"," \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_length\n"," \n","        list_conv1d.append(flops)\n"," \n","    list_linear=[] \n","    def linear_hook(self, input, output):\n","        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n"," \n","        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n","        bias_ops = self.bias.nelement()\n"," \n","        flops = batch_size * (weight_ops + bias_ops)\n","        list_linear.append(flops)\n"," \n","    list_bn=[] \n","    def bn_hook(self, input, output):\n","        list_bn.append(input[0].nelement() * 2)\n"," \n","    list_relu=[] \n","    def relu_hook(self, input, output):\n","        list_relu.append(input[0].nelement() * 2)\n"," \n","    list_pooling2d=[]\n","    def pooling2d_hook(self, input, output):\n","        batch_size, input_channels, input_height, input_width = input[0].size()\n","        output_channels, output_height, output_width = output[0].size()\n"," \n","        kernel_ops = self.kernel_size * self.kernel_size\n","        bias_ops = 0\n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_height * output_width\n"," \n","        list_pooling2d.append(flops)\n","\n","    list_pooling1d=[]\n","    def pooling1d_hook(self, input, output):\n","        batch_size, input_channels, input_length = input[0].size()\n","        output_channels, output_length = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0]\n","        bias_ops = 0\n","        \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_length\n"," \n","        list_pooling2d.append(flops)\n"," \n","    def foo(net):\n","        childrens = list(net.children())\n","        if not childrens:\n","            if isinstance(net, nn.Conv2d):\n","                net.register_forward_hook(conv2d_hook)\n","            elif isinstance(net, nn.Conv1d):\n","                net.register_forward_hook(conv1d_hook)\n","            elif isinstance(net, nn.Linear):\n","                net.register_forward_hook(linear_hook)\n","            elif isinstance(net, nn.BatchNorm2d) or isinstance(net, nn.BatchNorm1d):\n","                net.register_forward_hook(bn_hook)\n","            elif isinstance(net, nn.ReLU):\n","                net.register_forward_hook(relu_hook)\n","            elif isinstance(net, nn.AvgPool2d) or isinstance(net, nn.MaxPool2d):\n","                net.register_forward_hook(pooling2d_hook)\n","            elif isinstance(net, nn.AvgPool1d) or isinstance(net, nn.MaxPool1d):\n","                net.register_forward_hook(pooling1d_hook)\n","            else:\n","                print('Warning: flop of module {} is not counted!'.format(net))\n","            return\n","        for c in childrens:\n","            foo(c)\n","\n","    # Register hook\n","    foo(model)\n","    \n","    device = device = next(model.parameters()).device\n","    input = torch.rand(1, audio_length).to(device)\n","\n","    out = model(input)\n"," \n","    total_flops = sum(list_conv2d) + sum(list_conv1d) + sum(list_linear) + \\\n","        sum(list_bn) + sum(list_relu) + sum(list_pooling2d) + sum(list_pooling1d)\n","    \n","    return total_flops\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing pytorch_utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHGiEtFHTJ7w","executionInfo":{"status":"ok","timestamp":1606614340223,"user_tz":-330,"elapsed":2987,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"b77a3071-c693-4a4b-caea-3ae4ff89f92f"},"source":["%%writefile Datasets.py\n","import random, glob\n","import numpy as np, pandas as pd\n","import soundfile as sf\n","\n","import torch\n","from torch.utils.data import Dataset\n","from albumentations.pytorch.functional import img_to_tensor\n","\n","from Codes import CODE, INV_CODE\n","\n","class AudioDataset(Dataset):\n","    def __init__(self, df, period=1, transforms=None, train=True):\n","        \n","        self.period = period\n","        self.transforms = transforms\n","        self.train = train\n","\n","        self.wav_paths = df[\"fn\"].values\n","        if train:\n","            self.labels = df[\"label\"].values\n","        else:\n","            self.labels = np.zeros_like(self.wav_paths)\n","    \n","    def __len__(self):\n","        return len(self.wav_paths)\n","    \n","    def __getitem__(self, idx):\n","        wav_path, code = self.wav_paths[idx], self.labels[idx]\n","        label = np.zeros(len(CODE), dtype='f')\n","\n","        y, sr = sf.read(wav_path)\n","\n","        if self.transforms:\n","            y = self.transforms(samples=y, sample_rate=sr)\n","        \n","        len_y = len(y)\n","        effective_length = sr * self.period\n","        if len_y < effective_length:\n","            new_y = np.zeros(effective_length, dtype=y.dtype)\n","            start = np.random.randint(effective_length - len_y)\n","            new_y[start:start+len_y] = y\n","            y = new_y#.astype(np.float)\n","        elif len_y > effective_length:\n","            start = np.random.randint(len_y - effective_length)\n","            y = y[start:start + effective_length]#.astype(np.float32)\n","        else:\n","            y = y#.astype(np.float32)\n","\n","        if self.train:\n","            #label[CODE[code]] = 1\n","            label = CODE[code]\n","        else:\n","            label = 0\n","\n","        return {\n","            \"waveform\" : y, #torch.tensor(y, dtype=torch.double),\n","            \"target\" : torch.tensor(label, dtype=torch.long)\n","        }\n","    \n","    def __get_labels__(self):\n","        return self.labels"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Datasets.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylpcfWr4TNkZ","executionInfo":{"status":"ok","timestamp":1606614341870,"user_tz":-330,"elapsed":2417,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"e2e5cede-876c-48d8-98b1-7f95fa5cb2df"},"source":["%%writefile Augmentation.py\n","import audiomentations as A\n","\n","augmenter = A.Compose([\n","    A.AddGaussianNoise(p=0.4),\n","    A.AddGaussianSNR(p=0.4),\n","    #A.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n","    #A.AddImpulseResponse(p=0.1),\n","    #A.AddShortNoises(\"../input/train_audio/\", p=1)\n","    A.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.05),\n","    A.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.05),\n","    A.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n","    A.Shift(p=0.1),\n","    A.Normalize(p=0.1),\n","    A.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n","    A.PolarityInversion(p=0.05),\n","    A.Gain(p=0.2)\n","])\n","\n","test_augmenter = A.Compose([\n","    A.AddGaussianNoise(p=0.3),\n","    A.AddGaussianSNR(p=0.3),\n","    #A.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n","    #A.AddImpulseResponse(p=0.1),\n","    #A.AddShortNoises(\"../input/train_audio/\", p=1)\n","    A.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.05),\n","    A.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.05),\n","    A.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n","    A.Shift(p=0.1),\n","    A.Normalize(p=0.1),\n","    A.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n","    A.PolarityInversion(p=0.05),\n","    A.Gain(p=0.1)\n","])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Augmentation.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YwTGTAjWTYzk","executionInfo":{"status":"ok","timestamp":1606614344957,"user_tz":-330,"elapsed":3588,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"5551e433-d51c-49f1-c705-f2846cf8cbdd"},"source":["%%writefile Models.py\n","import numpy as np\n","from functools import partial\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.modules.dropout import Dropout\n","from torch.nn.modules.linear import Linear\n","from torch.nn.modules.pooling import AdaptiveAvgPool2d, AdaptiveMaxPool2d\n","\n","import timm\n","from timm.models.efficientnet import tf_efficientnet_b4_ns, tf_efficientnet_b3_ns, \\\n","    tf_efficientnet_b5_ns, tf_efficientnet_b2_ns, tf_efficientnet_b6_ns, tf_efficientnet_b7_ns, tf_efficientnet_b0_ns\n","\n","from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n","from torchlibrosa.augmentation import SpecAugmentation\n","\n","from pytorch_utils import do_mixup, interpolate, pad_framewise_output\n","\n","encoder_params = {\n","    \"resnest50d\" : {\n","        \"features\" : 2048,\n","        \"init_op\"  : partial(timm.models.resnest50d, pretrained=True, in_chans=1)\n","    },\n","    \"densenet201\" : {\n","        \"features\": 1920,\n","        \"init_op\": partial(timm.models.densenet201, pretrained=True)\n","    },\n","    \"dpn92\" : {\n","        \"features\": 2688,\n","        \"init_op\": partial(timm.models.dpn92, pretrained=True)\n","    },\n","    \"dpn131\": {\n","        \"features\": 2688,\n","        \"init_op\": partial(timm.models.dpn131, pretrained=True)\n","    },\n","    \"tf_efficientnet_b0_ns\": {\n","        \"features\": 1280,\n","        \"init_op\": partial(tf_efficientnet_b0_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b3_ns\": {\n","        \"features\": 1536,\n","        \"init_op\": partial(tf_efficientnet_b3_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b2_ns\": {\n","        \"features\": 1408,\n","        \"init_op\": partial(tf_efficientnet_b2_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b4_ns\": {\n","        \"features\": 1792,\n","        \"init_op\": partial(tf_efficientnet_b4_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b5_ns\": {\n","        \"features\": 2048,\n","        \"init_op\": partial(tf_efficientnet_b5_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b6_ns\": {\n","        \"features\": 2304,\n","        \"init_op\": partial(tf_efficientnet_b6_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b7_ns\": {\n","        \"features\": 2560,\n","        \"init_op\": partial(tf_efficientnet_b7_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","}\n","\n","\n","class AudioClassifier(nn.Module):\n","    def __init__(self, encoder, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n","        super().__init__()\n","\n","        window = 'hann'\n","        center = True\n","        pad_mode = 'reflect'\n","        ref = 1.0\n","        amin = 1e-10\n","        top_db = None\n","\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n","            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n","            freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n","            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n","            freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n","            freq_drop_width=8, freq_stripes_num=2)\n","        \n","        self.encoder = encoder_params[encoder][\"init_op\"]()\n","        self.avg_pool = AdaptiveAvgPool2d((1, 1))\n","        self.dropout = Dropout(0.3)\n","        self.fc = Linear(encoder_params[encoder]['features'], classes_num)\n","    \n","    def forward(self, input, spec_aug=False, mixup_lambda=None):\n","        #print(input.type())\n","        x = self.spectrogram_extractor(input.float()) # (batch_size, 1, time_steps, freq_bins)\n","        x = self.logmel_extractor(x) # (batch_size, 1, time_steps, mel_bins)\n","\n","        #if spec_aug:\n","        #    x = self.spec_augmenter(x)\n","        if self.training:\n","            x = self.spec_augmenter(x)\n","        \n","        # Mixup on spectrogram\n","        if mixup_lambda is not None:\n","            x = do_mixup(x, mixup_lambda)\n","            #pass\n","        \n","        x = self.encoder.forward_features(x)\n","        x = self.avg_pool(x).flatten(1)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def init_layer(layer):\n","    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n","    nn.init.xavier_uniform_(layer.weight)\n"," \n","    if hasattr(layer, 'bias'):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","            \n","    \n","def init_bn(bn):\n","    \"\"\"Initialize a Batchnorm layer. \"\"\"\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.)\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \n","        super(ConvBlock, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=in_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(3, 3), stride=(1, 1),\n","                              padding=(1, 1), bias=False)\n","                              \n","        self.conv2 = nn.Conv2d(in_channels=out_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(3, 3), stride=(1, 1),\n","                              padding=(1, 1), bias=False)\n","                              \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weight()\n","        \n","    def init_weight(self):\n","        init_layer(self.conv1)\n","        init_layer(self.conv2)\n","        init_bn(self.bn1)\n","        init_bn(self.bn2)\n","\n","        \n","    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n","        \n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        x = F.relu_(self.bn2(self.conv2(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","        \n","        return x\n","\n","\n","class ConvBlock5x5(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \n","        super(ConvBlock5x5, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=in_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(5, 5), stride=(1, 1),\n","                              padding=(2, 2), bias=False)\n","                              \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weight()\n","        \n","    def init_weight(self):\n","        init_layer(self.conv1)\n","        init_bn(self.bn1)\n","\n","        \n","    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n","        \n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","        \n","        return x\n","\n","\n","class AttBlock(nn.Module):\n","    def __init__(self, n_in, n_out, activation='linear', temperature=1.):\n","        super(AttBlock, self).__init__()\n","        \n","        self.activation = activation\n","        self.temperature = temperature\n","        self.att = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n","        self.cla = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n","        \n","        self.bn_att = nn.BatchNorm1d(n_out)\n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        init_layer(self.att)\n","        init_layer(self.cla)\n","        init_bn(self.bn_att)\n","         \n","    def forward(self, x):\n","        # x: (n_samples, n_in, n_time)\n","        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n","        cla = self.nonlinear_transform(self.cla(x))\n","        x = torch.sum(norm_att * cla, dim=2)\n","        return x, norm_att, cla\n","\n","    def nonlinear_transform(self, x):\n","        if self.activation == 'linear':\n","            return x\n","        elif self.activation == 'sigmoid':\n","            return torch.sigmoid(x)\n","\n","class Cnn14(nn.Module):\n","    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n","        fmax, classes_num):\n","        \n","        super(Cnn14, self).__init__()\n","\n","        window = 'hann'\n","        center = True\n","        pad_mode = 'reflect'\n","        ref = 1.0\n","        amin = 1e-10\n","        top_db = None\n","\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n","            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n","            freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n","            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n","            freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n","            freq_drop_width=8, freq_stripes_num=2)\n","\n","        self.bn0 = nn.BatchNorm2d(64)\n","\n","        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n","        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n","        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n","        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n","        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n","\n","        self.fc1 = nn.Linear(2048, 2048, bias=True)\n","        self.fc_audioset1 = nn.Linear(2048, classes_num, bias=True)\n","        \n","        self.init_weight()\n","\n","    def init_weight(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc1)\n","        init_layer(self.fc_audioset1)\n"," \n","    def forward(self, input, mixup_lambda=None):\n","        \"\"\"\n","        Input: (batch_size, data_length)\"\"\"\n","\n","        x = self.spectrogram_extractor(input.float())   # (batch_size, 1, time_steps, freq_bins)\n","        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","        \n","        if self.training:\n","            x = self.spec_augmenter(x)\n","\n","        # Mixup on spectrogram\n","        if self.training and mixup_lambda is not None:\n","            x = do_mixup(x, mixup_lambda)\n","\n","        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = torch.mean(x, dim=3)\n","        \n","        (x1, _) = torch.max(x, dim=2)\n","        x2 = torch.mean(x, dim=2)\n","        x = x1 + x2\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu_(self.fc1(x))\n","        #embedding = F.dropout(x, p=0.5, training=self.training)\n","        #clipwise_output = torch.sigmoid(self.fc_audioset(x))\n","        x = self.fc_audioset1(x)\n","        \n","        #output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n","\n","        return x\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Models.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ3Qtqm3ThGU","executionInfo":{"status":"ok","timestamp":1606614346479,"user_tz":-330,"elapsed":3158,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"389bf271-55b5-4dfd-a623-11141bd9bea1"},"source":["%%writefile Utils.py\n","import torch\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import log_loss\n","\n","def logloss_metric(y_true, y_pred):\n","    y_true = np.asarray(y_true).ravel()\n","    y_pred = np.asarray(y_pred).ravel()\n","    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n","    loss = np.where(y_true == 1, -np.log(y_pred), -np.log(1 - y_pred))\n","    return loss.mean()\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","class MetricMeter(object):\n","    def __init__(self):\n","        self.reset()\n","    \n","    def reset(self):\n","        self.y_true = []\n","        self.y_pred = []\n","    \n","    def update(self, y_true, y_pred):\n","        self.y_true.extend(y_true.cpu().detach().numpy().tolist())\n","        self.y_pred.extend(torch.nn.functional.softmax(y_pred).cpu().detach().numpy().tolist())\n","\n","    @property\n","    def avg(self):\n","        #self.logloss = torch.nn.CrossEntropyLoss()(torch.tensor(self.y_pred), torch.tensor(self.y_true)).item()#np.argmax(self.y_true, axis=1)\n","        self.logloss = log_loss(self.y_true, self.y_pred, labels=range(0, 193))\n","        self.acc = metrics.accuracy_score(self.y_true, np.argmax(self.y_pred, axis=1))\n","        self.f1 = metrics.f1_score(self.y_true, np.argmax(self.y_pred, axis=1), labels=range(0, 193), average=\"micro\")\n","    \n","        return {\n","            \"logloss\" : self.logloss,\n","            \"acc\" : self.acc,\n","            \"f1\" : self.f1\n","\n","        }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzqXc3o_UKds","executionInfo":{"status":"ok","timestamp":1606614347428,"user_tz":-330,"elapsed":1924,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"8a82f420-f487-4898-9d73-401b6d52546f"},"source":["%%writefile Losses.py\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Losses.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4j1jV-lRUNpf","executionInfo":{"status":"ok","timestamp":1606614347430,"user_tz":-330,"elapsed":1358,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"4f5d3993-35e9-40cc-9b6c-9ad84056794a"},"source":["%%writefile Functions.py\n","from tqdm import tqdm\n","\n","import numpy as np\n","import torch, torch.nn as nn\n","import torch.nn.functional as F\n","\n","from Utils import AverageMeter, MetricMeter\n","\n","def train_epoch(args, model, loader, criterion, optimizer, scheduler, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","\n","    model.train()\n","    #scaler = torch.cuda.amp.GradScaler()\n","\n","    t = tqdm(loader)\n","    for i, sample in enumerate(t):\n","        optimizer.zero_grad()\n","        input = sample['waveform'].to(args.device)\n","        target = sample['target'].to(args.device)\n","        #print(input.shape)\n","        #with torch.cuda.amp.autocast(enabled=args.amp):\n","        output = model(input)\n","        loss = criterion(output, target)\n","        #scaler.scale(loss).backward()\n","        #scaler.step(optimizer)\n","        #scaler.update()\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler and args.step_scheduler:\n","            scheduler.step()\n","\n","        bs = input.size(0)\n","        scores.update(target, output)\n","        losses.update(loss.item(), bs)\n","\n","        t.set_description(f\"Train E:{epoch} - Loss{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","\n","def valid_epoch(args, model, loader, criterion, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample['waveform'].to(args.device)\n","            target = sample['target'].to(args.device)\n","            output = model(input)\n","            loss = criterion(output, target)\n","\n","            bs = input.size(0)\n","            scores.update(target, output)\n","            losses.update(loss.item(), bs)\n","            t.set_description(f\"Valid E:{epoch} - Loss:{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","\n","def test_epoch(args, model, loader):\n","    model.eval()\n","    pred_list = []\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample[\"waveform\"].to(args.device)\n","            output = torch.nn.Softmax()(model(input)).cpu().detach().numpy().tolist()\n","            pred_list.extend(output)\n","    \n","    return pred_list\n","\n","def TTA_epoch(args, model, loader, ntta=10):\n","    tta_preds = []\n","    for i in range(ntta):\n","        model.eval()\n","        pred_list = []\n","        with torch.no_grad():\n","            t = tqdm(loader)\n","            for i, sample in enumerate(t):\n","                input = sample[\"waveform\"].to(args.device)\n","                output = torch.nn.Softmax()(model(input)).cpu().detach().numpy().tolist()\n","                pred_list.extend(output)\n","        tta_preds.append(pred_list)\n","    return np.mean(tta_preds, axis=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Functions.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRK1FOq6UROb","executionInfo":{"status":"ok","timestamp":1606614419770,"user_tz":-330,"elapsed":2047,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"c49b9f80-91e6-4fea-be1d-ea2054b30d8b"},"source":["%%writefile Run.py\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os, time, librosa, random\n","import numpy as np, pandas as pd\n","\n","import torch, torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import get_linear_schedule_with_warmup\n","from catalyst.data.sampler import DistributedSampler, BalanceClassSampler\n","from tqdm import tqdm\n","\n","try:\n","    import wandb\n","except:\n","    wandb = False\n","\n","import Codes\n","import Datasets\n","import Models\n","import Losses\n","import Functions\n","import Augmentation\n","\n","class args:\n","    DEBUG = False\n","    amp = False\n","    wandb = False\n","    exp_name = \"Eff7_20fold_base\"\n","    network = \"AudioClassifier\" #\"Cnn14\" #\"AudioClassifier\"\n","    encoder = None #\"ResNet38\"\n","    pretrain_weights = None #\"/content/Cnn14_mAP=0.431.pth\"\n","    model_param = {\n","        'encoder' : 'tf_efficientnet_b7_ns',\n","        'sample_rate': 32000,\n","        'window_size' : 1024,\n","        'hop_size' : 320,\n","        'mel_bins' : 64,\n","        'fmin' : 50,\n","        'fmax' : 14000,\n","        'classes_num' : 193 \n","    }\n","    losses = \"CrossEntropyLoss\" #\"BCEWithLogitsLoss\"\n","    lr = 1e-3\n","    step_scheduler = True\n","    epoch_scheduler = False\n","    period = 3\n","    seed = 24\n","    start_epoch = 0\n","    epochs = 50\n","    batch_size = 64\n","    num_workers = 2\n","    early_stop = 10\n","\n","    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n","    train_csv = \"train_20folds_seed24_df.csv\"\n","    test_csv = \"test_df.csv\"\n","    sub_csv = \"SampleSubmission.csv\"\n","    output_dir = \"/content/drive/MyDrive/ZINDI GIZ NLP Agricultural Keyword Spotter #3 place solution/weights\" # <--- update output_dir path hear\n","\n","def main(fold):\n","\n","    # Setting seed\n","    seed = args.seed\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","    args.fold = fold\n","    args.save_path = os.path.join(args.output_dir, args.exp_name)\n","    os.makedirs(args.save_path, exist_ok=True)\n","\n","    train_df = pd.read_csv(args.train_csv)\n","    test_df = pd.read_csv(args.test_csv)\n","    sub_df = pd.read_csv(args.sub_csv)\n","    if args.DEBUG:\n","        train_df = train_df.sample(1000)\n","    train_fold = train_df[train_df.kfold != fold]\n","    valid_fold = train_df[train_df.kfold == fold]\n","\n","    train_dataset = Datasets.AudioDataset(\n","        df=train_fold,\n","        period=args.period,\n","        transforms=Augmentation.augmenter,\n","        train=True\n","    )\n","    valid_dataset = Datasets.AudioDataset(\n","        df=valid_fold,\n","        period=args.period,\n","        transforms=None,\n","        train=True\n","    )\n","    test_dataset = Datasets.AudioDataset(\n","        df=test_df,\n","        period=args.period,\n","        transforms=None,\n","        train=False\n","    )\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=args.batch_size,\n","        #sampler = BalanceClassSampler(labels=train_dataset.__get_labels__(), mode=\"upsampling\"),\n","        shuffle=True,\n","        drop_last=True,\n","        num_workers=args.num_workers\n","    )\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    tta_dataset = Datasets.AudioDataset(\n","        df=test_df,\n","        period=args.period,\n","        transforms=Augmentation.test_augmenter,\n","        train=False\n","    )\n","    tta_loader = torch.utils.data.DataLoader(\n","        tta_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    model = Models.__dict__[args.network](**args.model_param)\n","    model = model.to(args.device)\n","\n","    if args.pretrain_weights:\n","        print(\"---------------------loading pretrain weights\")\n","        model.load_state_dict(torch.load(args.pretrain_weights, map_location=args.device)[\"model\"], strict=False)\n","        model = model.to(args.device)\n","\n","    criterion = Losses.__dict__[args.losses]()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n","    num_train_steps = int(len(train_loader) * args.epochs)\n","    num_warmup_steps = int(0.1 * args.epochs * len(train_loader))\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n","    \n","    best_logloss = np.inf\n","    for epoch in range(args.start_epoch, args.epochs):\n","        train_avg, train_loss = Functions.train_epoch(args, model, train_loader, criterion, optimizer, scheduler, epoch)\n","        valid_avg, valid_loss = Functions.valid_epoch(args, model, valid_loader, criterion, epoch)\n","        \n","        if args.epoch_scheduler:\n","            scheduler.step()\n","\n","        content = f\"\"\"\n","                {time.ctime()} \\n\n","                Fold:{args.fold}, Epoch:{epoch}, lr:{optimizer.param_groups[0]['lr']:.7}\\n\n","                Train Loss:{train_loss:0.4f} - LogLoss:{train_avg['logloss']:0.4f} --- ACC:{train_avg['acc']:0.4f} --- F1:{train_avg['f1']:0.4f}\\n\n","                Valid Loss:{valid_loss:0.4f} - LogLoss:{valid_avg['logloss']:0.4f} --- ACC:{valid_avg['acc']:0.4f} --- F1:{valid_avg['f1']:0.4f}\\n\n","        \"\"\"\n","        print(content)\n","        with open(f'{args.save_path}/log_{args.exp_name}.txt', 'a') as appender:\n","            appender.write(content+'\\n')\n","        \n","        if valid_avg['logloss'] < best_logloss:\n","            print(f\"########## >>>>>>>> Model Improved From {best_logloss} ----> {valid_avg['logloss']}\")\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}.bin'))\n","            best_logloss = valid_avg['logloss']\n","        torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}_last.bin'))\n","\n","    model.load_state_dict(torch.load(os.path.join(args.save_path, f'fold-{args.fold}.bin'), map_location=args.device))\n","    model = model.to(args.device)\n","\n","    target_cols = sub_df.columns.values.tolist()\n","    test_pred = Functions.test_epoch(args, model, test_loader)\n","    print(np.array(test_pred).shape)\n","    tta_pred = Functions.TTA_epoch(args, model, tta_loader, ntta=10)\n","    print(np.array(tta_pred).shape)\n","    \n","    test_pred_df = pd.DataFrame({\n","        \"fn\" : test_df.fn.values\n","    })\n","    test_pred_df[\"fn\"] = test_pred_df[\"fn\"].apply(lambda x: x.split(\"/\")[-1])\n","    test_pred_df[\"fn\"] = test_pred_df[\"fn\"].apply(lambda x: f\"audio_files/{x}\")\n","    test_pred_df[list(Codes.CODE.keys())] = test_pred\n","    test_pred_df = test_pred_df[target_cols]\n","    test_pred_df.to_csv(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"), index=False)\n","    print(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"))\n","\n","    tta_pred_df = pd.DataFrame({\n","        \"fn\" : test_df.fn.values\n","    })\n","    tta_pred_df[\"fn\"] = tta_pred_df[\"fn\"].apply(lambda x: x.split(\"/\")[-1])\n","    tta_pred_df[\"fn\"] = tta_pred_df[\"fn\"].apply(lambda x: f\"audio_files/{x}\")\n","    tta_pred_df[list(Codes.CODE.keys())] = tta_pred\n","    tta_pred_df = tta_pred_df[target_cols]\n","    tta_pred_df.to_csv(os.path.join(args.save_path, f\"tta-fold-{args.fold}-submission.csv\"), index=False)\n","    print(os.path.join(args.save_path, f\"tta-fold-{args.fold}-submission.csv\"))\n","    \n","    oof_pred = Functions.test_epoch(args, model, valid_loader)\n","    oof_pred_df = pd.DataFrame({\n","        \"fn\" : valid_fold.fn.values\n","    })\n","    oof_pred_df[list(Codes.CODE.keys())] = oof_pred\n","    oof_pred_df = oof_pred_df[target_cols]\n","    oof_pred_df.to_csv(os.path.join(args.save_path, f\"oof-fold-{args.fold}.csv\"), index=False)\n","    \n","if __name__ == \"__main__\":\n","    for fold in range(0, 20):\n","        if fold >= 0:\n","            main(fold)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting Run.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFu0YKb_rYwR","executionInfo":{"status":"ok","timestamp":1606617815406,"user_tz":-330,"elapsed":3394416,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"9b42621a-ac0d-4061-fd25-6c38e3078d39"},"source":["!python Run.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-29 01:47:04.237396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Train E:0 - Loss5.2265: 100% 69/69 [01:03<00:00,  1.08it/s]\n","Valid E:0 - Loss:5.0789: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 01:48:18 2020 \n","\n","                Fold:9, Epoch:0, lr:0.0002\n","\n","                Train Loss:5.2265 - LogLoss:5.2265 --- ACC:0.0070 --- F1:0.0070\n","\n","                Valid Loss:5.0789 - LogLoss:5.0789 --- ACC:0.0085 --- F1:0.0085\n","\n","        \n","########## >>>>>>>> Model Improved From inf ----> 5.078946798068608\n","Train E:1 - Loss5.0954: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:1 - Loss:5.0203: 100% 4/4 [00:01<00:00,  4.00it/s]\n","\n","                Sun Nov 29 01:49:25 2020 \n","\n","                Fold:9, Epoch:1, lr:0.0004\n","\n","                Train Loss:5.0954 - LogLoss:5.0954 --- ACC:0.0111 --- F1:0.0111\n","\n","                Valid Loss:5.0203 - LogLoss:5.0203 --- ACC:0.0128 --- F1:0.0128\n","\n","        \n","########## >>>>>>>> Model Improved From 5.078946798068608 ----> 5.020253940727097\n","Train E:2 - Loss5.0485: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:2 - Loss:4.8989: 100% 4/4 [00:00<00:00,  4.00it/s]\n","\n","                Sun Nov 29 01:50:32 2020 \n","\n","                Fold:9, Epoch:2, lr:0.0006\n","\n","                Train Loss:5.0485 - LogLoss:5.0485 --- ACC:0.0113 --- F1:0.0113\n","\n","                Valid Loss:4.8989 - LogLoss:4.8989 --- ACC:0.0255 --- F1:0.0255\n","\n","        \n","########## >>>>>>>> Model Improved From 5.020253940727097 ----> 4.898939612214527\n","Train E:3 - Loss4.5929: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:3 - Loss:3.8216: 100% 4/4 [00:00<00:00,  4.02it/s]\n","\n","                Sun Nov 29 01:51:39 2020 \n","\n","                Fold:9, Epoch:3, lr:0.0008\n","\n","                Train Loss:4.5929 - LogLoss:4.5929 --- ACC:0.0534 --- F1:0.0534\n","\n","                Valid Loss:3.8216 - LogLoss:3.8216 --- ACC:0.1489 --- F1:0.1489\n","\n","        \n","########## >>>>>>>> Model Improved From 4.898939612214527 ----> 3.8216233899488565\n","Train E:4 - Loss3.6401: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:4 - Loss:2.7185: 100% 4/4 [00:01<00:00,  3.88it/s]\n","\n","                Sun Nov 29 01:52:45 2020 \n","\n","                Fold:9, Epoch:4, lr:0.001\n","\n","                Train Loss:3.6401 - LogLoss:3.6401 --- ACC:0.1590 --- F1:0.1590\n","\n","                Valid Loss:2.7185 - LogLoss:2.7185 --- ACC:0.2979 --- F1:0.2979\n","\n","        \n","########## >>>>>>>> Model Improved From 3.8216233899488565 ----> 2.7185166067206024\n","Train E:5 - Loss2.7767: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:5 - Loss:1.8167: 100% 4/4 [00:01<00:00,  3.97it/s]\n","\n","                Sun Nov 29 01:53:52 2020 \n","\n","                Fold:9, Epoch:5, lr:0.0009777778\n","\n","                Train Loss:2.7767 - LogLoss:2.7767 --- ACC:0.3202 --- F1:0.3202\n","\n","                Valid Loss:1.8167 - LogLoss:1.8167 --- ACC:0.5191 --- F1:0.5191\n","\n","        \n","########## >>>>>>>> Model Improved From 2.7185166067206024 ----> 1.81665336254958\n","Train E:6 - Loss2.1362: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:6 - Loss:1.0956: 100% 4/4 [00:00<00:00,  4.02it/s]\n","\n","                Sun Nov 29 01:54:59 2020 \n","\n","                Fold:9, Epoch:6, lr:0.0009555556\n","\n","                Train Loss:2.1362 - LogLoss:2.1362 --- ACC:0.4429 --- F1:0.4429\n","\n","                Valid Loss:1.0956 - LogLoss:1.0956 --- ACC:0.7234 --- F1:0.7234\n","\n","        \n","########## >>>>>>>> Model Improved From 1.81665336254958 ----> 1.0956323886029797\n","Train E:7 - Loss1.8589: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:7 - Loss:1.0352: 100% 4/4 [00:01<00:00,  3.88it/s]\n","\n","                Sun Nov 29 01:56:06 2020 \n","\n","                Fold:9, Epoch:7, lr:0.0009333333\n","\n","                Train Loss:1.8589 - LogLoss:1.8589 --- ACC:0.5204 --- F1:0.5204\n","\n","                Valid Loss:1.0352 - LogLoss:1.0352 --- ACC:0.7234 --- F1:0.7234\n","\n","        \n","########## >>>>>>>> Model Improved From 1.0956323886029797 ----> 1.0351846468265957\n","Train E:8 - Loss1.6497: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:8 - Loss:0.7620: 100% 4/4 [00:01<00:00,  3.92it/s]\n","\n","                Sun Nov 29 01:57:12 2020 \n","\n","                Fold:9, Epoch:8, lr:0.0009111111\n","\n","                Train Loss:1.6497 - LogLoss:1.6497 --- ACC:0.5645 --- F1:0.5645\n","\n","                Valid Loss:0.7620 - LogLoss:0.7620 --- ACC:0.7745 --- F1:0.7745\n","\n","        \n","########## >>>>>>>> Model Improved From 1.0351846468265957 ----> 0.7620181579729485\n","Train E:9 - Loss1.4696: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:9 - Loss:0.7272: 100% 4/4 [00:00<00:00,  4.06it/s]\n","\n","                Sun Nov 29 01:58:18 2020 \n","\n","                Fold:9, Epoch:9, lr:0.0008888889\n","\n","                Train Loss:1.4696 - LogLoss:1.4696 --- ACC:0.6001 --- F1:0.6001\n","\n","                Valid Loss:0.7272 - LogLoss:0.7272 --- ACC:0.7872 --- F1:0.7872\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7620181579729485 ----> 0.727160687469013\n","Train E:10 - Loss1.3649: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:10 - Loss:0.8058: 100% 4/4 [00:01<00:00,  3.97it/s]\n","\n","                Sun Nov 29 01:59:25 2020 \n","\n","                Fold:9, Epoch:10, lr:0.0008666667\n","\n","                Train Loss:1.3649 - LogLoss:1.3649 --- ACC:0.6291 --- F1:0.6291\n","\n","                Valid Loss:0.8058 - LogLoss:0.8058 --- ACC:0.7915 --- F1:0.7915\n","\n","        \n","Train E:11 - Loss1.2892: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:11 - Loss:0.6492: 100% 4/4 [00:01<00:00,  3.97it/s]\n","\n","                Sun Nov 29 02:00:31 2020 \n","\n","                Fold:9, Epoch:11, lr:0.0008444444\n","\n","                Train Loss:1.2892 - LogLoss:1.2892 --- ACC:0.6549 --- F1:0.6549\n","\n","                Valid Loss:0.6492 - LogLoss:0.6492 --- ACC:0.8128 --- F1:0.8128\n","\n","        \n","########## >>>>>>>> Model Improved From 0.727160687469013 ----> 0.6492342472861515\n","Train E:12 - Loss1.1797: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:12 - Loss:0.5833: 100% 4/4 [00:00<00:00,  4.01it/s]\n","\n","                Sun Nov 29 02:01:38 2020 \n","\n","                Fold:9, Epoch:12, lr:0.0008222222\n","\n","                Train Loss:1.1797 - LogLoss:1.1797 --- ACC:0.6746 --- F1:0.6746\n","\n","                Valid Loss:0.5833 - LogLoss:0.5833 --- ACC:0.8426 --- F1:0.8426\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6492342472861515 ----> 0.5833440395793054\n","Train E:13 - Loss1.1334: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:13 - Loss:0.6092: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:02:45 2020 \n","\n","                Fold:9, Epoch:13, lr:0.0008\n","\n","                Train Loss:1.1334 - LogLoss:1.1334 --- ACC:0.6898 --- F1:0.6898\n","\n","                Valid Loss:0.6092 - LogLoss:0.6092 --- ACC:0.8383 --- F1:0.8383\n","\n","        \n","Train E:14 - Loss1.0806: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:14 - Loss:0.5886: 100% 4/4 [00:00<00:00,  4.01it/s]\n","\n","                Sun Nov 29 02:03:50 2020 \n","\n","                Fold:9, Epoch:14, lr:0.0007777778\n","\n","                Train Loss:1.0806 - LogLoss:1.0806 --- ACC:0.6943 --- F1:0.6943\n","\n","                Valid Loss:0.5886 - LogLoss:0.5886 --- ACC:0.8426 --- F1:0.8426\n","\n","        \n","Train E:15 - Loss1.0128: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:15 - Loss:0.5876: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:04:55 2020 \n","\n","                Fold:9, Epoch:15, lr:0.0007555556\n","\n","                Train Loss:1.0128 - LogLoss:1.0128 --- ACC:0.7176 --- F1:0.7176\n","\n","                Valid Loss:0.5876 - LogLoss:0.5876 --- ACC:0.8511 --- F1:0.8511\n","\n","        \n","Train E:16 - Loss1.0016: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:16 - Loss:0.4875: 100% 4/4 [00:00<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:06:00 2020 \n","\n","                Fold:9, Epoch:16, lr:0.0007333333\n","\n","                Train Loss:1.0016 - LogLoss:1.0016 --- ACC:0.7217 --- F1:0.7217\n","\n","                Valid Loss:0.4875 - LogLoss:0.4875 --- ACC:0.8681 --- F1:0.8681\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5833440395793054 ----> 0.48746963906568525\n","Train E:17 - Loss0.9503: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:17 - Loss:0.5408: 100% 4/4 [00:01<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:07:07 2020 \n","\n","                Fold:9, Epoch:17, lr:0.0007111111\n","\n","                Train Loss:0.9503 - LogLoss:0.9503 --- ACC:0.7373 --- F1:0.7373\n","\n","                Valid Loss:0.5408 - LogLoss:0.5408 --- ACC:0.8596 --- F1:0.8596\n","\n","        \n","Train E:18 - Loss0.9023: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:18 - Loss:0.4657: 100% 4/4 [00:00<00:00,  4.01it/s]\n","\n","                Sun Nov 29 02:08:12 2020 \n","\n","                Fold:9, Epoch:18, lr:0.0006888889\n","\n","                Train Loss:0.9023 - LogLoss:0.9023 --- ACC:0.7482 --- F1:0.7482\n","\n","                Valid Loss:0.4657 - LogLoss:0.4657 --- ACC:0.8851 --- F1:0.8851\n","\n","        \n","########## >>>>>>>> Model Improved From 0.48746963906568525 ----> 0.46572401914050726\n","Train E:19 - Loss0.9294: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:19 - Loss:0.5643: 100% 4/4 [00:01<00:00,  3.93it/s]\n","\n","                Sun Nov 29 02:09:18 2020 \n","\n","                Fold:9, Epoch:19, lr:0.0006666667\n","\n","                Train Loss:0.9294 - LogLoss:0.9294 --- ACC:0.7362 --- F1:0.7362\n","\n","                Valid Loss:0.5643 - LogLoss:0.5643 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:20 - Loss0.8570: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:20 - Loss:0.5132: 100% 4/4 [00:01<00:00,  3.99it/s]\n","\n","                Sun Nov 29 02:10:24 2020 \n","\n","                Fold:9, Epoch:20, lr:0.0006444444\n","\n","                Train Loss:0.8570 - LogLoss:0.8570 --- ACC:0.7559 --- F1:0.7559\n","\n","                Valid Loss:0.5132 - LogLoss:0.5132 --- ACC:0.8596 --- F1:0.8596\n","\n","        \n","Train E:21 - Loss0.8211: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:21 - Loss:0.5075: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:11:29 2020 \n","\n","                Fold:9, Epoch:21, lr:0.0006222222\n","\n","                Train Loss:0.8211 - LogLoss:0.8211 --- ACC:0.7677 --- F1:0.7677\n","\n","                Valid Loss:0.5075 - LogLoss:0.5075 --- ACC:0.8596 --- F1:0.8596\n","\n","        \n","Train E:22 - Loss0.8508: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:22 - Loss:0.4635: 100% 4/4 [00:01<00:00,  3.96it/s]\n","\n","                Sun Nov 29 02:12:33 2020 \n","\n","                Fold:9, Epoch:22, lr:0.0006\n","\n","                Train Loss:0.8508 - LogLoss:0.8508 --- ACC:0.7568 --- F1:0.7568\n","\n","                Valid Loss:0.4635 - LogLoss:0.4635 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","########## >>>>>>>> Model Improved From 0.46572401914050726 ----> 0.46350041015860566\n","Train E:23 - Loss0.7774: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:23 - Loss:0.4851: 100% 4/4 [00:00<00:00,  4.04it/s]\n","\n","                Sun Nov 29 02:13:40 2020 \n","\n","                Fold:9, Epoch:23, lr:0.0005777778\n","\n","                Train Loss:0.7774 - LogLoss:0.7774 --- ACC:0.7860 --- F1:0.7860\n","\n","                Valid Loss:0.4851 - LogLoss:0.4851 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:24 - Loss0.7742: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:24 - Loss:0.5507: 100% 4/4 [00:00<00:00,  4.04it/s]\n","\n","                Sun Nov 29 02:14:45 2020 \n","\n","                Fold:9, Epoch:24, lr:0.0005555556\n","\n","                Train Loss:0.7742 - LogLoss:0.7742 --- ACC:0.7781 --- F1:0.7781\n","\n","                Valid Loss:0.5507 - LogLoss:0.5507 --- ACC:0.8638 --- F1:0.8638\n","\n","        \n","Train E:25 - Loss0.7086: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:25 - Loss:0.4865: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:15:50 2020 \n","\n","                Fold:9, Epoch:25, lr:0.0005333333\n","\n","                Train Loss:0.7086 - LogLoss:0.7086 --- ACC:0.7919 --- F1:0.7919\n","\n","                Valid Loss:0.4865 - LogLoss:0.4865 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:26 - Loss0.7458: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:26 - Loss:0.5379: 100% 4/4 [00:01<00:00,  3.96it/s]\n","\n","                Sun Nov 29 02:16:55 2020 \n","\n","                Fold:9, Epoch:26, lr:0.0005111111\n","\n","                Train Loss:0.7458 - LogLoss:0.7458 --- ACC:0.7828 --- F1:0.7828\n","\n","                Valid Loss:0.5379 - LogLoss:0.5379 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:27 - Loss0.6856: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:27 - Loss:0.5217: 100% 4/4 [00:01<00:00,  3.96it/s]\n","\n","                Sun Nov 29 02:18:00 2020 \n","\n","                Fold:9, Epoch:27, lr:0.0004888889\n","\n","                Train Loss:0.6856 - LogLoss:0.6856 --- ACC:0.8039 --- F1:0.8039\n","\n","                Valid Loss:0.5217 - LogLoss:0.5217 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:28 - Loss0.6850: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:28 - Loss:0.5030: 100% 4/4 [00:01<00:00,  3.93it/s]\n","\n","                Sun Nov 29 02:19:05 2020 \n","\n","                Fold:9, Epoch:28, lr:0.0004666667\n","\n","                Train Loss:0.6850 - LogLoss:0.6850 --- ACC:0.7953 --- F1:0.7953\n","\n","                Valid Loss:0.5030 - LogLoss:0.5030 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:29 - Loss0.6011: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:29 - Loss:0.5292: 100% 4/4 [00:01<00:00,  3.99it/s]\n","\n","                Sun Nov 29 02:20:10 2020 \n","\n","                Fold:9, Epoch:29, lr:0.0004444444\n","\n","                Train Loss:0.6011 - LogLoss:0.6011 --- ACC:0.8184 --- F1:0.8184\n","\n","                Valid Loss:0.5292 - LogLoss:0.5292 --- ACC:0.8681 --- F1:0.8681\n","\n","        \n","Train E:30 - Loss0.6584: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:30 - Loss:0.4920: 100% 4/4 [00:01<00:00,  3.99it/s]\n","\n","                Sun Nov 29 02:21:15 2020 \n","\n","                Fold:9, Epoch:30, lr:0.0004222222\n","\n","                Train Loss:0.6584 - LogLoss:0.6584 --- ACC:0.8071 --- F1:0.8071\n","\n","                Valid Loss:0.4920 - LogLoss:0.4920 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:31 - Loss0.5964: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:31 - Loss:0.4901: 100% 4/4 [00:00<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:22:21 2020 \n","\n","                Fold:9, Epoch:31, lr:0.0004\n","\n","                Train Loss:0.5964 - LogLoss:0.5964 --- ACC:0.8254 --- F1:0.8254\n","\n","                Valid Loss:0.4901 - LogLoss:0.4901 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:32 - Loss0.6051: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:32 - Loss:0.4789: 100% 4/4 [00:00<00:00,  4.01it/s]\n","\n","                Sun Nov 29 02:23:26 2020 \n","\n","                Fold:9, Epoch:32, lr:0.0003777778\n","\n","                Train Loss:0.6051 - LogLoss:0.6051 --- ACC:0.8200 --- F1:0.8200\n","\n","                Valid Loss:0.4789 - LogLoss:0.4789 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:33 - Loss0.5451: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:33 - Loss:0.4711: 100% 4/4 [00:01<00:00,  3.86it/s]\n","\n","                Sun Nov 29 02:24:31 2020 \n","\n","                Fold:9, Epoch:33, lr:0.0003555556\n","\n","                Train Loss:0.5451 - LogLoss:0.5451 --- ACC:0.8311 --- F1:0.8311\n","\n","                Valid Loss:0.4711 - LogLoss:0.4711 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","Train E:34 - Loss0.5903: 100% 69/69 [01:01<00:00,  1.12it/s]\n","Valid E:34 - Loss:0.4993: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:25:36 2020 \n","\n","                Fold:9, Epoch:34, lr:0.0003333333\n","\n","                Train Loss:0.5903 - LogLoss:0.5903 --- ACC:0.8225 --- F1:0.8225\n","\n","                Valid Loss:0.4993 - LogLoss:0.4993 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","Train E:35 - Loss0.5756: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:35 - Loss:0.4743: 100% 4/4 [00:00<00:00,  4.02it/s]\n","\n","                Sun Nov 29 02:26:40 2020 \n","\n","                Fold:9, Epoch:35, lr:0.0003111111\n","\n","                Train Loss:0.5756 - LogLoss:0.5756 --- ACC:0.8157 --- F1:0.8157\n","\n","                Valid Loss:0.4743 - LogLoss:0.4743 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:36 - Loss0.5341: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:36 - Loss:0.5197: 100% 4/4 [00:01<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:27:45 2020 \n","\n","                Fold:9, Epoch:36, lr:0.0002888889\n","\n","                Train Loss:0.5341 - LogLoss:0.5341 --- ACC:0.8440 --- F1:0.8440\n","\n","                Valid Loss:0.5197 - LogLoss:0.5197 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:37 - Loss0.5201: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:37 - Loss:0.4818: 100% 4/4 [00:01<00:00,  3.94it/s]\n","\n","                Sun Nov 29 02:28:51 2020 \n","\n","                Fold:9, Epoch:37, lr:0.0002666667\n","\n","                Train Loss:0.5201 - LogLoss:0.5201 --- ACC:0.8388 --- F1:0.8388\n","\n","                Valid Loss:0.4818 - LogLoss:0.4818 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:38 - Loss0.5078: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:38 - Loss:0.4839: 100% 4/4 [00:01<00:00,  3.97it/s]\n","\n","                Sun Nov 29 02:29:56 2020 \n","\n","                Fold:9, Epoch:38, lr:0.0002444444\n","\n","                Train Loss:0.5078 - LogLoss:0.5078 --- ACC:0.8433 --- F1:0.8433\n","\n","                Valid Loss:0.4839 - LogLoss:0.4839 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","Train E:39 - Loss0.4765: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:39 - Loss:0.4961: 100% 4/4 [00:00<00:00,  4.01it/s]\n","\n","                Sun Nov 29 02:31:02 2020 \n","\n","                Fold:9, Epoch:39, lr:0.0002222222\n","\n","                Train Loss:0.4765 - LogLoss:0.4765 --- ACC:0.8603 --- F1:0.8603\n","\n","                Valid Loss:0.4961 - LogLoss:0.4961 --- ACC:0.9064 --- F1:0.9064\n","\n","        \n","Train E:40 - Loss0.4628: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:40 - Loss:0.4852: 100% 4/4 [00:01<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:32:07 2020 \n","\n","                Fold:9, Epoch:40, lr:0.0002\n","\n","                Train Loss:0.4628 - LogLoss:0.4628 --- ACC:0.8567 --- F1:0.8567\n","\n","                Valid Loss:0.4852 - LogLoss:0.4852 --- ACC:0.8851 --- F1:0.8851\n","\n","        \n","Train E:41 - Loss0.4667: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:41 - Loss:0.5134: 100% 4/4 [00:00<00:00,  4.02it/s]\n","\n","                Sun Nov 29 02:33:13 2020 \n","\n","                Fold:9, Epoch:41, lr:0.0001777778\n","\n","                Train Loss:0.4667 - LogLoss:0.4667 --- ACC:0.8591 --- F1:0.8591\n","\n","                Valid Loss:0.5134 - LogLoss:0.5134 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:42 - Loss0.4630: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:42 - Loss:0.5285: 100% 4/4 [00:00<00:00,  4.00it/s]\n","\n","                Sun Nov 29 02:34:18 2020 \n","\n","                Fold:9, Epoch:42, lr:0.0001555556\n","\n","                Train Loss:0.4630 - LogLoss:0.4630 --- ACC:0.8598 --- F1:0.8598\n","\n","                Valid Loss:0.5285 - LogLoss:0.5285 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:43 - Loss0.4242: 100% 69/69 [01:01<00:00,  1.11it/s]\n","Valid E:43 - Loss:0.5191: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:35:23 2020 \n","\n","                Fold:9, Epoch:43, lr:0.0001333333\n","\n","                Train Loss:0.4242 - LogLoss:0.4242 --- ACC:0.8709 --- F1:0.8709\n","\n","                Valid Loss:0.5191 - LogLoss:0.5191 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:44 - Loss0.4203: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:44 - Loss:0.5003: 100% 4/4 [00:01<00:00,  3.98it/s]\n","\n","                Sun Nov 29 02:36:28 2020 \n","\n","                Fold:9, Epoch:44, lr:0.0001111111\n","\n","                Train Loss:0.4203 - LogLoss:0.4203 --- ACC:0.8712 --- F1:0.8712\n","\n","                Valid Loss:0.5003 - LogLoss:0.5003 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:45 - Loss0.3998: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:45 - Loss:0.4902: 100% 4/4 [00:01<00:00,  3.90it/s]\n","\n","                Sun Nov 29 02:37:33 2020 \n","\n","                Fold:9, Epoch:45, lr:8.888889e-05\n","\n","                Train Loss:0.3998 - LogLoss:0.3998 --- ACC:0.8736 --- F1:0.8736\n","\n","                Valid Loss:0.4902 - LogLoss:0.4902 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:46 - Loss0.3793: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:46 - Loss:0.4479: 100% 4/4 [00:01<00:00,  3.95it/s]\n","\n","                Sun Nov 29 02:38:38 2020 \n","\n","                Fold:9, Epoch:46, lr:6.666667e-05\n","\n","                Train Loss:0.3793 - LogLoss:0.3793 --- ACC:0.8773 --- F1:0.8773\n","\n","                Valid Loss:0.4479 - LogLoss:0.4479 --- ACC:0.9064 --- F1:0.9064\n","\n","        \n","########## >>>>>>>> Model Improved From 0.46350041015860566 ----> 0.4478800682856017\n","Train E:47 - Loss0.4235: 100% 69/69 [01:02<00:00,  1.11it/s]\n","Valid E:47 - Loss:0.4492: 100% 4/4 [00:00<00:00,  4.03it/s]\n","\n","                Sun Nov 29 02:39:45 2020 \n","\n","                Fold:9, Epoch:47, lr:4.444444e-05\n","\n","                Train Loss:0.4235 - LogLoss:0.4235 --- ACC:0.8734 --- F1:0.8734\n","\n","                Valid Loss:0.4492 - LogLoss:0.4492 --- ACC:0.9064 --- F1:0.9064\n","\n","        \n","Train E:48 - Loss0.4146: 100% 69/69 [01:02<00:00,  1.10it/s]\n","Valid E:48 - Loss:0.4483: 100% 4/4 [00:01<00:00,  3.97it/s]\n","\n","                Sun Nov 29 02:40:50 2020 \n","\n","                Fold:9, Epoch:48, lr:2.222222e-05\n","\n","                Train Loss:0.4146 - LogLoss:0.4146 --- ACC:0.8698 --- F1:0.8698\n","\n","                Valid Loss:0.4483 - LogLoss:0.4483 --- ACC:0.9106 --- F1:0.9106\n","\n","        \n","Train E:49 - Loss0.3467: 100% 69/69 [01:03<00:00,  1.09it/s]\n","Valid E:49 - Loss:0.4503: 100% 4/4 [00:00<00:00,  4.02it/s]\n","\n","                Sun Nov 29 02:41:56 2020 \n","\n","                Fold:9, Epoch:49, lr:0.0\n","\n","                Train Loss:0.3467 - LogLoss:0.3467 --- ACC:0.8970 --- F1:0.8970\n","\n","                Valid Loss:0.4503 - LogLoss:0.4503 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","100% 16/16 [00:03<00:00,  4.59it/s]\n","(1017, 193)\n","100% 16/16 [00:09<00:00,  1.76it/s]\n","100% 16/16 [00:09<00:00,  1.65it/s]\n","100% 16/16 [00:08<00:00,  1.81it/s]\n","100% 16/16 [00:08<00:00,  1.80it/s]\n","100% 16/16 [00:08<00:00,  1.94it/s]\n","100% 16/16 [00:08<00:00,  1.84it/s]\n","100% 16/16 [00:08<00:00,  1.95it/s]\n","100% 16/16 [00:09<00:00,  1.72it/s]\n","100% 16/16 [00:09<00:00,  1.69it/s]\n","100% 16/16 [00:08<00:00,  1.92it/s]\n","(1017, 193)\n","/content/drive/MyDrive/ZINDI Agricultural Keyword Spotter/weights/Eff7_20fold_base/fold-9-submission.csv\n","/content/drive/MyDrive/ZINDI Agricultural Keyword Spotter/weights/Eff7_20fold_base/tta-fold-9-submission.csv\n","100% 4/4 [00:01<00:00,  3.94it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FtF9T_t47Vnc"},"source":[""],"execution_count":null,"outputs":[]}]}