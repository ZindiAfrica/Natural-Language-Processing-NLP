{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03-Eff6_20fold_base Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O7JJolruOegm"},"source":["### Eff6_20fold_base (0 to 19) folds\n","\n","- In this notebook we are using colab pro with high ram and 16gb GPU\n","- this notebook same as previus notebook 01-Eff5_20fold_base part1\n","- except encoder/model to EfficientNet-06\n","\n","#### Important points \n","- for saving outputs we need to mount drive \n","- for downloading preprocessing data we need to include kaggle.json file for kaggle API\n","- for saving outputs we need to give output path\n","- output path in `Run.py` `args` class `output_dir`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RE0b1lGqPCy7","executionInfo":{"status":"ok","timestamp":1606587070226,"user_tz":-330,"elapsed":2112,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"609036e4-1d59-45e8-bb4f-66d0c4f205fd"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Nov 28 18:11:08 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjH07ydpPoyO","executionInfo":{"status":"ok","timestamp":1606587125774,"user_tz":-330,"elapsed":53277,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"1faa4581-ad8d-4517-9450-0d2018c877e4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1_JDA_DsPwsX"},"source":["# kaggle api for download preprocessed data\n","! mkdir /root/.kaggle\n","! cp '/content/drive/My Drive/kaggle.json' /root/.kaggle\n","! chmod 400 /root/.kaggle/kaggle.json\n","\n","!pip uninstall -y kaggle >> quit\n","!pip install --upgrade pip >> quit\n","!pip install kaggle==1.5.6 >> quit\n","!kaggle -v >> quit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RD2w3OaNQAqf","executionInfo":{"status":"ok","timestamp":1606587168460,"user_tz":-330,"elapsed":57612,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"13277afd-c062-4b37-c00f-eee04da967b3"},"source":["!kaggle datasets download -d gopidurgaprasad/giz-nlp-agricultural-keyword-spotter\n","!unzip giz-nlp-agricultural-keyword-spotter.zip >> quit"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading giz-nlp-agricultural-keyword-spotter.zip to /content\n"," 99% 569M/575M [00:17<00:00, 40.0MB/s]\n","100% 575M/575M [00:17<00:00, 33.7MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8yDh-uIQZoP","executionInfo":{"status":"ok","timestamp":1606587199789,"user_tz":-330,"elapsed":81945,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"f20a2c96-934d-4673-dc59-8eca4e3618c9"},"source":["##install requred packages\n","!pip -q install timm\n","!pip -q install albumentations\n","!pip -q install soundfile\n","!pip -q install torchlibrosa\n","!pip -q install audiomentations\n","!pip -q install catalyst\n","!pip -q install transformers\n","!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 247 kB 14.2 MB/s \n","\u001b[K     |████████████████████████████████| 631 kB 14.8 MB/s \n","\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 489 kB 12.3 MB/s \n","\u001b[K     |████████████████████████████████| 159 kB 26.3 MB/s \n","\u001b[K     |████████████████████████████████| 308 kB 25.4 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 13.7 MB/s \n","\u001b[K     |████████████████████████████████| 883 kB 69.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 75.0 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 82.9 MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N4BhmjAsQzX9"},"source":["### process data and create k-folds"]},{"cell_type":"code","metadata":{"id":"tkuiGG1RQrc-"},"source":["import glob, os, random\n","import pandas as pd, numpy as np\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Suq6VHGTQ8cp","executionInfo":{"status":"ok","timestamp":1606587199795,"user_tz":-330,"elapsed":77203,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"74464002-ae97-4d63-992b-5a421e07983e"},"source":["train_wav = glob.glob(\"audio_train/input/audio_train/*/*.wav\")\n","test_wav = glob.glob(\"audio_test/input/audio_test/*.wav\")\n","print(len(train_wav), len(test_wav))\n","\n","train_df = pd.DataFrame({\n","    \"fn\" : train_wav\n","}).sort_values(\"fn\")\n","train_df[\"label\"] = train_df.fn.apply(lambda x: x.split(\"/\")[-2])\n","\n","test_df = pd.DataFrame({\n","    \"fn\" : test_wav\n","}).sort_values(\"fn\")\n","\n","print(train_df.shape, test_df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4709 1017\n","(4709, 2) (1017, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpDtvNaeR-Je","executionInfo":{"status":"ok","timestamp":1606587199798,"user_tz":-330,"elapsed":74570,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"0cb316f7-0802-408c-c820-779a0f25d6b7"},"source":["FOLDS = 20\n","SEED = 42\n","\n","train_df.loc[:, 'kfold'] = -1\n","train_df = train_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","X = train_df['fn'].values\n","y = train_df['label'].values\n","kfold = StratifiedKFold(n_splits=FOLDS)\n","for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n","    train_df.loc[v_idx, \"kfold\"] = fold\n","print(train_df.kfold.value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0     236\n","4     236\n","7     236\n","3     236\n","8     236\n","6     236\n","2     236\n","1     236\n","5     236\n","9     235\n","12    235\n","16    235\n","19    235\n","13    235\n","15    235\n","10    235\n","14    235\n","18    235\n","11    235\n","17    235\n","Name: kfold, dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=20.\n","  % (min_groups, self.n_splits)), UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PyAIDfpgSqvc"},"source":["train_df.to_csv(\"train_20folds_seed42_df.csv\", index=False)\n","test_df.to_csv(\"test_df.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqorozP9S7vx","executionInfo":{"status":"ok","timestamp":1606587202467,"user_tz":-330,"elapsed":73305,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"730e5919-09f4-4c45-f8d0-765d171f3e59"},"source":["%%writefile Codes.py\n","CODE = {\n"," 'Pump': 0,\n"," 'Spinach': 1,\n"," 'abalimi': 2,\n"," 'afukirira': 3,\n"," 'agriculture': 4,\n"," 'akammwanyi': 5,\n"," 'akamonde': 6,\n"," 'akasaanyi': 7,\n"," 'akatunda': 8,\n"," 'akatungulu': 9,\n"," 'akawuka': 10,\n"," 'amakoola': 11,\n"," 'amakungula': 12,\n"," 'amalagala': 13,\n"," 'amappapaali': 14,\n"," 'amatooke': 15,\n"," 'banana': 16,\n"," 'beans': 17,\n"," 'bibala': 18,\n"," 'bulimi': 19,\n"," 'butterfly': 20,\n"," 'cabbages': 21,\n"," 'cassava': 22,\n"," 'caterpillar': 23,\n"," 'caterpillars': 24,\n"," 'coffee': 25,\n"," 'crop': 26,\n"," 'ddagala': 27,\n"," 'dig': 28,\n"," 'disease': 29,\n"," 'doodo': 30,\n"," 'drought': 31,\n"," 'ebbugga': 32,\n"," 'ebibala': 33,\n"," 'ebigimusa': 34,\n"," 'ebijanjaalo': 35,\n"," 'ebijjanjalo': 36,\n"," 'ebikajjo': 37,\n"," 'ebikolo': 38,\n"," 'ebikongoliro': 39,\n"," 'ebikoola': 40,\n"," 'ebimera': 41,\n"," 'ebinyebwa': 42,\n"," 'ebirime': 43,\n"," 'ebisaanyi': 44,\n"," 'ebisooli': 45,\n"," 'ebisoolisooli': 46,\n"," 'ebitooke': 47,\n"," 'ebiwojjolo': 48,\n"," 'ebiwuka': 49,\n"," 'ebyobulimi': 50,\n"," 'eddagala': 51,\n"," 'eggobe': 52,\n"," 'ejjobyo': 53,\n"," 'ekibala': 54,\n"," 'ekigimusa': 55,\n"," 'ekijanjaalo': 56,\n"," 'ekikajjo': 57,\n"," 'ekikolo': 58,\n"," 'ekikoola': 59,\n"," 'ekimera': 60,\n"," 'ekirime': 61,\n"," 'ekirwadde': 62,\n"," 'ekisaanyi': 63,\n"," 'ekitooke': 64,\n"," 'ekiwojjolo': 65,\n"," 'ekyeya': 66,\n"," 'emboga': 67,\n"," 'emicungwa': 68,\n"," 'emisiri': 69,\n"," 'emiyembe': 70,\n"," 'emmwanyi': 71,\n"," 'endagala': 72,\n"," 'endokwa': 73,\n"," 'endwadde': 74,\n"," 'enkota': 75,\n"," 'ennima': 76,\n"," 'ennimiro': 77,\n"," 'ennyaanya': 78,\n"," 'ensigo': 79,\n"," 'ensiringanyi': 80,\n"," 'ensujju': 81,\n"," 'ensuku': 82,\n"," 'ensukusa': 83,\n"," 'enva endiirwa': 84,\n"," 'eppapaali': 85,\n"," 'faamu': 86,\n"," 'farm': 87,\n"," 'farmer': 88,\n"," 'farming instructor': 89,\n"," 'fertilizer': 90,\n"," 'fruit': 91,\n"," 'fruit picking': 92,\n"," 'garden': 93,\n"," 'greens': 94,\n"," 'ground nuts': 95,\n"," 'harvest': 96,\n"," 'harvesting': 97,\n"," 'insect': 98,\n"," 'insects': 99,\n"," 'irish potatoes': 100,\n"," 'irrigate': 101,\n"," 'kaamulali': 102,\n"," 'kasaanyi': 103,\n"," 'kassooli': 104,\n"," 'kikajjo': 105,\n"," 'kikolo': 106,\n"," 'kisaanyi': 107,\n"," 'kukungula': 108,\n"," 'leaf': 109,\n"," 'leaves': 110,\n"," 'lumonde': 111,\n"," 'lusuku': 112,\n"," 'maize': 113,\n"," 'maize stalk borer': 114,\n"," 'maize streak virus': 115,\n"," 'mango': 116,\n"," 'mangoes': 117,\n"," 'matooke': 118,\n"," 'matooke seedlings': 119,\n"," 'medicine': 120,\n"," 'miceere': 121,\n"," 'micungwa': 122,\n"," 'mpeke': 123,\n"," 'muceere': 124,\n"," 'mucungwa': 125,\n"," 'mulimi': 126,\n"," 'munyeera': 127,\n"," 'muwogo': 128,\n"," 'nakavundira': 129,\n"," 'nambaale': 130,\n"," 'namuginga': 131,\n"," 'ndwadde': 132,\n"," 'nfukirira': 133,\n"," 'nnakati': 134,\n"," 'nnasale beedi': 135,\n"," 'nnimiro': 136,\n"," 'nnyaanya': 137,\n"," 'npk': 138,\n"," 'nursery bed': 139,\n"," 'obulimi': 140,\n"," 'obulwadde': 141,\n"," 'obumonde': 142,\n"," 'obusaanyi': 143,\n"," 'obutunda': 144,\n"," 'obutungulu': 145,\n"," 'obuwuka': 146,\n"," 'okufukirira': 147,\n"," 'okufuuyira': 148,\n"," 'okugimusa': 149,\n"," 'okukkoola': 150,\n"," 'okukungula': 151,\n"," 'okulima': 152,\n"," 'okulimibwa': 153,\n"," 'okunnoga': 154,\n"," 'okusaasaana': 155,\n"," 'okusaasaanya': 156,\n"," 'okusiga': 157,\n"," 'okusimba': 158,\n"," 'okuzifuuyira': 159,\n"," 'olusuku': 160,\n"," 'omuceere': 161,\n"," 'omucungwa': 162,\n"," 'omulimi': 163,\n"," 'omulimisa': 164,\n"," 'omusiri': 165,\n"," 'omuyembe': 166,\n"," 'onion': 167,\n"," 'orange': 168,\n"," 'pampu': 169,\n"," 'passion fruit': 170,\n"," 'pawpaw': 171,\n"," 'pepper': 172,\n"," 'plant': 173,\n"," 'plantation': 174,\n"," 'ppaapaali': 175,\n"," 'pumpkin': 176,\n"," 'rice': 177,\n"," 'seed': 178,\n"," 'sikungula': 179,\n"," 'sow': 180,\n"," 'spray': 181,\n"," 'spread': 182,\n"," 'suckers': 183,\n"," 'sugarcane': 184,\n"," 'sukumawiki': 185,\n"," 'super grow': 186,\n"," 'sweet potatoes': 187,\n"," 'tomatoes': 188,\n"," 'vegetables': 189,\n"," 'watermelon': 190,\n"," 'weeding': 191,\n"," 'worm': 192\n","}\n","\n","INV_CODE = {v: k for k, v in CODE.items()}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Codes.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zxgzmrfTE3L","executionInfo":{"status":"ok","timestamp":1606587202469,"user_tz":-330,"elapsed":72248,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"fc2d10b2-fe0c-4dba-e635-5913e10bc6a5"},"source":["%%writefile pytorch_utils.py\n","import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","\n","\n","def move_data_to_device(x, device):\n","    if 'float' in str(x.dtype):\n","        x = torch.Tensor(x)\n","    elif 'int' in str(x.dtype):\n","        x = torch.LongTensor(x)\n","    else:\n","        return x\n","\n","    return x.to(device)\n","\n","\n","def do_mixup(x, mixup_lambda):\n","    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n","    (1, 3, 5, ...).\n","\n","    Args:\n","      x: (batch_size * 2, ...)\n","      mixup_lambda: (batch_size * 2,)\n","\n","    Returns:\n","      out: (batch_size, ...)\n","    \"\"\"\n","    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n","        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n","    return out\n","    \n","\n","def append_to_dict(dict, key, value):\n","    if key in dict.keys():\n","        dict[key].append(value)\n","    else:\n","        dict[key] = [value]\n","\n","\n","def forward(model, generator, return_input=False, \n","    return_target=False):\n","    \"\"\"Forward data to a model.\n","    \n","    Args: \n","      model: object\n","      generator: object\n","      return_input: bool\n","      return_target: bool\n","\n","    Returns:\n","      audio_name: (audios_num,)\n","      clipwise_output: (audios_num, classes_num)\n","      (ifexist) segmentwise_output: (audios_num, segments_num, classes_num)\n","      (ifexist) framewise_output: (audios_num, frames_num, classes_num)\n","      (optional) return_input: (audios_num, segment_samples)\n","      (optional) return_target: (audios_num, classes_num)\n","    \"\"\"\n","    output_dict = {}\n","    device = next(model.parameters()).device\n","    time1 = time.time()\n","\n","    # Forward data to a model in mini-batches\n","    for n, batch_data_dict in enumerate(generator):\n","        print(n)\n","        batch_waveform = move_data_to_device(batch_data_dict['waveform'], device)\n","        \n","        with torch.no_grad():\n","            model.eval()\n","            batch_output = model(batch_waveform)\n","\n","        append_to_dict(output_dict, 'audio_name', batch_data_dict['audio_name'])\n","\n","        append_to_dict(output_dict, 'clipwise_output', \n","            batch_output['clipwise_output'].data.cpu().numpy())\n","\n","        if 'segmentwise_output' in batch_output.keys():\n","            append_to_dict(output_dict, 'segmentwise_output', \n","                batch_output['segmentwise_output'].data.cpu().numpy())\n","\n","        if 'framewise_output' in batch_output.keys():\n","            append_to_dict(output_dict, 'framewise_output', \n","                batch_output['framewise_output'].data.cpu().numpy())\n","            \n","        if return_input:\n","            append_to_dict(output_dict, 'waveform', batch_data_dict['waveform'])\n","            \n","        if return_target:\n","            if 'target' in batch_data_dict.keys():\n","                append_to_dict(output_dict, 'target', batch_data_dict['target'])\n","\n","        if n % 10 == 0:\n","            print(' --- Inference time: {:.3f} s / 10 iterations ---'.format(\n","                time.time() - time1))\n","            time1 = time.time()\n","\n","    for key in output_dict.keys():\n","        output_dict[key] = np.concatenate(output_dict[key], axis=0)\n","\n","    return output_dict\n","\n","\n","def interpolate(x, ratio):\n","    \"\"\"Interpolate data in time domain. This is used to compensate the \n","    resolution reduction in downsampling of a CNN.\n","    \n","    Args:\n","      x: (batch_size, time_steps, classes_num)\n","      ratio: int, ratio to interpolate\n","\n","    Returns:\n","      upsampled: (batch_size, time_steps * ratio, classes_num)\n","    \"\"\"\n","    (batch_size, time_steps, classes_num) = x.shape\n","    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n","    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n","    return upsampled\n","\n","\n","def pad_framewise_output(framewise_output, frames_num):\n","    \"\"\"Pad framewise_output to the same length as input frames. The pad value \n","    is the same as the value of the last frame.\n","\n","    Args:\n","      framewise_output: (batch_size, frames_num, classes_num)\n","      frames_num: int, number of frames to pad\n","\n","    Outputs:\n","      output: (batch_size, frames_num, classes_num)\n","    \"\"\"\n","    pad = framewise_output[:, -1 :, :].repeat(1, frames_num - framewise_output.shape[1], 1)\n","    \"\"\"tensor for padding\"\"\"\n","\n","    output = torch.cat((framewise_output, pad), dim=1)\n","    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n","\n","    return output\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def count_flops(model, audio_length):\n","    \"\"\"Count flops. Code modified from others' implementation.\n","    \"\"\"\n","    multiply_adds = True\n","    list_conv2d=[]\n","    def conv2d_hook(self, input, output):\n","        batch_size, input_channels, input_height, input_width = input[0].size()\n","        output_channels, output_height, output_width = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n","        bias_ops = 1 if self.bias is not None else 0\n"," \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_height * output_width\n"," \n","        list_conv2d.append(flops)\n","\n","    list_conv1d=[]\n","    def conv1d_hook(self, input, output):\n","        batch_size, input_channels, input_length = input[0].size()\n","        output_channels, output_length = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0] * (self.in_channels / self.groups) * (2 if multiply_adds else 1)\n","        bias_ops = 1 if self.bias is not None else 0\n"," \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_length\n"," \n","        list_conv1d.append(flops)\n"," \n","    list_linear=[] \n","    def linear_hook(self, input, output):\n","        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n"," \n","        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n","        bias_ops = self.bias.nelement()\n"," \n","        flops = batch_size * (weight_ops + bias_ops)\n","        list_linear.append(flops)\n"," \n","    list_bn=[] \n","    def bn_hook(self, input, output):\n","        list_bn.append(input[0].nelement() * 2)\n"," \n","    list_relu=[] \n","    def relu_hook(self, input, output):\n","        list_relu.append(input[0].nelement() * 2)\n"," \n","    list_pooling2d=[]\n","    def pooling2d_hook(self, input, output):\n","        batch_size, input_channels, input_height, input_width = input[0].size()\n","        output_channels, output_height, output_width = output[0].size()\n"," \n","        kernel_ops = self.kernel_size * self.kernel_size\n","        bias_ops = 0\n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_height * output_width\n"," \n","        list_pooling2d.append(flops)\n","\n","    list_pooling1d=[]\n","    def pooling1d_hook(self, input, output):\n","        batch_size, input_channels, input_length = input[0].size()\n","        output_channels, output_length = output[0].size()\n"," \n","        kernel_ops = self.kernel_size[0]\n","        bias_ops = 0\n","        \n","        params = output_channels * (kernel_ops + bias_ops)\n","        flops = batch_size * params * output_length\n"," \n","        list_pooling2d.append(flops)\n"," \n","    def foo(net):\n","        childrens = list(net.children())\n","        if not childrens:\n","            if isinstance(net, nn.Conv2d):\n","                net.register_forward_hook(conv2d_hook)\n","            elif isinstance(net, nn.Conv1d):\n","                net.register_forward_hook(conv1d_hook)\n","            elif isinstance(net, nn.Linear):\n","                net.register_forward_hook(linear_hook)\n","            elif isinstance(net, nn.BatchNorm2d) or isinstance(net, nn.BatchNorm1d):\n","                net.register_forward_hook(bn_hook)\n","            elif isinstance(net, nn.ReLU):\n","                net.register_forward_hook(relu_hook)\n","            elif isinstance(net, nn.AvgPool2d) or isinstance(net, nn.MaxPool2d):\n","                net.register_forward_hook(pooling2d_hook)\n","            elif isinstance(net, nn.AvgPool1d) or isinstance(net, nn.MaxPool1d):\n","                net.register_forward_hook(pooling1d_hook)\n","            else:\n","                print('Warning: flop of module {} is not counted!'.format(net))\n","            return\n","        for c in childrens:\n","            foo(c)\n","\n","    # Register hook\n","    foo(model)\n","    \n","    device = device = next(model.parameters()).device\n","    input = torch.rand(1, audio_length).to(device)\n","\n","    out = model(input)\n"," \n","    total_flops = sum(list_conv2d) + sum(list_conv1d) + sum(list_linear) + \\\n","        sum(list_bn) + sum(list_relu) + sum(list_pooling2d) + sum(list_pooling1d)\n","    \n","    return total_flops\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing pytorch_utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHGiEtFHTJ7w","executionInfo":{"status":"ok","timestamp":1606587202471,"user_tz":-330,"elapsed":70821,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"e11fdf04-5fb5-4036-f69e-490d1283f20f"},"source":["%%writefile Datasets.py\n","import random, glob\n","import numpy as np, pandas as pd\n","import soundfile as sf\n","\n","import torch\n","from torch.utils.data import Dataset\n","from albumentations.pytorch.functional import img_to_tensor\n","\n","from Codes import CODE, INV_CODE\n","\n","class AudioDataset(Dataset):\n","    def __init__(self, df, period=1, transforms=None, train=True):\n","        \n","        self.period = period\n","        self.transforms = transforms\n","        self.train = train\n","\n","        self.wav_paths = df[\"fn\"].values\n","        if train:\n","            self.labels = df[\"label\"].values\n","        else:\n","            self.labels = np.zeros_like(self.wav_paths)\n","    \n","    def __len__(self):\n","        return len(self.wav_paths)\n","    \n","    def __getitem__(self, idx):\n","        wav_path, code = self.wav_paths[idx], self.labels[idx]\n","        label = np.zeros(len(CODE), dtype='f')\n","\n","        y, sr = sf.read(wav_path)\n","\n","        if self.transforms:\n","            y = self.transforms(samples=y, sample_rate=sr)\n","        \n","        len_y = len(y)\n","        effective_length = sr * self.period\n","        if len_y < effective_length:\n","            new_y = np.zeros(effective_length, dtype=y.dtype)\n","            start = np.random.randint(effective_length - len_y)\n","            new_y[start:start+len_y] = y\n","            y = new_y#.astype(np.float)\n","        elif len_y > effective_length:\n","            start = np.random.randint(len_y - effective_length)\n","            y = y[start:start + effective_length]#.astype(np.float32)\n","        else:\n","            y = y#.astype(np.float32)\n","\n","        if self.train:\n","            #label[CODE[code]] = 1\n","            label = CODE[code]\n","        else:\n","            label = 0\n","\n","        return {\n","            \"waveform\" : y, #torch.tensor(y, dtype=torch.double),\n","            \"target\" : torch.tensor(label, dtype=torch.long)\n","        }\n","    \n","    def __get_labels__(self):\n","        return self.labels"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Datasets.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylpcfWr4TNkZ","executionInfo":{"status":"ok","timestamp":1606587202474,"user_tz":-330,"elapsed":68829,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"2a7ad1a3-e9dd-49dd-f3db-b124543d4634"},"source":["%%writefile Augmentation.py\n","import audiomentations as A\n","\n","augmenter = A.Compose([\n","    A.AddGaussianNoise(p=0.4),\n","    A.AddGaussianSNR(p=0.4),\n","    #A.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n","    #A.AddImpulseResponse(p=0.1),\n","    #A.AddShortNoises(\"../input/train_audio/\", p=1)\n","    A.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.05),\n","    A.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.05),\n","    A.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n","    A.Shift(p=0.1),\n","    A.Normalize(p=0.1),\n","    A.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n","    A.PolarityInversion(p=0.05),\n","    A.Gain(p=0.2)\n","])\n","\n","test_augmenter = A.Compose([\n","    A.AddGaussianNoise(p=0.3),\n","    A.AddGaussianSNR(p=0.3),\n","    #A.AddBackgroundNoise(\"../input/train_audio/\", p=1)\n","    #A.AddImpulseResponse(p=0.1),\n","    #A.AddShortNoises(\"../input/train_audio/\", p=1)\n","    A.FrequencyMask(min_frequency_band=0.0,  max_frequency_band=0.2, p=0.05),\n","    A.TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.05),\n","    A.PitchShift(min_semitones=-0.5, max_semitones=0.5, p=0.05),\n","    A.Shift(p=0.1),\n","    A.Normalize(p=0.1),\n","    A.ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=1, p=0.05),\n","    A.PolarityInversion(p=0.05),\n","    A.Gain(p=0.1)\n","])\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Augmentation.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YwTGTAjWTYzk","executionInfo":{"status":"ok","timestamp":1606587202476,"user_tz":-330,"elapsed":67169,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"eede4737-8347-4e50-9e78-1b81e53bdfde"},"source":["%%writefile Models.py\n","import numpy as np\n","from functools import partial\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.modules.dropout import Dropout\n","from torch.nn.modules.linear import Linear\n","from torch.nn.modules.pooling import AdaptiveAvgPool2d, AdaptiveMaxPool2d\n","\n","import timm\n","from timm.models.efficientnet import tf_efficientnet_b4_ns, tf_efficientnet_b3_ns, \\\n","    tf_efficientnet_b5_ns, tf_efficientnet_b2_ns, tf_efficientnet_b6_ns, tf_efficientnet_b7_ns, tf_efficientnet_b0_ns\n","\n","from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n","from torchlibrosa.augmentation import SpecAugmentation\n","\n","from pytorch_utils import do_mixup, interpolate, pad_framewise_output\n","\n","encoder_params = {\n","    \"resnest50d\" : {\n","        \"features\" : 2048,\n","        \"init_op\"  : partial(timm.models.resnest50d, pretrained=True, in_chans=1)\n","    },\n","    \"densenet201\" : {\n","        \"features\": 1920,\n","        \"init_op\": partial(timm.models.densenet201, pretrained=True)\n","    },\n","    \"dpn92\" : {\n","        \"features\": 2688,\n","        \"init_op\": partial(timm.models.dpn92, pretrained=True)\n","    },\n","    \"dpn131\": {\n","        \"features\": 2688,\n","        \"init_op\": partial(timm.models.dpn131, pretrained=True)\n","    },\n","    \"tf_efficientnet_b0_ns\": {\n","        \"features\": 1280,\n","        \"init_op\": partial(tf_efficientnet_b0_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b3_ns\": {\n","        \"features\": 1536,\n","        \"init_op\": partial(tf_efficientnet_b3_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b2_ns\": {\n","        \"features\": 1408,\n","        \"init_op\": partial(tf_efficientnet_b2_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b4_ns\": {\n","        \"features\": 1792,\n","        \"init_op\": partial(tf_efficientnet_b4_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b5_ns\": {\n","        \"features\": 2048,\n","        \"init_op\": partial(tf_efficientnet_b5_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","    \"tf_efficientnet_b6_ns\": {\n","        \"features\": 2304,\n","        \"init_op\": partial(tf_efficientnet_b6_ns, pretrained=True, drop_path_rate=0.2, in_chans=1)\n","    },\n","}\n","\n","\n","class AudioClassifier(nn.Module):\n","    def __init__(self, encoder, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n","        super().__init__()\n","\n","        window = 'hann'\n","        center = True\n","        pad_mode = 'reflect'\n","        ref = 1.0\n","        amin = 1e-10\n","        top_db = None\n","\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n","            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n","            freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n","            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n","            freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n","            freq_drop_width=8, freq_stripes_num=2)\n","        \n","        self.encoder = encoder_params[encoder][\"init_op\"]()\n","        self.avg_pool = AdaptiveAvgPool2d((1, 1))\n","        self.dropout = Dropout(0.3)\n","        self.fc = Linear(encoder_params[encoder]['features'], classes_num)\n","    \n","    def forward(self, input, spec_aug=False, mixup_lambda=None):\n","        #print(input.type())\n","        x = self.spectrogram_extractor(input.float()) # (batch_size, 1, time_steps, freq_bins)\n","        x = self.logmel_extractor(x) # (batch_size, 1, time_steps, mel_bins)\n","\n","        #if spec_aug:\n","        #    x = self.spec_augmenter(x)\n","        if self.training:\n","            x = self.spec_augmenter(x)\n","        \n","        # Mixup on spectrogram\n","        if mixup_lambda is not None:\n","            x = do_mixup(x, mixup_lambda)\n","            #pass\n","        \n","        x = self.encoder.forward_features(x)\n","        x = self.avg_pool(x).flatten(1)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def init_layer(layer):\n","    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n","    nn.init.xavier_uniform_(layer.weight)\n"," \n","    if hasattr(layer, 'bias'):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","            \n","    \n","def init_bn(bn):\n","    \"\"\"Initialize a Batchnorm layer. \"\"\"\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.)\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \n","        super(ConvBlock, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=in_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(3, 3), stride=(1, 1),\n","                              padding=(1, 1), bias=False)\n","                              \n","        self.conv2 = nn.Conv2d(in_channels=out_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(3, 3), stride=(1, 1),\n","                              padding=(1, 1), bias=False)\n","                              \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weight()\n","        \n","    def init_weight(self):\n","        init_layer(self.conv1)\n","        init_layer(self.conv2)\n","        init_bn(self.bn1)\n","        init_bn(self.bn2)\n","\n","        \n","    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n","        \n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        x = F.relu_(self.bn2(self.conv2(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","        \n","        return x\n","\n","\n","class ConvBlock5x5(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        \n","        super(ConvBlock5x5, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=in_channels, \n","                              out_channels=out_channels,\n","                              kernel_size=(5, 5), stride=(1, 1),\n","                              padding=(2, 2), bias=False)\n","                              \n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weight()\n","        \n","    def init_weight(self):\n","        init_layer(self.conv1)\n","        init_bn(self.bn1)\n","\n","        \n","    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n","        \n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","        \n","        return x\n","\n","\n","class AttBlock(nn.Module):\n","    def __init__(self, n_in, n_out, activation='linear', temperature=1.):\n","        super(AttBlock, self).__init__()\n","        \n","        self.activation = activation\n","        self.temperature = temperature\n","        self.att = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n","        self.cla = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n","        \n","        self.bn_att = nn.BatchNorm1d(n_out)\n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        init_layer(self.att)\n","        init_layer(self.cla)\n","        init_bn(self.bn_att)\n","         \n","    def forward(self, x):\n","        # x: (n_samples, n_in, n_time)\n","        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n","        cla = self.nonlinear_transform(self.cla(x))\n","        x = torch.sum(norm_att * cla, dim=2)\n","        return x, norm_att, cla\n","\n","    def nonlinear_transform(self, x):\n","        if self.activation == 'linear':\n","            return x\n","        elif self.activation == 'sigmoid':\n","            return torch.sigmoid(x)\n","\n","class Cnn14(nn.Module):\n","    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n","        fmax, classes_num):\n","        \n","        super(Cnn14, self).__init__()\n","\n","        window = 'hann'\n","        center = True\n","        pad_mode = 'reflect'\n","        ref = 1.0\n","        amin = 1e-10\n","        top_db = None\n","\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n","            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n","            freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n","            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n","            freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n","            freq_drop_width=8, freq_stripes_num=2)\n","\n","        self.bn0 = nn.BatchNorm2d(64)\n","\n","        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n","        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n","        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n","        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n","        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n","\n","        self.fc1 = nn.Linear(2048, 2048, bias=True)\n","        self.fc_audioset1 = nn.Linear(2048, classes_num, bias=True)\n","        \n","        self.init_weight()\n","\n","    def init_weight(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc1)\n","        init_layer(self.fc_audioset1)\n"," \n","    def forward(self, input, mixup_lambda=None):\n","        \"\"\"\n","        Input: (batch_size, data_length)\"\"\"\n","\n","        x = self.spectrogram_extractor(input.float())   # (batch_size, 1, time_steps, freq_bins)\n","        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","        \n","        if self.training:\n","            x = self.spec_augmenter(x)\n","\n","        # Mixup on spectrogram\n","        if self.training and mixup_lambda is not None:\n","            x = do_mixup(x, mixup_lambda)\n","\n","        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = torch.mean(x, dim=3)\n","        \n","        (x1, _) = torch.max(x, dim=2)\n","        x2 = torch.mean(x, dim=2)\n","        x = x1 + x2\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu_(self.fc1(x))\n","        #embedding = F.dropout(x, p=0.5, training=self.training)\n","        #clipwise_output = torch.sigmoid(self.fc_audioset(x))\n","        x = self.fc_audioset1(x)\n","        \n","        #output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n","\n","        return x\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Models.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ3Qtqm3ThGU","executionInfo":{"status":"ok","timestamp":1606587202483,"user_tz":-330,"elapsed":64506,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"5f4aa0a9-eda6-47f6-9249-48e6c1dfe286"},"source":["%%writefile Utils.py\n","import torch\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import log_loss\n","\n","def logloss_metric(y_true, y_pred):\n","    y_true = np.asarray(y_true).ravel()\n","    y_pred = np.asarray(y_pred).ravel()\n","    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n","    loss = np.where(y_true == 1, -np.log(y_pred), -np.log(1 - y_pred))\n","    return loss.mean()\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","class MetricMeter(object):\n","    def __init__(self):\n","        self.reset()\n","    \n","    def reset(self):\n","        self.y_true = []\n","        self.y_pred = []\n","    \n","    def update(self, y_true, y_pred):\n","        self.y_true.extend(y_true.cpu().detach().numpy().tolist())\n","        self.y_pred.extend(torch.nn.functional.softmax(y_pred).cpu().detach().numpy().tolist())\n","\n","    @property\n","    def avg(self):\n","        #self.logloss = torch.nn.CrossEntropyLoss()(torch.tensor(self.y_pred), torch.tensor(self.y_true)).item()#np.argmax(self.y_true, axis=1)\n","        self.logloss = log_loss(self.y_true, self.y_pred, labels=range(0, 193))\n","        self.acc = metrics.accuracy_score(self.y_true, np.argmax(self.y_pred, axis=1))\n","        self.f1 = metrics.f1_score(self.y_true, np.argmax(self.y_pred, axis=1), labels=range(0, 193), average=\"micro\")\n","    \n","        return {\n","            \"logloss\" : self.logloss,\n","            \"acc\" : self.acc,\n","            \"f1\" : self.f1\n","\n","        }"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzqXc3o_UKds","executionInfo":{"status":"ok","timestamp":1606587202486,"user_tz":-330,"elapsed":62347,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"d62b4d81-6957-4568-c051-d19b5932f6a6"},"source":["%%writefile Losses.py\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Losses.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4j1jV-lRUNpf","executionInfo":{"status":"ok","timestamp":1606587202488,"user_tz":-330,"elapsed":61458,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"4e61486e-9449-4b96-bd9d-ff00b5ba1033"},"source":["%%writefile Functions.py\n","from tqdm import tqdm\n","\n","import numpy as np\n","import torch, torch.nn as nn\n","import torch.nn.functional as F\n","\n","from Utils import AverageMeter, MetricMeter\n","\n","def train_epoch(args, model, loader, criterion, optimizer, scheduler, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","\n","    model.train()\n","    #scaler = torch.cuda.amp.GradScaler()\n","\n","    t = tqdm(loader)\n","    for i, sample in enumerate(t):\n","        optimizer.zero_grad()\n","        input = sample['waveform'].to(args.device)\n","        target = sample['target'].to(args.device)\n","        #print(input.shape)\n","        #with torch.cuda.amp.autocast(enabled=args.amp):\n","        output = model(input)\n","        loss = criterion(output, target)\n","        #scaler.scale(loss).backward()\n","        #scaler.step(optimizer)\n","        #scaler.update()\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler and args.step_scheduler:\n","            scheduler.step()\n","\n","        bs = input.size(0)\n","        scores.update(target, output)\n","        losses.update(loss.item(), bs)\n","\n","        t.set_description(f\"Train E:{epoch} - Loss{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","\n","def valid_epoch(args, model, loader, criterion, epoch):\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample['waveform'].to(args.device)\n","            target = sample['target'].to(args.device)\n","            output = model(input)\n","            loss = criterion(output, target)\n","\n","            bs = input.size(0)\n","            scores.update(target, output)\n","            losses.update(loss.item(), bs)\n","            t.set_description(f\"Valid E:{epoch} - Loss:{losses.avg:0.4f}\")\n","    t.close()\n","    return scores.avg, losses.avg\n","\n","def test_epoch(args, model, loader):\n","    model.eval()\n","    pred_list = []\n","    with torch.no_grad():\n","        t = tqdm(loader)\n","        for i, sample in enumerate(t):\n","            input = sample[\"waveform\"].to(args.device)\n","            output = torch.nn.Softmax()(model(input)).cpu().detach().numpy().tolist()\n","            pred_list.extend(output)\n","    \n","    return pred_list\n","\n","def TTA_epoch(args, model, loader, ntta=10):\n","    tta_preds = []\n","    for i in range(ntta):\n","        model.eval()\n","        pred_list = []\n","        with torch.no_grad():\n","            t = tqdm(loader)\n","            for i, sample in enumerate(t):\n","                input = sample[\"waveform\"].to(args.device)\n","                output = torch.nn.Softmax()(model(input)).cpu().detach().numpy().tolist()\n","                pred_list.extend(output)\n","        tta_preds.append(pred_list)\n","    return np.mean(tta_preds, axis=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing Functions.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRK1FOq6UROb","executionInfo":{"status":"ok","timestamp":1606562354451,"user_tz":-330,"elapsed":3615,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"ed1708c4-4437-4961-a201-471b9d02e36b"},"source":["%%writefile Run.py\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os, time, librosa, random\n","import numpy as np, pandas as pd\n","\n","import torch, torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import get_linear_schedule_with_warmup\n","from catalyst.data.sampler import DistributedSampler, BalanceClassSampler\n","from tqdm import tqdm\n","\n","try:\n","    import wandb\n","except:\n","    wandb = False\n","\n","import Codes\n","import Datasets\n","import Models\n","import Losses\n","import Functions\n","import Augmentation\n","\n","class args:\n","    DEBUG = False\n","    amp = False\n","    wandb = False\n","    exp_name = \"Eff6_20fold_base\"\n","    network = \"AudioClassifier\" #\"Cnn14\" #\"AudioClassifier\"\n","    encoder = \"ResNet38\"\n","    pretrain_weights = None #\"/content/Cnn14_mAP=0.431.pth\"\n","    model_param = {\n","        'encoder' : 'tf_efficientnet_b6_ns',\n","        'sample_rate': 32000,\n","        'window_size' : 1024,\n","        'hop_size' : 320,\n","        'mel_bins' : 64,\n","        'fmin' : 50,\n","        'fmax' : 14000,\n","        'classes_num' : 193 \n","    }\n","    losses = \"CrossEntropyLoss\" #\"BCEWithLogitsLoss\"\n","    lr = 1e-3\n","    step_scheduler = True\n","    epoch_scheduler = False\n","    period = 3\n","    seed = 42\n","    start_epoch = 0\n","    epochs = 50\n","    batch_size = 64\n","    num_workers = 2\n","    early_stop = 10\n","\n","    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n","    train_csv = \"train_20folds_seed42_df.csv\"\n","    test_csv = \"test_df.csv\"\n","    sub_csv = \"SampleSubmission.csv\"\n","    output_dir = \"/content/drive/MyDrive/ZINDI GIZ NLP Agricultural Keyword Spotter #3 place solution/weights\"\n","\n","def main(fold):\n","\n","    # Setting seed\n","    seed = args.seed\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","    args.fold = fold\n","    args.save_path = os.path.join(args.output_dir, args.exp_name)\n","    os.makedirs(args.save_path, exist_ok=True)\n","\n","    train_df = pd.read_csv(args.train_csv)\n","    test_df = pd.read_csv(args.test_csv)\n","    sub_df = pd.read_csv(args.sub_csv)\n","    if args.DEBUG:\n","        train_df = train_df.sample(1000)\n","    train_fold = train_df[train_df.kfold != fold]\n","    valid_fold = train_df[train_df.kfold == fold]\n","\n","    train_dataset = Datasets.AudioDataset(\n","        df=train_fold,\n","        period=args.period,\n","        transforms=Augmentation.augmenter,\n","        train=True\n","    )\n","    valid_dataset = Datasets.AudioDataset(\n","        df=valid_fold,\n","        period=args.period,\n","        transforms=None,\n","        train=True\n","    )\n","    test_dataset = Datasets.AudioDataset(\n","        df=test_df,\n","        period=args.period,\n","        transforms=None,\n","        train=False\n","    )\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=args.batch_size,\n","        #sampler = BalanceClassSampler(labels=train_dataset.__get_labels__(), mode=\"upsampling\"),\n","        shuffle=True,\n","        drop_last=True,\n","        num_workers=args.num_workers\n","    )\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    tta_dataset = Datasets.AudioDataset(\n","        df=test_df,\n","        period=args.period,\n","        transforms=Augmentation.test_augmenter,\n","        train=False\n","    )\n","    tta_loader = torch.utils.data.DataLoader(\n","        tta_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        drop_last=False,\n","        num_workers=args.num_workers\n","    )\n","\n","    model = Models.__dict__[args.network](**args.model_param)\n","    model = model.to(args.device)\n","\n","    if args.pretrain_weights:\n","        print(\"---------------------loading pretrain weights\")\n","        model.load_state_dict(torch.load(args.pretrain_weights, map_location=args.device)[\"model\"], strict=False)\n","        model = model.to(args.device)\n","\n","    criterion = Losses.__dict__[args.losses]()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n","    num_train_steps = int(len(train_loader) * args.epochs)\n","    num_warmup_steps = int(0.1 * args.epochs * len(train_loader))\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n","    \n","    best_logloss = np.inf\n","    for epoch in range(args.start_epoch, args.epochs):\n","        train_avg, train_loss = Functions.train_epoch(args, model, train_loader, criterion, optimizer, scheduler, epoch)\n","        valid_avg, valid_loss = Functions.valid_epoch(args, model, valid_loader, criterion, epoch)\n","        \n","        if args.epoch_scheduler:\n","            scheduler.step()\n","\n","        content = f\"\"\"\n","                {time.ctime()} \\n\n","                Fold:{args.fold}, Epoch:{epoch}, lr:{optimizer.param_groups[0]['lr']:.7}\\n\n","                Train Loss:{train_loss:0.4f} - LogLoss:{train_avg['logloss']:0.4f} --- ACC:{train_avg['acc']:0.4f} --- F1:{train_avg['f1']:0.4f}\\n\n","                Valid Loss:{valid_loss:0.4f} - LogLoss:{valid_avg['logloss']:0.4f} --- ACC:{valid_avg['acc']:0.4f} --- F1:{valid_avg['f1']:0.4f}\\n\n","        \"\"\"\n","        print(content)\n","        with open(f'{args.save_path}/log_{args.exp_name}.txt', 'a') as appender:\n","            appender.write(content+'\\n')\n","        \n","        if valid_avg['logloss'] < best_logloss:\n","            print(f\"########## >>>>>>>> Model Improved From {best_logloss} ----> {valid_avg['logloss']}\")\n","            torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}.bin'))\n","            best_logloss = valid_avg['logloss']\n","        #torch.save(model.state_dict(), os.path.join(args.save_path, f'fold-{args.fold}_last.bin'))\n","\n","    model.load_state_dict(torch.load(os.path.join(args.save_path, f'fold-{args.fold}.bin'), map_location=args.device))\n","    model = model.to(args.device)\n","\n","    target_cols = sub_df.columns.values.tolist()\n","    test_pred = Functions.test_epoch(args, model, test_loader)\n","    print(np.array(test_pred).shape)\n","    tta_pred = Functions.TTA_epoch(args, model, tta_loader, ntta=10)\n","    print(np.array(tta_pred).shape)\n","    \n","    test_pred_df = pd.DataFrame({\n","        \"fn\" : test_df.fn.values\n","    })\n","    test_pred_df[\"fn\"] = test_pred_df[\"fn\"].apply(lambda x: x.split(\"/\")[-1])\n","    test_pred_df[\"fn\"] = test_pred_df[\"fn\"].apply(lambda x: f\"audio_files/{x}\")\n","    test_pred_df[list(Codes.CODE.keys())] = test_pred\n","    test_pred_df = test_pred_df[target_cols]\n","    test_pred_df.to_csv(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"), index=False)\n","    print(os.path.join(args.save_path, f\"fold-{args.fold}-submission.csv\"))\n","\n","    tta_pred_df = pd.DataFrame({\n","        \"fn\" : test_df.fn.values\n","    })\n","    tta_pred_df[\"fn\"] = tta_pred_df[\"fn\"].apply(lambda x: x.split(\"/\")[-1])\n","    tta_pred_df[\"fn\"] = tta_pred_df[\"fn\"].apply(lambda x: f\"audio_files/{x}\")\n","    tta_pred_df[list(Codes.CODE.keys())] = tta_pred\n","    tta_pred_df = tta_pred_df[target_cols]\n","    tta_pred_df.to_csv(os.path.join(args.save_path, f\"tta-fold-{args.fold}-submission.csv\"), index=False)\n","    print(os.path.join(args.save_path, f\"tta-fold-{args.fold}-submission.csv\"))\n","    \n","    oof_pred = Functions.test_epoch(args, model, valid_loader)\n","    oof_pred_df = pd.DataFrame({\n","        \"fn\" : valid_fold.fn.values\n","    })\n","    oof_pred_df[list(Codes.CODE.keys())] = oof_pred\n","    oof_pred_df = oof_pred_df[target_cols]\n","    oof_pred_df.to_csv(os.path.join(args.save_path, f\"oof-fold-{args.fold}.csv\"), index=False)\n","    \n","if __name__ == \"__main__\":\n","    for fold in range(0, 20):\n","        if fold >= 0:\n","            main(fold)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting Run.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnGn5rEJJdQ4","executionInfo":{"status":"ok","timestamp":1606564960323,"user_tz":-330,"elapsed":2607459,"user":{"displayName":"kaggle ai","photoUrl":"","userId":"18291610024750681979"}},"outputId":"3acd99a6-3242-470d-c81a-e5fea8103760"},"source":["!python Run.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-11-28 11:19:16.021900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Train E:0 - Loss5.2150: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:0 - Loss:5.1091: 100% 4/4 [00:00<00:00,  4.82it/s]\n","\n","                Sat Nov 28 11:20:14 2020 \n","\n","                Fold:17, Epoch:0, lr:0.0002\n","\n","                Train Loss:5.2150 - LogLoss:5.2150 --- ACC:0.0075 --- F1:0.0075\n","\n","                Valid Loss:5.1091 - LogLoss:5.1091 --- ACC:0.0085 --- F1:0.0085\n","\n","        \n","########## >>>>>>>> Model Improved From inf ----> 5.109109647084766\n","Train E:1 - Loss5.0779: 100% 69/69 [00:47<00:00,  1.44it/s]\n","Valid E:1 - Loss:5.0239: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:21:03 2020 \n","\n","                Fold:17, Epoch:1, lr:0.0004\n","\n","                Train Loss:5.0779 - LogLoss:5.0779 --- ACC:0.0115 --- F1:0.0115\n","\n","                Valid Loss:5.0239 - LogLoss:5.0239 --- ACC:0.0213 --- F1:0.0213\n","\n","        \n","########## >>>>>>>> Model Improved From 5.109109647084766 ----> 5.023863179192261\n","Train E:2 - Loss5.0416: 100% 69/69 [00:47<00:00,  1.44it/s]\n","Valid E:2 - Loss:4.8429: 100% 4/4 [00:00<00:00,  4.76it/s]\n","\n","                Sat Nov 28 11:21:53 2020 \n","\n","                Fold:17, Epoch:2, lr:0.0006\n","\n","                Train Loss:5.0416 - LogLoss:5.0416 --- ACC:0.0091 --- F1:0.0091\n","\n","                Valid Loss:4.8429 - LogLoss:4.8429 --- ACC:0.0213 --- F1:0.0213\n","\n","        \n","########## >>>>>>>> Model Improved From 5.023863179192261 ----> 4.842924465663708\n","Train E:3 - Loss4.6646: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:3 - Loss:3.8580: 100% 4/4 [00:00<00:00,  4.82it/s]\n","\n","                Sat Nov 28 11:22:43 2020 \n","\n","                Fold:17, Epoch:3, lr:0.0008\n","\n","                Train Loss:4.6646 - LogLoss:4.6646 --- ACC:0.0480 --- F1:0.0480\n","\n","                Valid Loss:3.8580 - LogLoss:3.8580 --- ACC:0.0766 --- F1:0.0766\n","\n","        \n","########## >>>>>>>> Model Improved From 4.842924465663708 ----> 3.858022793420724\n","Train E:4 - Loss3.7197: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:4 - Loss:2.7870: 100% 4/4 [00:00<00:00,  4.77it/s]\n","\n","                Sat Nov 28 11:23:34 2020 \n","\n","                Fold:17, Epoch:4, lr:0.001\n","\n","                Train Loss:3.7197 - LogLoss:3.7197 --- ACC:0.1508 --- F1:0.1508\n","\n","                Valid Loss:2.7870 - LogLoss:2.7870 --- ACC:0.3234 --- F1:0.3234\n","\n","        \n","########## >>>>>>>> Model Improved From 3.858022793420724 ----> 2.7870018702630177\n","Train E:5 - Loss2.8704: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:5 - Loss:1.7810: 100% 4/4 [00:00<00:00,  4.84it/s]\n","\n","                Sat Nov 28 11:24:24 2020 \n","\n","                Fold:17, Epoch:5, lr:0.0009777778\n","\n","                Train Loss:2.8704 - LogLoss:2.8704 --- ACC:0.2883 --- F1:0.2883\n","\n","                Valid Loss:1.7810 - LogLoss:1.7810 --- ACC:0.5660 --- F1:0.5660\n","\n","        \n","########## >>>>>>>> Model Improved From 2.7870018702630177 ----> 1.780983469277906\n","Train E:6 - Loss2.2507: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:6 - Loss:1.3384: 100% 4/4 [00:00<00:00,  4.82it/s]\n","\n","                Sat Nov 28 11:25:15 2020 \n","\n","                Fold:17, Epoch:6, lr:0.0009555556\n","\n","                Train Loss:2.2507 - LogLoss:2.2507 --- ACC:0.4221 --- F1:0.4221\n","\n","                Valid Loss:1.3384 - LogLoss:1.3384 --- ACC:0.6255 --- F1:0.6255\n","\n","        \n","########## >>>>>>>> Model Improved From 1.780983469277906 ----> 1.3383514031367232\n","Train E:7 - Loss1.9169: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:7 - Loss:0.9916: 100% 4/4 [00:00<00:00,  4.72it/s]\n","\n","                Sat Nov 28 11:26:05 2020 \n","\n","                Fold:17, Epoch:7, lr:0.0009333333\n","\n","                Train Loss:1.9169 - LogLoss:1.9169 --- ACC:0.4995 --- F1:0.4995\n","\n","                Valid Loss:0.9916 - LogLoss:0.9916 --- ACC:0.7489 --- F1:0.7489\n","\n","        \n","########## >>>>>>>> Model Improved From 1.3383514031367232 ----> 0.9916007760800138\n","Train E:8 - Loss1.6725: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:8 - Loss:0.8827: 100% 4/4 [00:00<00:00,  4.84it/s]\n","\n","                Sat Nov 28 11:26:55 2020 \n","\n","                Fold:17, Epoch:8, lr:0.0009111111\n","\n","                Train Loss:1.6725 - LogLoss:1.6725 --- ACC:0.5555 --- F1:0.5555\n","\n","                Valid Loss:0.8827 - LogLoss:0.8827 --- ACC:0.7660 --- F1:0.7660\n","\n","        \n","########## >>>>>>>> Model Improved From 0.9916007760800138 ----> 0.8826682704809289\n","Train E:9 - Loss1.5517: 100% 69/69 [00:49<00:00,  1.41it/s]\n","Valid E:9 - Loss:0.7757: 100% 4/4 [00:00<00:00,  4.74it/s]\n","\n","                Sat Nov 28 11:27:46 2020 \n","\n","                Fold:17, Epoch:9, lr:0.0008888889\n","\n","                Train Loss:1.5517 - LogLoss:1.5517 --- ACC:0.5851 --- F1:0.5851\n","\n","                Valid Loss:0.7757 - LogLoss:0.7757 --- ACC:0.8000 --- F1:0.8000\n","\n","        \n","########## >>>>>>>> Model Improved From 0.8826682704809289 ----> 0.7757439420078445\n","Train E:10 - Loss1.4258: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:10 - Loss:0.7193: 100% 4/4 [00:00<00:00,  4.87it/s]\n","\n","                Sat Nov 28 11:28:37 2020 \n","\n","                Fold:17, Epoch:10, lr:0.0008666667\n","\n","                Train Loss:1.4258 - LogLoss:1.4258 --- ACC:0.6125 --- F1:0.6125\n","\n","                Valid Loss:0.7193 - LogLoss:0.7193 --- ACC:0.7915 --- F1:0.7915\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7757439420078445 ----> 0.7193347005629838\n","Train E:11 - Loss1.3043: 100% 69/69 [00:49<00:00,  1.39it/s]\n","Valid E:11 - Loss:0.6780: 100% 4/4 [00:00<00:00,  4.81it/s]\n","\n","                Sat Nov 28 11:29:29 2020 \n","\n","                Fold:17, Epoch:11, lr:0.0008444444\n","\n","                Train Loss:1.3043 - LogLoss:1.3043 --- ACC:0.6442 --- F1:0.6442\n","\n","                Valid Loss:0.6780 - LogLoss:0.6780 --- ACC:0.8213 --- F1:0.8213\n","\n","        \n","########## >>>>>>>> Model Improved From 0.7193347005629838 ----> 0.6779668605555251\n","Train E:12 - Loss1.2425: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:12 - Loss:0.6153: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:30:19 2020 \n","\n","                Fold:17, Epoch:12, lr:0.0008222222\n","\n","                Train Loss:1.2425 - LogLoss:1.2425 --- ACC:0.6601 --- F1:0.6601\n","\n","                Valid Loss:0.6153 - LogLoss:0.6153 --- ACC:0.8340 --- F1:0.8340\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6779668605555251 ----> 0.6152746132383007\n","Train E:13 - Loss1.1676: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:13 - Loss:0.5934: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:31:10 2020 \n","\n","                Fold:17, Epoch:13, lr:0.0008\n","\n","                Train Loss:1.1676 - LogLoss:1.1676 --- ACC:0.6787 --- F1:0.6787\n","\n","                Valid Loss:0.5934 - LogLoss:0.5934 --- ACC:0.8468 --- F1:0.8468\n","\n","        \n","########## >>>>>>>> Model Improved From 0.6152746132383007 ----> 0.5934438318699354\n","Train E:14 - Loss1.0859: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:14 - Loss:0.6601: 100% 4/4 [00:00<00:00,  4.87it/s]\n","\n","                Sat Nov 28 11:32:01 2020 \n","\n","                Fold:17, Epoch:14, lr:0.0007777778\n","\n","                Train Loss:1.0859 - LogLoss:1.0859 --- ACC:0.6957 --- F1:0.6957\n","\n","                Valid Loss:0.6601 - LogLoss:0.6601 --- ACC:0.8553 --- F1:0.8553\n","\n","        \n","Train E:15 - Loss1.0704: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:15 - Loss:0.5889: 100% 4/4 [00:00<00:00,  4.84it/s]\n","\n","                Sat Nov 28 11:32:50 2020 \n","\n","                Fold:17, Epoch:15, lr:0.0007555556\n","\n","                Train Loss:1.0704 - LogLoss:1.0704 --- ACC:0.7004 --- F1:0.7004\n","\n","                Valid Loss:0.5889 - LogLoss:0.5889 --- ACC:0.8638 --- F1:0.8638\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5934438318699354 ----> 0.5889146495037545\n","Train E:16 - Loss1.0498: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:16 - Loss:0.6020: 100% 4/4 [00:00<00:00,  4.74it/s]\n","\n","                Sat Nov 28 11:33:41 2020 \n","\n","                Fold:17, Epoch:16, lr:0.0007333333\n","\n","                Train Loss:1.0498 - LogLoss:1.0498 --- ACC:0.6972 --- F1:0.6972\n","\n","                Valid Loss:0.6020 - LogLoss:0.6020 --- ACC:0.8638 --- F1:0.8638\n","\n","        \n","Train E:17 - Loss0.9715: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:17 - Loss:0.5608: 100% 4/4 [00:00<00:00,  4.78it/s]\n","\n","                Sat Nov 28 11:34:31 2020 \n","\n","                Fold:17, Epoch:17, lr:0.0007111111\n","\n","                Train Loss:0.9715 - LogLoss:0.9715 --- ACC:0.7242 --- F1:0.7242\n","\n","                Valid Loss:0.5608 - LogLoss:0.5608 --- ACC:0.8468 --- F1:0.8468\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5889146495037545 ----> 0.5607662253569434\n","Train E:18 - Loss0.9390: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:18 - Loss:0.6218: 100% 4/4 [00:00<00:00,  4.75it/s]\n","\n","                Sat Nov 28 11:35:21 2020 \n","\n","                Fold:17, Epoch:18, lr:0.0006888889\n","\n","                Train Loss:0.9390 - LogLoss:0.9390 --- ACC:0.7332 --- F1:0.7332\n","\n","                Valid Loss:0.6218 - LogLoss:0.6218 --- ACC:0.8511 --- F1:0.8511\n","\n","        \n","Train E:19 - Loss0.8948: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:19 - Loss:0.4815: 100% 4/4 [00:00<00:00,  4.74it/s]\n","\n","                Sat Nov 28 11:36:12 2020 \n","\n","                Fold:17, Epoch:19, lr:0.0006666667\n","\n","                Train Loss:0.8948 - LogLoss:0.8948 --- ACC:0.7477 --- F1:0.7477\n","\n","                Valid Loss:0.4815 - LogLoss:0.4815 --- ACC:0.8766 --- F1:0.8766\n","\n","        \n","########## >>>>>>>> Model Improved From 0.5607662253569434 ----> 0.48149069694015495\n","Train E:20 - Loss0.9102: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:20 - Loss:0.4744: 100% 4/4 [00:00<00:00,  4.71it/s]\n","\n","                Sat Nov 28 11:37:03 2020 \n","\n","                Fold:17, Epoch:20, lr:0.0006444444\n","\n","                Train Loss:0.9102 - LogLoss:0.9102 --- ACC:0.7328 --- F1:0.7328\n","\n","                Valid Loss:0.4744 - LogLoss:0.4744 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","########## >>>>>>>> Model Improved From 0.48149069694015495 ----> 0.47440233319095537\n","Train E:21 - Loss0.8259: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:21 - Loss:0.5967: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:37:53 2020 \n","\n","                Fold:17, Epoch:21, lr:0.0006222222\n","\n","                Train Loss:0.8259 - LogLoss:0.8259 --- ACC:0.7659 --- F1:0.7659\n","\n","                Valid Loss:0.5967 - LogLoss:0.5967 --- ACC:0.8553 --- F1:0.8553\n","\n","        \n","Train E:22 - Loss0.8117: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:22 - Loss:0.5370: 100% 4/4 [00:00<00:00,  4.61it/s]\n","\n","                Sat Nov 28 11:38:43 2020 \n","\n","                Fold:17, Epoch:22, lr:0.0006\n","\n","                Train Loss:0.8117 - LogLoss:0.8117 --- ACC:0.7665 --- F1:0.7665\n","\n","                Valid Loss:0.5370 - LogLoss:0.5370 --- ACC:0.8681 --- F1:0.8681\n","\n","        \n","Train E:23 - Loss0.7917: 100% 69/69 [00:47<00:00,  1.44it/s]\n","Valid E:23 - Loss:0.4622: 100% 4/4 [00:00<00:00,  4.80it/s]\n","\n","                Sat Nov 28 11:39:32 2020 \n","\n","                Fold:17, Epoch:23, lr:0.0005777778\n","\n","                Train Loss:0.7917 - LogLoss:0.7917 --- ACC:0.7722 --- F1:0.7722\n","\n","                Valid Loss:0.4622 - LogLoss:0.4622 --- ACC:0.8723 --- F1:0.8723\n","\n","        \n","########## >>>>>>>> Model Improved From 0.47440233319095537 ----> 0.46217308996583106\n","Train E:24 - Loss0.7780: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:24 - Loss:0.4827: 100% 4/4 [00:00<00:00,  4.76it/s]\n","\n","                Sat Nov 28 11:40:23 2020 \n","\n","                Fold:17, Epoch:24, lr:0.0005555556\n","\n","                Train Loss:0.7780 - LogLoss:0.7780 --- ACC:0.7720 --- F1:0.7720\n","\n","                Valid Loss:0.4827 - LogLoss:0.4827 --- ACC:0.8723 --- F1:0.8723\n","\n","        \n","Train E:25 - Loss0.7656: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:25 - Loss:0.4773: 100% 4/4 [00:00<00:00,  4.71it/s]\n","\n","                Sat Nov 28 11:41:12 2020 \n","\n","                Fold:17, Epoch:25, lr:0.0005333333\n","\n","                Train Loss:0.7656 - LogLoss:0.7656 --- ACC:0.7758 --- F1:0.7758\n","\n","                Valid Loss:0.4773 - LogLoss:0.4773 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:26 - Loss0.7266: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:26 - Loss:0.4793: 100% 4/4 [00:00<00:00,  4.69it/s]\n","\n","                Sat Nov 28 11:42:02 2020 \n","\n","                Fold:17, Epoch:26, lr:0.0005111111\n","\n","                Train Loss:0.7266 - LogLoss:0.7266 --- ACC:0.7905 --- F1:0.7905\n","\n","                Valid Loss:0.4793 - LogLoss:0.4793 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:27 - Loss0.7314: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:27 - Loss:0.5748: 100% 4/4 [00:00<00:00,  4.75it/s]\n","\n","                Sat Nov 28 11:42:52 2020 \n","\n","                Fold:17, Epoch:27, lr:0.0004888889\n","\n","                Train Loss:0.7314 - LogLoss:0.7314 --- ACC:0.7865 --- F1:0.7865\n","\n","                Valid Loss:0.5748 - LogLoss:0.5748 --- ACC:0.8723 --- F1:0.8723\n","\n","        \n","Train E:28 - Loss0.7088: 100% 69/69 [00:47<00:00,  1.45it/s]\n","Valid E:28 - Loss:0.4432: 100% 4/4 [00:00<00:00,  4.69it/s]\n","\n","                Sat Nov 28 11:43:40 2020 \n","\n","                Fold:17, Epoch:28, lr:0.0004666667\n","\n","                Train Loss:0.7088 - LogLoss:0.7088 --- ACC:0.7966 --- F1:0.7966\n","\n","                Valid Loss:0.4432 - LogLoss:0.4432 --- ACC:0.8766 --- F1:0.8766\n","\n","        \n","########## >>>>>>>> Model Improved From 0.46217308996583106 ----> 0.443192085354708\n","Train E:29 - Loss0.6617: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:29 - Loss:0.5254: 100% 4/4 [00:00<00:00,  4.81it/s]\n","\n","                Sat Nov 28 11:44:31 2020 \n","\n","                Fold:17, Epoch:29, lr:0.0004444444\n","\n","                Train Loss:0.6617 - LogLoss:0.6617 --- ACC:0.8093 --- F1:0.8093\n","\n","                Valid Loss:0.5254 - LogLoss:0.5254 --- ACC:0.8809 --- F1:0.8809\n","\n","        \n","Train E:30 - Loss0.6335: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:30 - Loss:0.5154: 100% 4/4 [00:00<00:00,  4.71it/s]\n","\n","                Sat Nov 28 11:45:21 2020 \n","\n","                Fold:17, Epoch:30, lr:0.0004222222\n","\n","                Train Loss:0.6335 - LogLoss:0.6335 --- ACC:0.8125 --- F1:0.8125\n","\n","                Valid Loss:0.5154 - LogLoss:0.5154 --- ACC:0.8851 --- F1:0.8851\n","\n","        \n","Train E:31 - Loss0.6225: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:31 - Loss:0.5127: 100% 4/4 [00:00<00:00,  4.76it/s]\n","\n","                Sat Nov 28 11:46:11 2020 \n","\n","                Fold:17, Epoch:31, lr:0.0004\n","\n","                Train Loss:0.6225 - LogLoss:0.6225 --- ACC:0.8184 --- F1:0.8184\n","\n","                Valid Loss:0.5127 - LogLoss:0.5127 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:32 - Loss0.5958: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:32 - Loss:0.5324: 100% 4/4 [00:00<00:00,  4.71it/s]\n","\n","                Sat Nov 28 11:47:00 2020 \n","\n","                Fold:17, Epoch:32, lr:0.0003777778\n","\n","                Train Loss:0.5958 - LogLoss:0.5958 --- ACC:0.8202 --- F1:0.8202\n","\n","                Valid Loss:0.5324 - LogLoss:0.5324 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:33 - Loss0.6287: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:33 - Loss:0.5613: 100% 4/4 [00:00<00:00,  4.70it/s]\n","\n","                Sat Nov 28 11:47:50 2020 \n","\n","                Fold:17, Epoch:33, lr:0.0003555556\n","\n","                Train Loss:0.6287 - LogLoss:0.6287 --- ACC:0.8120 --- F1:0.8120\n","\n","                Valid Loss:0.5613 - LogLoss:0.5613 --- ACC:0.8681 --- F1:0.8681\n","\n","        \n","Train E:34 - Loss0.6069: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:34 - Loss:0.4903: 100% 4/4 [00:00<00:00,  4.73it/s]\n","\n","                Sat Nov 28 11:48:40 2020 \n","\n","                Fold:17, Epoch:34, lr:0.0003333333\n","\n","                Train Loss:0.6069 - LogLoss:0.6069 --- ACC:0.8211 --- F1:0.8211\n","\n","                Valid Loss:0.4903 - LogLoss:0.4903 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:35 - Loss0.5473: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:35 - Loss:0.5020: 100% 4/4 [00:00<00:00,  4.73it/s]\n","\n","                Sat Nov 28 11:49:30 2020 \n","\n","                Fold:17, Epoch:35, lr:0.0003111111\n","\n","                Train Loss:0.5473 - LogLoss:0.5473 --- ACC:0.8297 --- F1:0.8297\n","\n","                Valid Loss:0.5020 - LogLoss:0.5020 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:36 - Loss0.5629: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:36 - Loss:0.5284: 100% 4/4 [00:00<00:00,  4.78it/s]\n","\n","                Sat Nov 28 11:50:20 2020 \n","\n","                Fold:17, Epoch:36, lr:0.0002888889\n","\n","                Train Loss:0.5629 - LogLoss:0.5629 --- ACC:0.8297 --- F1:0.8297\n","\n","                Valid Loss:0.5284 - LogLoss:0.5284 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:37 - Loss0.5359: 100% 69/69 [00:49<00:00,  1.38it/s]\n","Valid E:37 - Loss:0.5082: 100% 4/4 [00:00<00:00,  4.68it/s]\n","\n","                Sat Nov 28 11:51:11 2020 \n","\n","                Fold:17, Epoch:37, lr:0.0002666667\n","\n","                Train Loss:0.5359 - LogLoss:0.5359 --- ACC:0.8351 --- F1:0.8351\n","\n","                Valid Loss:0.5082 - LogLoss:0.5082 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","Train E:38 - Loss0.5205: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:38 - Loss:0.6067: 100% 4/4 [00:00<00:00,  4.72it/s]\n","\n","                Sat Nov 28 11:52:01 2020 \n","\n","                Fold:17, Epoch:38, lr:0.0002444444\n","\n","                Train Loss:0.5205 - LogLoss:0.5205 --- ACC:0.8426 --- F1:0.8426\n","\n","                Valid Loss:0.6067 - LogLoss:0.6067 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:39 - Loss0.4875: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:39 - Loss:0.5643: 100% 4/4 [00:00<00:00,  4.78it/s]\n","\n","                Sat Nov 28 11:52:50 2020 \n","\n","                Fold:17, Epoch:39, lr:0.0002222222\n","\n","                Train Loss:0.4875 - LogLoss:0.4875 --- ACC:0.8548 --- F1:0.8548\n","\n","                Valid Loss:0.5643 - LogLoss:0.5643 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:40 - Loss0.4797: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:40 - Loss:0.5623: 100% 4/4 [00:00<00:00,  4.72it/s]\n","\n","                Sat Nov 28 11:53:40 2020 \n","\n","                Fold:17, Epoch:40, lr:0.0002\n","\n","                Train Loss:0.4797 - LogLoss:0.4797 --- ACC:0.8587 --- F1:0.8587\n","\n","                Valid Loss:0.5623 - LogLoss:0.5623 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:41 - Loss0.4823: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:41 - Loss:0.5319: 100% 4/4 [00:00<00:00,  4.73it/s]\n","\n","                Sat Nov 28 11:54:30 2020 \n","\n","                Fold:17, Epoch:41, lr:0.0001777778\n","\n","                Train Loss:0.4823 - LogLoss:0.4823 --- ACC:0.8562 --- F1:0.8562\n","\n","                Valid Loss:0.5319 - LogLoss:0.5319 --- ACC:0.8766 --- F1:0.8766\n","\n","        \n","Train E:42 - Loss0.4531: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:42 - Loss:0.5097: 100% 4/4 [00:00<00:00,  4.70it/s]\n","\n","                Sat Nov 28 11:55:19 2020 \n","\n","                Fold:17, Epoch:42, lr:0.0001555556\n","\n","                Train Loss:0.4531 - LogLoss:0.4531 --- ACC:0.8644 --- F1:0.8644\n","\n","                Valid Loss:0.5097 - LogLoss:0.5097 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:43 - Loss0.4326: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:43 - Loss:0.5523: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:56:09 2020 \n","\n","                Fold:17, Epoch:43, lr:0.0001333333\n","\n","                Train Loss:0.4326 - LogLoss:0.4326 --- ACC:0.8616 --- F1:0.8616\n","\n","                Valid Loss:0.5523 - LogLoss:0.5523 --- ACC:0.8936 --- F1:0.8936\n","\n","        \n","Train E:44 - Loss0.4381: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:44 - Loss:0.5424: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 11:57:00 2020 \n","\n","                Fold:17, Epoch:44, lr:0.0001111111\n","\n","                Train Loss:0.4381 - LogLoss:0.4381 --- ACC:0.8693 --- F1:0.8693\n","\n","                Valid Loss:0.5424 - LogLoss:0.5424 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:45 - Loss0.3991: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:45 - Loss:0.5537: 100% 4/4 [00:00<00:00,  4.68it/s]\n","\n","                Sat Nov 28 11:57:49 2020 \n","\n","                Fold:17, Epoch:45, lr:8.888889e-05\n","\n","                Train Loss:0.3991 - LogLoss:0.3991 --- ACC:0.8804 --- F1:0.8804\n","\n","                Valid Loss:0.5537 - LogLoss:0.5537 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:46 - Loss0.4490: 100% 69/69 [00:48<00:00,  1.43it/s]\n","Valid E:46 - Loss:0.5401: 100% 4/4 [00:00<00:00,  4.70it/s]\n","\n","                Sat Nov 28 11:58:38 2020 \n","\n","                Fold:17, Epoch:46, lr:6.666667e-05\n","\n","                Train Loss:0.4490 - LogLoss:0.4490 --- ACC:0.8684 --- F1:0.8684\n","\n","                Valid Loss:0.5401 - LogLoss:0.5401 --- ACC:0.8894 --- F1:0.8894\n","\n","        \n","Train E:47 - Loss0.4021: 100% 69/69 [00:48<00:00,  1.42it/s]\n","Valid E:47 - Loss:0.5200: 100% 4/4 [00:00<00:00,  4.69it/s]\n","\n","                Sat Nov 28 11:59:28 2020 \n","\n","                Fold:17, Epoch:47, lr:4.444444e-05\n","\n","                Train Loss:0.4021 - LogLoss:0.4021 --- ACC:0.8816 --- F1:0.8816\n","\n","                Valid Loss:0.5200 - LogLoss:0.5200 --- ACC:0.8979 --- F1:0.8979\n","\n","        \n","Train E:48 - Loss0.3742: 100% 69/69 [00:49<00:00,  1.40it/s]\n","Valid E:48 - Loss:0.5116: 100% 4/4 [00:00<00:00,  4.66it/s]\n","\n","                Sat Nov 28 12:00:18 2020 \n","\n","                Fold:17, Epoch:48, lr:2.222222e-05\n","\n","                Train Loss:0.3742 - LogLoss:0.3742 --- ACC:0.8879 --- F1:0.8879\n","\n","                Valid Loss:0.5116 - LogLoss:0.5116 --- ACC:0.9064 --- F1:0.9064\n","\n","        \n","Train E:49 - Loss0.3877: 100% 69/69 [00:48<00:00,  1.41it/s]\n","Valid E:49 - Loss:0.5188: 100% 4/4 [00:00<00:00,  4.79it/s]\n","\n","                Sat Nov 28 12:01:08 2020 \n","\n","                Fold:17, Epoch:49, lr:0.0\n","\n","                Train Loss:0.3877 - LogLoss:0.3877 --- ACC:0.8816 --- F1:0.8816\n","\n","                Valid Loss:0.5188 - LogLoss:0.5188 --- ACC:0.9021 --- F1:0.9021\n","\n","        \n","100% 16/16 [00:02<00:00,  5.74it/s]\n","(1017, 193)\n","100% 16/16 [00:07<00:00,  2.09it/s]\n","100% 16/16 [00:10<00:00,  1.55it/s]\n","100% 16/16 [00:07<00:00,  2.21it/s]\n","100% 16/16 [00:09<00:00,  1.63it/s]\n","100% 16/16 [00:08<00:00,  1.94it/s]\n","100% 16/16 [00:08<00:00,  1.94it/s]\n","100% 16/16 [00:08<00:00,  1.86it/s]\n","100% 16/16 [00:07<00:00,  2.24it/s]\n","100% 16/16 [00:08<00:00,  1.96it/s]\n","100% 16/16 [00:08<00:00,  1.96it/s]\n","(1017, 193)\n","/content/drive/MyDrive/ZINDI Agricultural Keyword Spotter/weights/Eff6_20fold_base/fold-17-submission.csv\n","/content/drive/MyDrive/ZINDI Agricultural Keyword Spotter/weights/Eff6_20fold_base/tta-fold-17-submission.csv\n","100% 4/4 [00:00<00:00,  4.71it/s]\n"],"name":"stdout"}]}]}